{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to build the model that will eventually be used as the model behind the PL prediction for the app, and building the script to rebuild the model when new player data is introduced weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_csv(\"../final_combined_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns = [\n",
    "\t\"home_goals\", \"away_goals\", \"home_shots\", \"away_shots\", \"home_shots_on_target\", \"away_shots_on_target\",\n",
    "\t\"home_corners\", \"away_corners\", \"home_fouls\", \"away_fouls\", \"home_yellow_cards\", \"away_yellow_cards\",\n",
    "\t\"home_red_cards\", \"away_red_cards\"\n",
    "]\n",
    "\n",
    "player_stats_columns = [\n",
    "\t\"player_id\", \"minutes_played\",\"ninetys\",\"goals\",\"assists\",\"non_penalty_goals\",\"penalties_scored\",\"penalties_attempted\",\"yellow_cards\",\"red_cards\",\"expected_goals\",\n",
    "\t\"non_penalty_expected_goals\",\"expected_assisted_goals\",\"progressive_carries\",\"progressive_passes\",\"progressive_passes_received\",\"total_passing_distance\",\"total_progressive_passing_distance\",\"short_passes_completed\",\"short_passes_attempted\",\"medium_passes_completed\",\"medium_passes_attempted\",\n",
    "\t\"long_passes_completed\",\"long_passes_attempted\",\"expected_assists\",\"key_passes\",\"passes_into_final_third\",\"passes_into_penalty_area\",\"crosses_into_penalty_area\",\"shots\",\"shots_on_target\",\"average_shot_distance\",\"shots_from_free_kicks\",\n",
    "\t\"shots_from_penalties\",\"touches\",\"touches_in_defensive_penalty_area\",\"touches_in_defensive_third\",\"touches_in_middle_third\",\"touches_in_attacking_third\",\"touches_in_attacking_penalty_area\",\"live_ball_touches\",\"take_ons_attempted\",\"take_ons_succeeded\",\"times_tackled_during_take_on\",\n",
    "\t\"carries\",\"total_carrying_distance\",\"progressive_carrying_distance\",\"carries_into_final_third\",\"carries_into_penalty_area\",\"miscontrols\",\"dispossessed\",\"passes_received\",\"tackles\",\"tackles_won\",\"defensive_third_tackles\",\n",
    "\t\"middle_third_tackles\",\"attacking_third_tackles\",\"dribblers_tackled\",\"dribbler_tackles_attempted\",\"shots_blocked\",\"passes_blocked\",\"interceptions\",\"clearances\",\"errors_leading_to_shot\",\"goals_against\",\"shots_on_target_against\",\"saves\",\"clean_sheets\",\"penalties_faced\",\"penalties_allowed\",\"penalties_saved\",\"penalties_missed\"\n",
    "]\n",
    "pure_stats_columns = [\n",
    "\t\"minutes_played\",\"goals\",\"assists\",\"non_penalty_goals\",\"penalties_scored\",\"penalties_attempted\",\"yellow_cards\",\"red_cards\",\"expected_goals\",\n",
    "\t\"non_penalty_expected_goals\",\"expected_assisted_goals\",\"progressive_carries\",\"progressive_passes\",\"progressive_passes_received\",\"total_passing_distance\",\"total_progressive_passing_distance\",\"short_passes_completed\",\"short_passes_attempted\",\"medium_passes_completed\",\"medium_passes_attempted\",\n",
    "\t\"long_passes_completed\",\"long_passes_attempted\",\"expected_assists\",\"key_passes\",\"passes_into_final_third\",\"passes_into_penalty_area\",\"crosses_into_penalty_area\",\"shots\",\"shots_on_target\",\"average_shot_distance\",\"shots_from_free_kicks\",\n",
    "\t\"shots_from_penalties\",\"touches\",\"touches_in_defensive_penalty_area\",\"touches_in_defensive_third\",\"touches_in_middle_third\",\"touches_in_attacking_third\",\"touches_in_attacking_penalty_area\",\"live_ball_touches\",\"take_ons_attempted\",\"take_ons_succeeded\",\"times_tackled_during_take_on\",\n",
    "\t\"carries\",\"total_carrying_distance\",\"progressive_carrying_distance\",\"carries_into_final_third\",\"carries_into_penalty_area\",\"miscontrols\",\"dispossessed\",\"passes_received\",\"tackles\",\"tackles_won\",\"defensive_third_tackles\",\n",
    "\t\"middle_third_tackles\",\"attacking_third_tackles\",\"dribblers_tackled\",\"dribbler_tackles_attempted\",\"shots_blocked\",\"passes_blocked\",\"interceptions\",\"clearances\",\"errors_leading_to_shot\",\"goals_against\",\"shots_on_target_against\",\"saves\",\"clean_sheets\",\"penalties_faced\",\"penalties_allowed\",\"penalties_saved\",\"penalties_missed\"\n",
    "]\n",
    "team_stats_columns = [\n",
    "\t\"team_id\", \"goals\",\"assists\",\"non_penalty_goals\",\"penalties_scored\",\"penalties_attempted\",\"yellow_cards\",\"red_cards\",\"expected_goals\",\n",
    "\t\"non_penalty_expected_goals\",\"expected_assisted_goals\",\"progressive_carries\",\"progressive_passes\",\"progressive_passes_received\",\"total_passing_distance\",\"total_progressive_passing_distance\",\"short_passes_completed\",\"short_passes_attempted\",\"medium_passes_completed\",\"medium_passes_attempted\",\n",
    "\t\"long_passes_completed\",\"long_passes_attempted\",\"expected_assists\",\"key_passes\",\"passes_into_final_third\",\"passes_into_penalty_area\",\"crosses_into_penalty_area\",\"shots\",\"shots_on_target\",\"average_shot_distance\",\"shots_from_free_kicks\",\n",
    "\t\"shots_from_penalties\",\"touches\",\"touches_in_defensive_penalty_area\",\"touches_in_defensive_third\",\"touches_in_middle_third\",\"touches_in_attacking_third\",\"touches_in_attacking_penalty_area\",\"live_ball_touches\",\"take_ons_attempted\",\"take_ons_succeeded\",\"times_tackled_during_take_on\",\n",
    "\t\"carries\",\"total_carrying_distance\",\"progressive_carrying_distance\",\"carries_into_final_third\",\"carries_into_penalty_area\",\"miscontrols\",\"dispossessed\",\"passes_received\",\"tackles\",\"tackles_won\",\"defensive_third_tackles\",\n",
    "\t\"middle_third_tackles\",\"attacking_third_tackles\",\"dribblers_tackled\",\"dribbler_tackles_attempted\",\"shots_blocked\",\"passes_blocked\",\"interceptions\",\"clearances\",\"errors_leading_to_shot\",\"goals_against\",\"shots_on_target_against\",\"saves\",\"clean_sheets\",\"penalties_faced\",\"penalties_allowed\",\"penalties_saved\",\"penalties_missed\"\n",
    "]\n",
    "pure_stats_columns_no_minutes = [\n",
    "\t\"goals\",\"assists\",\"non_penalty_goals\",\"penalties_scored\",\"penalties_attempted\",\"yellow_cards\",\"red_cards\",\"expected_goals\",\n",
    "\t\"non_penalty_expected_goals\",\"expected_assisted_goals\",\"progressive_carries\",\"progressive_passes\",\"progressive_passes_received\",\"total_passing_distance\",\"total_progressive_passing_distance\",\"short_passes_completed\",\"short_passes_attempted\",\"medium_passes_completed\",\"medium_passes_attempted\",\n",
    "\t\"long_passes_completed\",\"long_passes_attempted\",\"expected_assists\",\"key_passes\",\"passes_into_final_third\",\"passes_into_penalty_area\",\"crosses_into_penalty_area\",\"shots\",\"shots_on_target\",\"average_shot_distance\",\"shots_from_free_kicks\",\n",
    "\t\"shots_from_penalties\",\"touches\",\"touches_in_defensive_penalty_area\",\"touches_in_defensive_third\",\"touches_in_middle_third\",\"touches_in_attacking_third\",\"touches_in_attacking_penalty_area\",\"live_ball_touches\",\"take_ons_attempted\",\"take_ons_succeeded\",\"times_tackled_during_take_on\",\n",
    "\t\"carries\",\"total_carrying_distance\",\"progressive_carrying_distance\",\"carries_into_final_third\",\"carries_into_penalty_area\",\"miscontrols\",\"dispossessed\",\"passes_received\",\"tackles\",\"tackles_won\",\"defensive_third_tackles\",\n",
    "\t\"middle_third_tackles\",\"attacking_third_tackles\",\"dribblers_tackled\",\"dribbler_tackles_attempted\",\"shots_blocked\",\"passes_blocked\",\"interceptions\",\"clearances\",\"errors_leading_to_shot\",\"goals_against\",\"shots_on_target_against\",\"saves\",\"clean_sheets\",\"penalties_faced\",\"penalties_allowed\",\"penalties_saved\",\"penalties_missed\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_standardized = scaler.fit_transform(combined[pure_stats_columns_no_minutes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evr = {}\n",
    "n_components = {}\n",
    "feature_to_pc = {}\n",
    "\n",
    "for n in range(1,26):\n",
    "\tpca = PCA(n_components = n, random_state=938)\n",
    "\tpca.fit(combined_standardized)\n",
    "\tfeature_to_pc_map = pd.DataFrame(pca.components_, columns=pure_stats_columns_no_minutes)\n",
    "\tcomponents = pca.transform(combined_standardized)\n",
    "\tcomponents_df = pd.DataFrame(data=components[:, [p for p in range(n)]], columns=pca.get_feature_names_out(), )\n",
    "\t\n",
    "\tevr[n] = sum(pca.explained_variance_ratio_)\n",
    "\tn_components[n] = components_df\n",
    "\tfeature_to_pc[n] = feature_to_pc_map\n",
    "\n",
    "pd.DataFrame(data=evr, index=[\"explained_variance_ratio\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the effect of different numbers if PCs on the outcome of the NN, testing n=2, 5 and 10. Use each n components to train and test the neural network, and compare the performance of each one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 69\n",
    "OUTPUT_SIZE = 14\n",
    "ROWS = 1927"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(32, activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(32, activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(32, activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=15\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(32, activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(32, activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above experiments show us the accuracy of each model increases with an increased number of features up to a point, it seem somewhere between 15 and 20 features, where the accuracy on the training data peaks. I will use 15 principal components going forward for the investigations, as this seems to yield the highest accuracy of those tested here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of predicting exact values for the match facts, I am not expecting exact matches between model and the actual results, just hoping for a close approximation, or at the very least, the correct side with the higher value, i.e. home team scores more goals than the away team is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 PC model build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined[pure_stats_columns_no_minutes]\n",
    "y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=543)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler(copy=True).fit(X_train)\n",
    "y_scaler = StandardScaler(copy=True).fit(y_train)\n",
    "\n",
    "X_train = X_scaler.transform(X_train)\n",
    "# y_train = y_scaler.transform(y_train)\n",
    "\n",
    "X_test = X_scaler.transform(X_test)\n",
    "# y_test = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=15\n",
    "\n",
    "pca = PCA(n_components = n, random_state=576)\n",
    "pca.fit(X_train)\n",
    "\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below table shows the breakdown of each principle component in terms of the proportion of the value from each of the table columns used to make it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(pca.components_, columns=pure_stats_columns_no_minutes)\n",
    "df.index.name = \"principle_component_number\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = len(X_train[0])\n",
    "OUTPUT_SIZE = len(output_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(15, activation='relu'),\n",
    "\ttf.keras.layers.Dense(12, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_shots = 0\n",
    "total_shots_over = 0\n",
    "total_shots_under = 0\n",
    "\n",
    "total_shots_on_target = 0\n",
    "total_shots_on_target_over = 0\n",
    "total_shots_on_target_under = 0\n",
    "\n",
    "total_booking_points = 0\n",
    "total_booking_points_over = 0\n",
    "total_booking_points_under = 0\n",
    "\n",
    "correct_score = 0\n",
    "\n",
    "winner = 0\n",
    "\n",
    "total_corners = 0\n",
    "total_corners_over = 0\n",
    "total_corners_under = 0\n",
    "\n",
    "total_fouls = 0\n",
    "total_fouls_over = 0\n",
    "total_fouls_under = 0\n",
    "\n",
    "goals_over = 0\n",
    "goals_under = 0\n",
    "\n",
    "all_under = 0\n",
    "all_over = 0\n",
    "\n",
    "total_tested  = len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, y in enumerate(y_hat):\n",
    "\thome_goals_hat, away_goals_hat, home_shots_hat, away_shots_hat, home_shots_on_target_hat, away_shots_on_target_hat, home_corners_hat, away_corners_hat, home_fouls_hat, away_fouls_hat, home_yellow_cards_hat, away_yellow_cards_hat, home_red_cards_hat, away_red_cards_hat = y\n",
    "\thome_goals, away_goals, home_shots, away_shots, home_shots_on_target, away_shots_on_target, home_corners, away_corners, home_fouls, away_fouls, home_yellow_cards, away_yellow_cards, home_red_cards, away_red_cards = y_test.iloc[idx].tolist()\n",
    "\t\n",
    "\ttotal_shots += 1 if np.floor(home_shots_hat)+np.floor(away_shots_hat) == home_shots+away_shots else 0\n",
    "\ttotal_shots_over += 1 if np.floor(home_shots_hat)+np.floor(away_shots_hat) > home_shots+away_shots else 0\n",
    "\ttotal_shots_under += 1 if np.floor(home_shots_hat)+np.floor(away_shots_hat) < home_shots+away_shots else 0\n",
    "\t\n",
    "\ttotal_shots_on_target += 1 if np.floor(home_shots_on_target_hat)+np.floor(away_shots_on_target_hat) == home_shots_on_target+away_shots_on_target else 0\n",
    "\ttotal_shots_on_target_over += 1 if np.floor(home_shots_on_target_hat)+np.floor(away_shots_on_target_hat) > home_shots_on_target+away_shots_on_target else 0\n",
    "\ttotal_shots_on_target_under += 1 if np.floor(home_shots_on_target_hat)+np.floor(away_shots_on_target_hat) < home_shots_on_target+away_shots_on_target else 0\n",
    "\n",
    "\ttotal_booking_points += 1 if (np.floor(home_yellow_cards_hat)+np.floor(away_yellow_cards_hat))*10+(np.floor(home_red_cards_hat)+np.floor(away_red_cards_hat))*25 == (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 else 0\n",
    "\ttotal_booking_points_over += 1 if (np.floor(home_yellow_cards_hat)+np.floor(away_yellow_cards_hat))*10+(np.floor(home_red_cards_hat)+np.floor(away_red_cards_hat))*25 > (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 else 0\n",
    "\ttotal_booking_points_under += 1 if (np.floor(home_yellow_cards_hat)+np.floor(away_yellow_cards_hat))*10+(np.floor(home_red_cards_hat)+np.floor(away_red_cards_hat))*25 < (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 else 0\n",
    "\n",
    "\tcorrect_score += 1 if np.floor(home_goals_hat) == home_goals and np.floor(away_goals_hat) == away_goals else 0\n",
    "\t\n",
    "\twinner += 1 if (home_goals_hat > away_goals_hat and home_goals > away_goals) or (home_goals_hat < away_goals_hat and home_goals < away_goals) else 0\n",
    "\n",
    "\ttotal_fouls += 1 if np.floor(home_fouls_hat) + np.floor(away_fouls_hat) == home_fouls + away_fouls else 0\n",
    "\ttotal_fouls_over += 1 if np.floor(home_fouls_hat) + np.floor(away_fouls_hat) > home_fouls+ away_fouls else 0\n",
    "\ttotal_fouls_under += 1 if np.floor(home_fouls_hat) + np.floor(away_fouls_hat) < home_fouls+ away_fouls else 0\n",
    "\n",
    "\ttotal_corners += 1 if np.floor(home_corners_hat) + np.floor(away_corners_hat) == home_corners + away_corners else 0\n",
    "\ttotal_corners_over += 1 if np.floor(home_corners_hat) + np.floor(away_corners_hat) > home_corners + away_corners else 0\n",
    "\ttotal_corners_under += 1 if np.floor(home_corners_hat) + np.floor(away_corners_hat) < home_corners + away_corners else 0\n",
    "\n",
    "\tgoals_over += 1 if np.floor(home_goals_hat) + np.floor(away_goals_hat) > home_goals + away_goals else 0\n",
    "\tgoals_under += 1 if np.floor(home_goals_hat) + np.floor(away_goals_hat) < home_goals + away_goals else 0\n",
    "\n",
    "\tall_under += 1 if np.floor(home_shots_hat)+np.floor(away_shots_hat) < home_shots+away_shots and np.floor(home_shots_on_target_hat)+np.floor(away_shots_on_target_hat) < home_shots_on_target+away_shots_on_target and (np.floor(home_yellow_cards_hat)+np.floor(away_yellow_cards_hat))*10+(np.floor(home_red_cards_hat)+np.floor(away_red_cards_hat))*25 < (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 and np.floor(home_corners_hat) + np.floor(away_corners_hat) < home_corners + away_corners and np.floor(home_corners_hat) + np.floor(away_corners_hat) < home_corners + away_corners and np.floor(home_goals_hat) + np.floor(away_goals_hat) < home_goals + away_goals else 0\n",
    "\tall_over += 1 if np.floor(home_shots_hat)+np.floor(away_shots_hat) > home_shots+away_shots and np.floor(home_shots_on_target_hat)+np.floor(away_shots_on_target_hat) > home_shots_on_target+away_shots_on_target and (np.floor(home_yellow_cards_hat)+np.floor(away_yellow_cards_hat))*10+(np.floor(home_red_cards_hat)+np.floor(away_red_cards_hat))*25 > (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 and np.floor(home_corners_hat) + np.floor(away_corners_hat) > home_corners + away_corners and np.floor(home_goals_hat) + np.floor(away_goals_hat) > home_goals + away_goals else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total_shots: \"+str(total_shots/total_tested))\n",
    "print(\"total_shots_over: \"+str(total_shots_over/total_tested))\n",
    "print(\"total_shots_under: \"+str(total_shots_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"total_shots_on_target: \"+str(total_shots_on_target/total_tested))\n",
    "print(\"total_shots_on_target_over: \"+str(total_shots_on_target_over/total_tested))\n",
    "print(\"total_shots_on_target_under: \"+str(total_shots_on_target_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"total_booking_points: \"+str(total_booking_points/total_tested))\n",
    "print(\"total_booking_points_over: \"+str(total_booking_points_over/total_tested))\n",
    "print(\"total_booking_points_under: \"+str(total_booking_points_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"correct_score: \"+str(correct_score/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"winner: \"+str(winner/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"total_corners: \"+str(total_corners/total_tested))\n",
    "print(\"total_corners_over: \"+str(total_corners_over/total_tested))\n",
    "print(\"total_corners_under: \"+str(total_corners_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"total_fouls: \"+str(total_fouls/total_tested))\n",
    "print(\"total_fouls_over: \"+str(total_fouls_over/total_tested))\n",
    "print(\"total_fouls_under: \"+str(total_fouls_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"goals_over: \"+str(goals_over/total_tested))\n",
    "print(\"goals_under: \"+str(goals_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"all_over: \"+str(all_over/total_tested))\n",
    "print(\"all_under: \"+str(all_under/total_tested))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to build and compile a model, with the arguments in it being the values to be update during tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp_model(hidden_layer_one=13, dropout=0.2, learn_rate=0.01, n_h_layers=1):\n",
    "\n",
    "\tmodel = tf.keras.models.Sequential()\n",
    "\n",
    "\t#Â input\n",
    "\tmodel.add(tf.keras.layers.Dense(15, activation=\"relu\", input_dim=15))\n",
    "\n",
    "\tfor i in range(n_h_layers):\n",
    "\t\tmodel.add(tf.keras.layers.Dense(hidden_layer_one, activation=\"relu\"))\n",
    "\n",
    "\t# dropout layer to remove redundant nodes\n",
    "\tmodel.add(tf.keras.layers.Dropout(dropout))\n",
    "\t\n",
    "\t# output\n",
    "\tmodel.add(tf.keras.layers.Dense(14, activation=\"relu\"))\n",
    "\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learn_rate),\n",
    "\t\tloss=\"mse\",\n",
    "\t\tmetrics=[\"accuracy\"])\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model using the *get_mlp_model* function, letting tensorflow use this function when building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(model=get_mlp_model, verbose=0, hidden_layer_one=10, learn_rate=0.01, dropout=0.05, n_h_layers=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameter search space, and then generate the search object to be used later, by RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a grid of the hyperparameter search space\n",
    "hidden_layer_one = [10, 15, 30, 50, 100]\n",
    "learn_rate = [1e-2, 1e-3, 1e-4]\n",
    "dropout = [0.05, 0.1, 0.2, 0.3, 0.4]\n",
    "batch_size = [4, 8, 16, 32, 64]\n",
    "epochs = [10, 50, 100, 150, 200, 500]\n",
    "n_h_layers = [1, 2, 3, 5]\n",
    "\n",
    "# create a dictionary from the hyperparameter grid\n",
    "grid = dict(\n",
    "\thidden_layer_one=hidden_layer_one,\n",
    "\tlearn_rate=learn_rate,\n",
    "\tdropout=dropout,\n",
    "\tbatch_size=batch_size,\n",
    "\tepochs=epochs,\n",
    "\tn_h_layers=n_h_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a scoring function for the searcher, average the value of all the *under* stats and return this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_average_under_rate = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(estimator, test_x: np.ndarray, test_y: pd.DataFrame) -> float:\n",
    "\ttest_y = test_y.to_numpy()\n",
    "\t\n",
    "\testimator.fit(test_x, test_y);\n",
    "\ty_hat = estimator.predict(test_x)\n",
    "\t\n",
    "\taverage_under_rate = 0\n",
    "\n",
    "\ttotal_shots_under = 0\n",
    "\ttotal_shots_on_target_under = 0\n",
    "\ttotal_booking_points_under = 0\n",
    "\ttotal_corners_under = 0\n",
    "\ttotal_fouls_under = 0\n",
    "\tgoals_under = 0\n",
    "\tall_under = 0\n",
    "\n",
    "\ttotal_tested = len(y_hat)\n",
    "\t\n",
    "\tfor idx, y in enumerate(y_hat):\n",
    "\n",
    "\t\thome_goals_hat, away_goals_hat, home_shots_hat, away_shots_hat, home_shots_on_target_hat, away_shots_on_target_hat, home_corners_hat, away_corners_hat, home_fouls_hat, away_fouls_hat, home_yellow_cards_hat, away_yellow_cards_hat, home_red_cards_hat, away_red_cards_hat = y\n",
    "\t\thome_goals, away_goals, home_shots, away_shots, home_shots_on_target, away_shots_on_target, home_corners, away_corners, home_fouls, away_fouls, home_yellow_cards, away_yellow_cards, home_red_cards, away_red_cards = test_y[idx]\n",
    "\n",
    "\t\ttotal_shots_under += 1 if np.floor(home_shots_hat)+np.floor(away_shots_hat) < home_shots+away_shots else 0\n",
    "\t\ttotal_shots_on_target_under += 1 if np.floor(home_shots_on_target_hat)+np.floor(away_shots_on_target_hat) < home_shots_on_target+away_shots_on_target else 0\n",
    "\t\ttotal_booking_points_under += 1 if (np.floor(home_yellow_cards_hat)+np.floor(away_yellow_cards_hat))*10+(np.floor(home_red_cards_hat)+np.floor(away_red_cards_hat))*25 < (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 else 0\n",
    "\t\ttotal_corners_under += 1 if np.floor(home_corners_hat) + np.floor(away_corners_hat) < home_corners + away_corners else 0\n",
    "\t\ttotal_fouls_under += 1 if np.floor(home_fouls_hat) + np.floor(away_fouls_hat) < home_fouls+ away_fouls else 0\n",
    "\t\tgoals_under += 1 if np.floor(home_goals_hat) + np.floor(away_goals_hat) < home_goals + away_goals else 0\n",
    "\n",
    "\t\taverage_under_rate += ((total_shots_under/total_tested)+(total_shots_on_target_under/total_tested)+(total_booking_points_under/total_tested)+(total_fouls_under/total_tested)+(total_corners_under/total_tested)+(goals_under/total_tested))/6\n",
    "\n",
    "\taverage_under_rate = average_under_rate/total_tested\n",
    "\t\n",
    "\treturn average_under_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the searcher object, used to iterate over the search parameters and determine the best hyper-parameter setup from the space we've created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = GridSearchCV(estimator=model, n_jobs=-1, \n",
    "\tparam_grid=grid, scoring=scoring, verbose=4, cv=3)\n",
    "\n",
    "searchResults = searcher.fit(X_train, y_train)\n",
    "\n",
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "print(\"[INFO] best score is {:.2f} using {}\".format(bestScore,bestParams))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next v  steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tune parameters and layers on the 15 PC model to increase the accuracy\n",
    "- Create a method to define the accuracy on the test set; strict equality for each of the output values is not necessary as under/over options on the betting platform mean a close approximation of the outcome is all that is required. Success/accuracy measure based on the bet markets available for each game:\n",
    "\t- Total shots\n",
    "\t- Total booking points\n",
    "\t- Correct score\n",
    "\t- Outright\n",
    "\t- Total corners\n",
    "\t- Under/over goals\n",
    "- Save the model\n",
    "- Complete the notebook with all annotations and text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomSearchCV  \n",
    "best score is 0.39 using {'n_h_layers': 5, 'learn_rate': 0.0001, 'hidden_layer_one': 15, 'epochs': 100, 'dropout': 0.2, 'batch_size': 64}  \n",
    "best score is 0.40 using {'n_h_layers': 7, 'learn_rate': 0.0001, 'hidden_layer_one': 15, 'epochs': 1000, 'dropout': 0.75, 'batch_size': 16}  \n",
    "best score is 0.49 using {'n_h_layers': 3, 'learn_rate': 0.0001, 'hidden_layer_one': 30, 'epochs': 10, 'dropout': 0.3, 'batch_size': 64} \n",
    "\n",
    "GridSearchCV  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scaling y reduces the accuracy of the model by a factor of 6, why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl-stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
