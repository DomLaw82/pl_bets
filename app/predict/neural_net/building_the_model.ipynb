{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to build the model that will eventually be used as the model behind the PL prediction for the app, and building the script to rebuild the model when new player data is introduced weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.read_csv(\"../files/final_combined_dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2116 entries, 0 to 2115\n",
      "Data columns (total 94 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   match_id                                2116 non-null   object \n",
      " 1   goals                                   2116 non-null   float64\n",
      " 2   assists                                 2116 non-null   float64\n",
      " 3   direct_goal_contributions               2116 non-null   float64\n",
      " 4   non_penalty_goals                       2116 non-null   float64\n",
      " 5   penalties_scored                        2116 non-null   float64\n",
      " 6   penalties_attempted                     2116 non-null   float64\n",
      " 7   yellow_cards                            2116 non-null   float64\n",
      " 8   red_cards                               2116 non-null   float64\n",
      " 9   expected_goals                          2116 non-null   float64\n",
      " 10  non_penalty_expected_goals              2116 non-null   float64\n",
      " 11  expected_assisted_goals                 2116 non-null   float64\n",
      " 12  progressive_carries                     2116 non-null   float64\n",
      " 13  progressive_passes                      2116 non-null   float64\n",
      " 14  total_passing_distance                  2116 non-null   float64\n",
      " 15  total_progressive_passing_distance      2116 non-null   float64\n",
      " 16  short_passes_completed                  2116 non-null   float64\n",
      " 17  short_passes_attempted                  2116 non-null   float64\n",
      " 18  medium_passes_completed                 2116 non-null   float64\n",
      " 19  medium_passes_attempted                 2116 non-null   float64\n",
      " 20  long_passes_completed                   2116 non-null   float64\n",
      " 21  long_passes_attempted                   2116 non-null   float64\n",
      " 22  expected_assists                        2116 non-null   float64\n",
      " 23  key_passes                              2116 non-null   float64\n",
      " 24  passes_into_final_third                 2116 non-null   float64\n",
      " 25  passes_into_penalty_area                2116 non-null   float64\n",
      " 26  crosses_into_penalty_area               2116 non-null   float64\n",
      " 27  shots                                   2116 non-null   float64\n",
      " 28  shots_on_target                         2116 non-null   float64\n",
      " 29  average_shot_distance                   2116 non-null   float64\n",
      " 30  shots_from_free_kicks                   2116 non-null   float64\n",
      " 31  penalties_made                          2116 non-null   float64\n",
      " 32  touches                                 2116 non-null   float64\n",
      " 33  touches_in_defensive_penalty_area       2116 non-null   float64\n",
      " 34  touches_in_defensive_third              2116 non-null   float64\n",
      " 35  touches_in_middle_third                 2116 non-null   float64\n",
      " 36  touches_in_attacking_third              2116 non-null   float64\n",
      " 37  touches_in_attacking_penalty_area       2116 non-null   float64\n",
      " 38  live_ball_touches                       2116 non-null   float64\n",
      " 39  take_ons_attempted                      2116 non-null   float64\n",
      " 40  take_ons_succeeded                      2116 non-null   float64\n",
      " 41  times_tackled_during_take_on            2116 non-null   float64\n",
      " 42  carries                                 2116 non-null   float64\n",
      " 43  total_carrying_distance                 2116 non-null   float64\n",
      " 44  progressive_carrying_distance           2116 non-null   float64\n",
      " 45  carries_into_final_third                2116 non-null   float64\n",
      " 46  carries_into_penalty_area               2116 non-null   float64\n",
      " 47  miscontrols                             2116 non-null   float64\n",
      " 48  dispossessed                            2116 non-null   float64\n",
      " 49  passes_received                         2116 non-null   float64\n",
      " 50  progressive_passes_received             2116 non-null   float64\n",
      " 51  tackles                                 2116 non-null   float64\n",
      " 52  tackles_won                             2116 non-null   float64\n",
      " 53  defensive_third_tackles                 2116 non-null   float64\n",
      " 54  middle_third_tackles                    2116 non-null   float64\n",
      " 55  attacking_third_tackles                 2116 non-null   float64\n",
      " 56  dribblers_tackled                       2116 non-null   float64\n",
      " 57  dribbler_tackles_attempted              2116 non-null   float64\n",
      " 58  shots_blocked                           2116 non-null   float64\n",
      " 59  passes_blocked                          2116 non-null   float64\n",
      " 60  interceptions                           2116 non-null   float64\n",
      " 61  clearances                              2116 non-null   float64\n",
      " 62  errors_leading_to_shot                  2116 non-null   float64\n",
      " 63  goals_against                           2116 non-null   float64\n",
      " 64  shots_on_target_against                 2116 non-null   float64\n",
      " 65  saves                                   2116 non-null   float64\n",
      " 66  clean_sheets                            2116 non-null   float64\n",
      " 67  penalties_faced                         2116 non-null   float64\n",
      " 68  penalties_allowed                       2116 non-null   float64\n",
      " 69  penalties_saved                         2116 non-null   float64\n",
      " 70  penalties_missed                        2116 non-null   float64\n",
      " 71  competition_id                          2116 non-null   int64  \n",
      " 72  home_team_id                            2116 non-null   object \n",
      " 73  away_team_id                            2116 non-null   object \n",
      " 74  referee_id                              2116 non-null   object \n",
      " 75  home_goals                              2116 non-null   int64  \n",
      " 76  away_goals                              2116 non-null   int64  \n",
      " 77  home_shots                              2116 non-null   int64  \n",
      " 78  away_shots                              2116 non-null   int64  \n",
      " 79  home_shots_on_target                    2116 non-null   int64  \n",
      " 80  away_shots_on_target                    2116 non-null   int64  \n",
      " 81  home_corners                            2116 non-null   int64  \n",
      " 82  away_corners                            2116 non-null   int64  \n",
      " 83  home_fouls                              2116 non-null   int64  \n",
      " 84  away_fouls                              2116 non-null   int64  \n",
      " 85  home_yellow_cards                       2116 non-null   int64  \n",
      " 86  away_yellow_cards                       2116 non-null   int64  \n",
      " 87  home_red_cards                          2116 non-null   int64  \n",
      " 88  away_red_cards                          2116 non-null   int64  \n",
      " 89  home_team_at_home_mean_goal_difference  2116 non-null   float64\n",
      " 90  home_team_overall_mean_goal_difference  2116 non-null   float64\n",
      " 91  away_team_at_away_mean_goal_difference  2116 non-null   float64\n",
      " 92  away_team_overall_mean_goal_difference  2116 non-null   float64\n",
      " 93  head_to_head_goal_difference            2116 non-null   int64  \n",
      "dtypes: float64(74), int64(16), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>goals</th>\n",
       "      <th>assists</th>\n",
       "      <th>direct_goal_contributions</th>\n",
       "      <th>non_penalty_goals</th>\n",
       "      <th>penalties_scored</th>\n",
       "      <th>penalties_attempted</th>\n",
       "      <th>yellow_cards</th>\n",
       "      <th>red_cards</th>\n",
       "      <th>expected_goals</th>\n",
       "      <th>...</th>\n",
       "      <th>away_fouls</th>\n",
       "      <th>home_yellow_cards</th>\n",
       "      <th>away_yellow_cards</th>\n",
       "      <th>home_red_cards</th>\n",
       "      <th>away_red_cards</th>\n",
       "      <th>home_team_at_home_mean_goal_difference</th>\n",
       "      <th>home_team_overall_mean_goal_difference</th>\n",
       "      <th>away_team_at_away_mean_goal_difference</th>\n",
       "      <th>away_team_overall_mean_goal_difference</th>\n",
       "      <th>head_to_head_goal_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m-00381</td>\n",
       "      <td>0.393401</td>\n",
       "      <td>0.269112</td>\n",
       "      <td>0.662513</td>\n",
       "      <td>0.355397</td>\n",
       "      <td>0.038004</td>\n",
       "      <td>0.054601</td>\n",
       "      <td>0.556054</td>\n",
       "      <td>-0.031945</td>\n",
       "      <td>0.394375</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m-00382</td>\n",
       "      <td>0.134401</td>\n",
       "      <td>0.408515</td>\n",
       "      <td>0.542916</td>\n",
       "      <td>0.169614</td>\n",
       "      <td>-0.035212</td>\n",
       "      <td>-0.062705</td>\n",
       "      <td>0.464746</td>\n",
       "      <td>0.040671</td>\n",
       "      <td>0.203698</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m-00383</td>\n",
       "      <td>1.032333</td>\n",
       "      <td>0.289712</td>\n",
       "      <td>1.322045</td>\n",
       "      <td>0.976505</td>\n",
       "      <td>0.055828</td>\n",
       "      <td>0.080853</td>\n",
       "      <td>0.654894</td>\n",
       "      <td>-0.011413</td>\n",
       "      <td>0.903525</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m-00384</td>\n",
       "      <td>0.073795</td>\n",
       "      <td>0.225465</td>\n",
       "      <td>0.299260</td>\n",
       "      <td>0.152876</td>\n",
       "      <td>-0.079081</td>\n",
       "      <td>-0.080597</td>\n",
       "      <td>0.105934</td>\n",
       "      <td>-0.043515</td>\n",
       "      <td>-0.051271</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m-00385</td>\n",
       "      <td>-0.308318</td>\n",
       "      <td>-0.074280</td>\n",
       "      <td>-0.382598</td>\n",
       "      <td>-0.265916</td>\n",
       "      <td>-0.042402</td>\n",
       "      <td>-0.029883</td>\n",
       "      <td>0.243744</td>\n",
       "      <td>-0.032462</td>\n",
       "      <td>-0.213221</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  match_id     goals   assists  direct_goal_contributions  non_penalty_goals  \\\n",
       "0  m-00381  0.393401  0.269112                   0.662513           0.355397   \n",
       "1  m-00382  0.134401  0.408515                   0.542916           0.169614   \n",
       "2  m-00383  1.032333  0.289712                   1.322045           0.976505   \n",
       "3  m-00384  0.073795  0.225465                   0.299260           0.152876   \n",
       "4  m-00385 -0.308318 -0.074280                  -0.382598          -0.265916   \n",
       "\n",
       "   penalties_scored  penalties_attempted  yellow_cards  red_cards  \\\n",
       "0          0.038004             0.054601      0.556054  -0.031945   \n",
       "1         -0.035212            -0.062705      0.464746   0.040671   \n",
       "2          0.055828             0.080853      0.654894  -0.011413   \n",
       "3         -0.079081            -0.080597      0.105934  -0.043515   \n",
       "4         -0.042402            -0.029883      0.243744  -0.032462   \n",
       "\n",
       "   expected_goals  ...  away_fouls  home_yellow_cards  away_yellow_cards  \\\n",
       "0        0.394375  ...           9                  2                  2   \n",
       "1        0.203698  ...          14                  5                  2   \n",
       "2        0.903525  ...          14                  2                  5   \n",
       "3       -0.051271  ...          15                  0                  2   \n",
       "4       -0.213221  ...          12                  4                  1   \n",
       "\n",
       "   home_red_cards  away_red_cards  home_team_at_home_mean_goal_difference  \\\n",
       "0               0               0                                     2.4   \n",
       "1               0               0                                     1.4   \n",
       "2               0               0                                     1.0   \n",
       "3               0               0                                     2.0   \n",
       "4               0               0                                     1.8   \n",
       "\n",
       "   home_team_overall_mean_goal_difference  \\\n",
       "0                                     1.6   \n",
       "1                                     1.6   \n",
       "2                                     1.6   \n",
       "3                                     1.6   \n",
       "4                                     1.6   \n",
       "\n",
       "   away_team_at_away_mean_goal_difference  \\\n",
       "0                                    -2.8   \n",
       "1                                    -0.6   \n",
       "2                                    -1.4   \n",
       "3                                     0.0   \n",
       "4                                     1.0   \n",
       "\n",
       "   away_team_overall_mean_goal_difference  head_to_head_goal_difference  \n",
       "0                                     0.2                             7  \n",
       "1                                     1.2                             1  \n",
       "2                                     0.2                             8  \n",
       "3                                     0.6                             1  \n",
       "4                                     0.0                             3  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns = [\n",
    "\t\"home_goals\", \"away_goals\", \"home_shots\", \"away_shots\", \"home_shots_on_target\", \"away_shots_on_target\",\n",
    "\t\"home_corners\", \"away_corners\", \"home_fouls\", \"away_fouls\", \"home_yellow_cards\", \"away_yellow_cards\",\n",
    "\t\"home_red_cards\", \"away_red_cards\"\n",
    "]\n",
    "match_columns = [\n",
    "\t\"match_id\", \"competition_id\", \"home_team_id\", \"away_team_id\", \"referee_id\",\n",
    "\t\"home_goals\", \"away_goals\", \"home_shots\", \"away_shots\", \"home_shots_on_target\", \"away_shots_on_target\",\n",
    "\t\"home_corners\", \"away_corners\", \"home_fouls\", \"away_fouls\", \"home_yellow_cards\", \"away_yellow_cards\",\n",
    "\t\"home_red_cards\", \"away_red_cards\"\n",
    "]\n",
    "stats_columns = [\n",
    "\t\"goals\",\"assists\",\"penalties_scored\",\"penalties_attempted\",\"yellow_cards\",\"red_cards\",\"expected_goals\",\n",
    "\t\"non_penalty_expected_goals\",\"expected_assisted_goals\",\"progressive_carries\",\"progressive_passes\",\"total_passing_distance\",\n",
    "\t\"total_progressive_passing_distance\",\"short_passes_completed\",\"short_passes_attempted\",\"medium_passes_completed\",\n",
    "\t\"medium_passes_attempted\",\"long_passes_completed\",\"long_passes_attempted\",\"expected_assists\",\"key_passes\",\n",
    "\t\"passes_into_final_third\",\"passes_into_penalty_area\",\"crosses_into_penalty_area\",\"shots\",\"shots_on_target\",\n",
    "\t\"average_shot_distance\",\"shots_from_free_kicks\",\"touches_in_defensive_penalty_area\",\"touches_in_defensive_third\",\n",
    "\t\"touches_in_middle_third\",\"touches_in_attacking_third\",\"touches_in_attacking_penalty_area\",\"live_ball_touches\",\n",
    "\t\"take_ons_attempted\",\"take_ons_succeeded\",\"carries\",\"total_carrying_distance\",\"progressive_carrying_distance\",\n",
    "\t\"carries_into_final_third\",\"carries_into_penalty_area\",\"miscontrols\",\"dispossessed\",\"passes_received\",\n",
    "\t\"progressive_passes_received\",\"tackles_won\",\"defensive_third_tackles\",\"middle_third_tackles\",\"attacking_third_tackles\",\n",
    "\t\"dribblers_tackled\",\"dribbler_tackles_attempted\",\"shots_blocked\",\"passes_blocked\",\"interceptions\",\"clearances\",\n",
    "\t\"errors_leading_to_shot\",\"goals_against\",\"shots_on_target_against\",\"saves\",\"clean_sheets\",\"penalties_faced\",\n",
    "\t\"penalties_allowed\",\"penalties_saved\",\"penalties_missed\"\n",
    "]\n",
    "player_stats_columns = [\"player_id\", \"minutes_played\",\"ninetys\"] + stats_columns\n",
    "pure_stats_columns = [\"minutes_played\"] + stats_columns\n",
    "team_stats_columns = [\"team_id\"] + stats_columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_standardized = scaler.fit_transform(combined[stats_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evr = {}\n",
    "n_components = {}\n",
    "feature_to_pc = {}\n",
    "\n",
    "for n in range(1,26):\n",
    "\tpca = PCA(n_components = n, random_state=938)\n",
    "\tpca.fit(combined_standardized)\n",
    "\tfeature_to_pc_map = pd.DataFrame(pca.components_, columns=stats_columns)\n",
    "\tcomponents = pca.transform(combined_standardized)\n",
    "\tcomponents_df = pd.DataFrame(data=components[:, [p for p in range(n)]], columns=pca.get_feature_names_out(), )\n",
    "\t\n",
    "\tevr[n] = sum(pca.explained_variance_ratio_)\n",
    "\tn_components[n] = components_df\n",
    "\tfeature_to_pc[n] = feature_to_pc_map\n",
    "\n",
    "pd.DataFrame(data=evr, index=[\"explained_variance_ratio\"]).T\n",
    "feature_to_pc[15].to_csv(\"../files/feature_to_15_pcs.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the effect of different numbers if PCs on the outcome of the NN, testing n=2, 5 and 10. Use each n components to train and test the neural network, and compare the performance of each one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = len(stats_columns)\n",
    "OUTPUT_SIZE = 14\n",
    "ROWS = 1927"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 01:08:33.185389: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 713us/step - loss: 41.0263 - accuracy: 0.4450\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 516us/step - loss: 26.6967 - accuracy: 0.4740\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 531us/step - loss: 12.8823 - accuracy: 0.4740\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 9.0366 - accuracy: 0.4740\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 8.7446 - accuracy: 0.4740\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 8.8324 - accuracy: 0.4740\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 8.7403 - accuracy: 0.4740\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 8.5990 - accuracy: 0.4740\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 8.6086 - accuracy: 0.4740\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 8.7018 - accuracy: 0.4740\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 8.5559 - accuracy: 0.4740\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 8.5847 - accuracy: 0.4740\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 8.4977 - accuracy: 0.4740\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 8.5235 - accuracy: 0.4740\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 8.5561 - accuracy: 0.4740\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 8.4876 - accuracy: 0.4740\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 8.5267 - accuracy: 0.4746\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 8.5013 - accuracy: 0.4740\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 8.5141 - accuracy: 0.4746\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 8.5214 - accuracy: 0.4775\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 8.5016 - accuracy: 0.4770\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 465us/step - loss: 8.4958 - accuracy: 0.4770\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 550us/step - loss: 8.4874 - accuracy: 0.4805\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 927us/step - loss: 8.4876 - accuracy: 0.4793\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 633us/step - loss: 8.4885 - accuracy: 0.4758\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 562us/step - loss: 8.4832 - accuracy: 0.4775\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 615us/step - loss: 8.4664 - accuracy: 0.4787\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 717us/step - loss: 8.4737 - accuracy: 0.4781\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 602us/step - loss: 8.4842 - accuracy: 0.4770\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 604us/step - loss: 8.4769 - accuracy: 0.4864\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 521us/step - loss: 8.4851 - accuracy: 0.4793\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.5075 - accuracy: 0.4823\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 837us/step - loss: 8.4713 - accuracy: 0.4799\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 780us/step - loss: 8.4847 - accuracy: 0.4787\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 594us/step - loss: 8.5061 - accuracy: 0.4811\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 8.4860 - accuracy: 0.4829\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 548us/step - loss: 8.4631 - accuracy: 0.4793\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 544us/step - loss: 8.4712 - accuracy: 0.4846\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 569us/step - loss: 8.4786 - accuracy: 0.4805\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 8.4781 - accuracy: 0.4781\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 515us/step - loss: 8.5284 - accuracy: 0.4835\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 546us/step - loss: 8.4755 - accuracy: 0.4829\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 8.4679 - accuracy: 0.4817\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 8.4707 - accuracy: 0.4829\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 8.4678 - accuracy: 0.4823\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 8.4661 - accuracy: 0.4811\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 8.4628 - accuracy: 0.4840\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 8.4732 - accuracy: 0.4817\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 8.4695 - accuracy: 0.4876\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.4593 - accuracy: 0.4840\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 521us/step - loss: 8.4606 - accuracy: 0.4811\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 8.4708 - accuracy: 0.4846\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 8.4614 - accuracy: 0.4817\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 8.4705 - accuracy: 0.4835\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 8.4538 - accuracy: 0.4840\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 489us/step - loss: 8.4544 - accuracy: 0.4793\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 8.4838 - accuracy: 0.4888\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 8.4520 - accuracy: 0.4817\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 8.4597 - accuracy: 0.4840\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 8.4525 - accuracy: 0.4846\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 8.4454 - accuracy: 0.4781\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 611us/step - loss: 8.4488 - accuracy: 0.4805\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 964us/step - loss: 8.4484 - accuracy: 0.4805\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 582us/step - loss: 8.4600 - accuracy: 0.4858\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 598us/step - loss: 8.4606 - accuracy: 0.4793\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 505us/step - loss: 8.4634 - accuracy: 0.4840\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 639us/step - loss: 8.4510 - accuracy: 0.4864\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 517us/step - loss: 8.4535 - accuracy: 0.4799\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 462us/step - loss: 8.4567 - accuracy: 0.4799\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 521us/step - loss: 8.4576 - accuracy: 0.4823\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 505us/step - loss: 8.4468 - accuracy: 0.4876\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 537us/step - loss: 8.4642 - accuracy: 0.4864\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 636us/step - loss: 8.4432 - accuracy: 0.4829\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 814us/step - loss: 8.4601 - accuracy: 0.4835\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 8.4593 - accuracy: 0.4823\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.4527 - accuracy: 0.4811\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 8.4423 - accuracy: 0.4829\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 472us/step - loss: 8.4616 - accuracy: 0.4805\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 490us/step - loss: 8.4561 - accuracy: 0.4876\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 8.4599 - accuracy: 0.4840\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 474us/step - loss: 8.4649 - accuracy: 0.4870\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 8.4576 - accuracy: 0.4817\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 8.4834 - accuracy: 0.4846\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 602us/step - loss: 8.4521 - accuracy: 0.4852\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 511us/step - loss: 8.4460 - accuracy: 0.4846\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 8.4545 - accuracy: 0.4852\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 504us/step - loss: 8.4488 - accuracy: 0.4835\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 8.4654 - accuracy: 0.4840\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.4488 - accuracy: 0.4870\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.4503 - accuracy: 0.4829\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 695us/step - loss: 8.4499 - accuracy: 0.4823\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 698us/step - loss: 8.4489 - accuracy: 0.4870\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 513us/step - loss: 8.4363 - accuracy: 0.4894\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 520us/step - loss: 8.4406 - accuracy: 0.4829\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 539us/step - loss: 8.4505 - accuracy: 0.4870\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 508us/step - loss: 8.4463 - accuracy: 0.4823\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 509us/step - loss: 8.4498 - accuracy: 0.4811\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 682us/step - loss: 8.4471 - accuracy: 0.4876\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 8.4373 - accuracy: 0.4840\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 8.4533 - accuracy: 0.4787\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 498us/step - loss: 8.4395 - accuracy: 0.4864\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 8.4502 - accuracy: 0.4864\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 8.4376 - accuracy: 0.4864\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 8.4447 - accuracy: 0.4846\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 8.4492 - accuracy: 0.4840\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 8.4457 - accuracy: 0.4888\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 509us/step - loss: 8.4468 - accuracy: 0.4858\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 8.4462 - accuracy: 0.4829\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 8.4443 - accuracy: 0.4846\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 617us/step - loss: 8.4466 - accuracy: 0.4846\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 571us/step - loss: 8.4453 - accuracy: 0.4864\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 500us/step - loss: 8.4485 - accuracy: 0.4858\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 546us/step - loss: 8.4456 - accuracy: 0.4840\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 563us/step - loss: 8.4472 - accuracy: 0.4894\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 728us/step - loss: 8.4405 - accuracy: 0.4840\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.4392 - accuracy: 0.4870\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 727us/step - loss: 8.4434 - accuracy: 0.4858\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 632us/step - loss: 8.4404 - accuracy: 0.4894\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 548us/step - loss: 8.4373 - accuracy: 0.4852\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 663us/step - loss: 8.4419 - accuracy: 0.4846\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 496us/step - loss: 8.4405 - accuracy: 0.4876\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 491us/step - loss: 8.4426 - accuracy: 0.4870\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 472us/step - loss: 8.4404 - accuracy: 0.4864\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 622us/step - loss: 8.4330 - accuracy: 0.4870\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 680us/step - loss: 8.4364 - accuracy: 0.4846\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 648us/step - loss: 8.4326 - accuracy: 0.4882\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 484us/step - loss: 8.4456 - accuracy: 0.4852\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 455us/step - loss: 8.4347 - accuracy: 0.4852\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 458us/step - loss: 8.4438 - accuracy: 0.4870\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 8.4445 - accuracy: 0.4858\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 8.4433 - accuracy: 0.4870\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 8.4394 - accuracy: 0.4858\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 8.4381 - accuracy: 0.4882\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 8.4344 - accuracy: 0.4840\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 8.4321 - accuracy: 0.4858\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 8.4347 - accuracy: 0.4882\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 8.4377 - accuracy: 0.4823\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 8.4353 - accuracy: 0.4870\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 8.4403 - accuracy: 0.4864\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 8.4415 - accuracy: 0.4864\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 8.4426 - accuracy: 0.4846\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 8.4377 - accuracy: 0.4858\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 8.4469 - accuracy: 0.4858\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 8.4436 - accuracy: 0.4876\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 8.4362 - accuracy: 0.4846\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 450us/step - loss: 8.4375 - accuracy: 0.4882\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 8.4283 - accuracy: 0.4870\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 8.4372 - accuracy: 0.4829\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 8.4332 - accuracy: 0.4852\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 8.4380 - accuracy: 0.4864\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 8.4251 - accuracy: 0.4858\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 8.4355 - accuracy: 0.4852\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 8.4300 - accuracy: 0.4864\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 8.4303 - accuracy: 0.4846\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 8.4379 - accuracy: 0.4864\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 8.4366 - accuracy: 0.4882\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 594us/step - loss: 8.4367 - accuracy: 0.4840\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 8.4315 - accuracy: 0.4876\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 533us/step - loss: 8.4400 - accuracy: 0.4846\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 8.4317 - accuracy: 0.4882\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 8.4337 - accuracy: 0.4905\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 8.4336 - accuracy: 0.4870\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 8.4327 - accuracy: 0.4882\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 8.4281 - accuracy: 0.4870\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 8.4270 - accuracy: 0.4858\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 8.4351 - accuracy: 0.4864\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 8.4359 - accuracy: 0.4876\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.4259 - accuracy: 0.4870\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 8.4326 - accuracy: 0.4876\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 8.4306 - accuracy: 0.4876\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 8.4318 - accuracy: 0.4870\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 8.4367 - accuracy: 0.4876\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 511us/step - loss: 8.4276 - accuracy: 0.4870\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 8.4320 - accuracy: 0.4888\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 8.4300 - accuracy: 0.4840\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 942us/step - loss: 8.4265 - accuracy: 0.4870\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 8.4289 - accuracy: 0.4870\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 8.4356 - accuracy: 0.4876\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 8.4267 - accuracy: 0.4870\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 8.4236 - accuracy: 0.4864\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 8.4294 - accuracy: 0.4864\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 8.4270 - accuracy: 0.4870\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 8.4338 - accuracy: 0.4858\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 8.4299 - accuracy: 0.4846\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 8.4252 - accuracy: 0.4876\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 8.4269 - accuracy: 0.4870\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 8.4260 - accuracy: 0.4888\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 8.4267 - accuracy: 0.4882\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 8.4183 - accuracy: 0.4882\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 485us/step - loss: 8.4233 - accuracy: 0.4870\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 8.4272 - accuracy: 0.4829\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 8.4233 - accuracy: 0.4840\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 684us/step - loss: 8.4323 - accuracy: 0.4852\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 8.4263 - accuracy: 0.4858\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 8.4249 - accuracy: 0.4846\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 8.4267 - accuracy: 0.4864\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 8.4334 - accuracy: 0.4888\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 8.4258 - accuracy: 0.4817\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 8.4189 - accuracy: 0.4864\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 8.4211 - accuracy: 0.4876\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 8.4176 - accuracy: 0.4864\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 8.4127 - accuracy: 0.4852\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 8.4287 - accuracy: 0.4852\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 680us/step - loss: 8.4245 - accuracy: 0.4923\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.4244 - accuracy: 0.4894\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 686us/step - loss: 8.4279 - accuracy: 0.4882\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 666us/step - loss: 8.4202 - accuracy: 0.4876\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 651us/step - loss: 8.4225 - accuracy: 0.4846\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 520us/step - loss: 8.4151 - accuracy: 0.4864\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 8.4148 - accuracy: 0.4876\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 829us/step - loss: 8.4287 - accuracy: 0.4852\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 845us/step - loss: 8.4154 - accuracy: 0.4870\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 631us/step - loss: 8.4223 - accuracy: 0.4864\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 8.4170 - accuracy: 0.4905\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 8.4196 - accuracy: 0.4882\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 527us/step - loss: 8.4135 - accuracy: 0.4882\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 8.4183 - accuracy: 0.4858\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 8.4261 - accuracy: 0.4852\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 788us/step - loss: 8.4146 - accuracy: 0.4870\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.4087 - accuracy: 0.4846\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.4173 - accuracy: 0.4864\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 602us/step - loss: 8.4249 - accuracy: 0.4870\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 777us/step - loss: 8.4198 - accuracy: 0.4882\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 535us/step - loss: 8.4179 - accuracy: 0.4882\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 497us/step - loss: 8.4134 - accuracy: 0.4894\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 507us/step - loss: 8.4194 - accuracy: 0.4882\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 515us/step - loss: 8.4157 - accuracy: 0.4882\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 601us/step - loss: 8.4200 - accuracy: 0.4852\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 0s 596us/step - loss: 8.4172 - accuracy: 0.4864\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 0s 576us/step - loss: 8.4112 - accuracy: 0.4864\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 618us/step - loss: 8.4093 - accuracy: 0.4876\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 8.4198 - accuracy: 0.4894\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 8.4133 - accuracy: 0.4864\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 535us/step - loss: 8.4198 - accuracy: 0.4888\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 533us/step - loss: 8.4069 - accuracy: 0.4852\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.4182 - accuracy: 0.4840\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 585us/step - loss: 8.4120 - accuracy: 0.4870\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 8.4136 - accuracy: 0.4852\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 8.4236 - accuracy: 0.4876\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 8.4079 - accuracy: 0.4858\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 750us/step - loss: 8.4081 - accuracy: 0.4911\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 8.4199 - accuracy: 0.4852\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 491us/step - loss: 8.4135 - accuracy: 0.4870\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 8.4102 - accuracy: 0.4888\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 593us/step - loss: 8.4179 - accuracy: 0.4894\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 546us/step - loss: 8.4127 - accuracy: 0.4864\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 511us/step - loss: 8.4153 - accuracy: 0.4876\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 8.4105 - accuracy: 0.4864\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8.4096 - accuracy: 0.4852\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 600us/step - loss: 8.4140 - accuracy: 0.4876\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 696us/step - loss: 8.4159 - accuracy: 0.4870\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 682us/step - loss: 8.4204 - accuracy: 0.4846\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 477us/step - loss: 8.4105 - accuracy: 0.4864\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 8.4159 - accuracy: 0.4858\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 8.4086 - accuracy: 0.4858\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 8.4123 - accuracy: 0.4876\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 8.4133 - accuracy: 0.4894\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 8.4093 - accuracy: 0.4864\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 8.4084 - accuracy: 0.4876\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 595us/step - loss: 8.4021 - accuracy: 0.4870\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 596us/step - loss: 8.4117 - accuracy: 0.4858\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.4088 - accuracy: 0.4882\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 646us/step - loss: 8.4078 - accuracy: 0.4888\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 452us/step - loss: 8.4086 - accuracy: 0.4864\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 8.4035 - accuracy: 0.4905\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 8.4070 - accuracy: 0.4888\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 8.4061 - accuracy: 0.4894\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 8.4128 - accuracy: 0.4882\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 525us/step - loss: 8.3988 - accuracy: 0.4870\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 907us/step - loss: 8.4000 - accuracy: 0.4882\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 8.4026 - accuracy: 0.4888\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 479us/step - loss: 8.4071 - accuracy: 0.4888\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 516us/step - loss: 8.4030 - accuracy: 0.4894\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 456us/step - loss: 8.4068 - accuracy: 0.4894\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 8.4060 - accuracy: 0.4876\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 8.4033 - accuracy: 0.4870\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 8.4028 - accuracy: 0.4888\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 8.4080 - accuracy: 0.4888\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 936us/step - loss: 8.4051 - accuracy: 0.4846\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 894us/step - loss: 8.4057 - accuracy: 0.4840\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 8.4061 - accuracy: 0.4864\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 8.4008 - accuracy: 0.4870\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 8.4124 - accuracy: 0.4888\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 492us/step - loss: 8.4039 - accuracy: 0.4858\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 697us/step - loss: 8.4020 - accuracy: 0.4864\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 565us/step - loss: 8.4053 - accuracy: 0.4900\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 8.3994 - accuracy: 0.4876\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 496us/step - loss: 8.4087 - accuracy: 0.4840\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 8.3972 - accuracy: 0.4876\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 556us/step - loss: 8.4024 - accuracy: 0.4882\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 473us/step - loss: 8.4027 - accuracy: 0.4858\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 473us/step - loss: 8.4052 - accuracy: 0.4900\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 8.3994 - accuracy: 0.4894\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 8.4005 - accuracy: 0.4876\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 8.4017 - accuracy: 0.4870\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 470us/step - loss: 8.4056 - accuracy: 0.4911\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 8.3975 - accuracy: 0.4900\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 8.3972 - accuracy: 0.4888\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 8.4033 - accuracy: 0.4870\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 879us/step - loss: 8.4006 - accuracy: 0.4888\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 455us/step - loss: 8.4018 - accuracy: 0.4876\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 8.4033 - accuracy: 0.4864\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 8.3979 - accuracy: 0.4882\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 8.3943 - accuracy: 0.4888\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 676us/step - loss: 8.3963 - accuracy: 0.4864\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 516us/step - loss: 8.4042 - accuracy: 0.4870\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 0s 452us/step - loss: 8.3949 - accuracy: 0.4888\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 0s 538us/step - loss: 8.3874 - accuracy: 0.4917\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 8.3882 - accuracy: 0.4894\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 8.3951 - accuracy: 0.4882\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 8.3882 - accuracy: 0.4852\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 8.3988 - accuracy: 0.4870\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 468us/step - loss: 8.4033 - accuracy: 0.4864\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 8.3950 - accuracy: 0.4882\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 8.4030 - accuracy: 0.4864\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 8.3977 - accuracy: 0.4882\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 8.3937 - accuracy: 0.4870\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 8.4049 - accuracy: 0.4835\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 8.3962 - accuracy: 0.4870\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 8.3959 - accuracy: 0.4846\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 8.3977 - accuracy: 0.4876\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 8.3937 - accuracy: 0.4858\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 653us/step - loss: 8.3924 - accuracy: 0.4876\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 8.3990 - accuracy: 0.4846\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 8.3995 - accuracy: 0.4876\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 8.3882 - accuracy: 0.4876\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 8.3875 - accuracy: 0.4882\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 8.3961 - accuracy: 0.4852\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 8.3888 - accuracy: 0.4870\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 8.3957 - accuracy: 0.4876\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 8.3912 - accuracy: 0.4882\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 8.3921 - accuracy: 0.4864\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 363us/step - loss: 8.3855 - accuracy: 0.4876\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 354us/step - loss: 8.3973 - accuracy: 0.4876\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 8.3935 - accuracy: 0.4870\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 370us/step - loss: 8.3902 - accuracy: 0.4894\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 603us/step - loss: 8.3952 - accuracy: 0.4882\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.3938 - accuracy: 0.4864\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 525us/step - loss: 8.3884 - accuracy: 0.4846\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 8.3882 - accuracy: 0.4888\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 8.3931 - accuracy: 0.4882\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 8.3879 - accuracy: 0.4876\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 8.3927 - accuracy: 0.4864\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 8.3879 - accuracy: 0.4876\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 8.3816 - accuracy: 0.4858\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 8.3904 - accuracy: 0.4905\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 8.3864 - accuracy: 0.4852\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 8.3984 - accuracy: 0.4905\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 8.3904 - accuracy: 0.4852\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 8.3885 - accuracy: 0.4882\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 8.3891 - accuracy: 0.4858\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 8.3860 - accuracy: 0.4858\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 708us/step - loss: 8.3950 - accuracy: 0.4864\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 8.3864 - accuracy: 0.4900\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 8.3861 - accuracy: 0.4840\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 516us/step - loss: 8.3830 - accuracy: 0.4900\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 8.3878 - accuracy: 0.4876\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 8.3874 - accuracy: 0.4852\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 8.3822 - accuracy: 0.4864\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 8.3896 - accuracy: 0.4905\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 8.3822 - accuracy: 0.4888\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 8.3898 - accuracy: 0.4870\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 8.3834 - accuracy: 0.4882\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 8.3837 - accuracy: 0.4823\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 8.3808 - accuracy: 0.4846\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 8.3987 - accuracy: 0.4840\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 8.3939 - accuracy: 0.4852\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 575us/step - loss: 8.3796 - accuracy: 0.4852\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 458us/step - loss: 8.3793 - accuracy: 0.4852\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 796us/step - loss: 8.3885 - accuracy: 0.4864\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 634us/step - loss: 8.3900 - accuracy: 0.4876\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 8.3882 - accuracy: 0.4852\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 8.3797 - accuracy: 0.4894\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 8.3822 - accuracy: 0.4870\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 8.3926 - accuracy: 0.4882\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 8.3860 - accuracy: 0.4840\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 521us/step - loss: 8.3913 - accuracy: 0.4852\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 458us/step - loss: 8.3872 - accuracy: 0.4876\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 8.3837 - accuracy: 0.4905\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 8.3766 - accuracy: 0.4882\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 8.3797 - accuracy: 0.4864\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 8.3839 - accuracy: 0.4905\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 478us/step - loss: 8.3797 - accuracy: 0.4870\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 492us/step - loss: 8.3824 - accuracy: 0.4870\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 8.3798 - accuracy: 0.4858\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 8.3771 - accuracy: 0.4894\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 8.3849 - accuracy: 0.4870\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 8.3863 - accuracy: 0.4888\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 8.3814 - accuracy: 0.4888\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 8.3840 - accuracy: 0.4894\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 8.3799 - accuracy: 0.4905\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 8.3812 - accuracy: 0.4900\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 444us/step - loss: 8.3833 - accuracy: 0.4882\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 8.3883 - accuracy: 0.4876\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 8.3736 - accuracy: 0.4876\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 8.3869 - accuracy: 0.4894\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 8.3762 - accuracy: 0.4882\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 8.3814 - accuracy: 0.4876\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 8.3737 - accuracy: 0.4876\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 8.3777 - accuracy: 0.4876\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 8.3778 - accuracy: 0.4876\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 863us/step - loss: 8.3827 - accuracy: 0.4852\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 8.3821 - accuracy: 0.4858\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 8.3852 - accuracy: 0.4870\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8.3885 - accuracy: 0.4858\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 623us/step - loss: 8.3787 - accuracy: 0.4876\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 463us/step - loss: 8.3877 - accuracy: 0.4870\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 8.3780 - accuracy: 0.4876\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 8.3784 - accuracy: 0.4870\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 8.3840 - accuracy: 0.4882\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 8.3738 - accuracy: 0.4888\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 8.3865 - accuracy: 0.4882\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 8.3739 - accuracy: 0.4894\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 450us/step - loss: 8.3771 - accuracy: 0.4864\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 8.3844 - accuracy: 0.4888\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 8.3791 - accuracy: 0.4888\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 8.3847 - accuracy: 0.4876\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 8.3806 - accuracy: 0.4911\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 8.3844 - accuracy: 0.4864\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 8.3809 - accuracy: 0.4882\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 8.3810 - accuracy: 0.4882\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 8.3791 - accuracy: 0.4852\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 8.3802 - accuracy: 0.4888\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 588us/step - loss: 8.3751 - accuracy: 0.4876\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 496us/step - loss: 8.3819 - accuracy: 0.4894\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 8.3775 - accuracy: 0.4876\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 452us/step - loss: 8.3734 - accuracy: 0.4894\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 8.3785 - accuracy: 0.4864\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 8.3799 - accuracy: 0.4870\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 8.3791 - accuracy: 0.4894\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 8.3762 - accuracy: 0.4864\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.3677 - accuracy: 0.4835\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 8.3727 - accuracy: 0.4876\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 8.3793 - accuracy: 0.4870\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 8.3755 - accuracy: 0.4852\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 8.3752 - accuracy: 0.4870\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 8.3856 - accuracy: 0.4888\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 8.3742 - accuracy: 0.4876\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 8.3862 - accuracy: 0.4876\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 437us/step - loss: 8.3756 - accuracy: 0.4864\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 8.3736 - accuracy: 0.4829\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 8.3723 - accuracy: 0.4876\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 621us/step - loss: 8.3793 - accuracy: 0.4882\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 504us/step - loss: 8.3824 - accuracy: 0.4911\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 444us/step - loss: 8.3795 - accuracy: 0.4858\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 8.3721 - accuracy: 0.4888\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 8.3680 - accuracy: 0.4882\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 8.3773 - accuracy: 0.4888\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 472us/step - loss: 8.3748 - accuracy: 0.4864\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 8.3870 - accuracy: 0.4817\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 8.3749 - accuracy: 0.4876\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 458us/step - loss: 8.3691 - accuracy: 0.4882\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 8.3807 - accuracy: 0.4864\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 506us/step - loss: 8.3689 - accuracy: 0.4846\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 515us/step - loss: 8.3798 - accuracy: 0.4870\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 658us/step - loss: 8.3685 - accuracy: 0.4858\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 600us/step - loss: 8.3747 - accuracy: 0.4864\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 497us/step - loss: 8.3742 - accuracy: 0.4852\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 661us/step - loss: 8.3733 - accuracy: 0.4876\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 507us/step - loss: 8.3800 - accuracy: 0.4882\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 8.3806 - accuracy: 0.4864\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 437us/step - loss: 8.3799 - accuracy: 0.4870\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.3855 - accuracy: 0.4876\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 8.3745 - accuracy: 0.4864\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 378us/step - loss: 8.3743 - accuracy: 0.4846\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 8.3732 - accuracy: 0.4835\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 8.3712 - accuracy: 0.4882\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 8.3772 - accuracy: 0.4876\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 8.3755 - accuracy: 0.4858\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 8.3701 - accuracy: 0.4858\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 8.3671 - accuracy: 0.4870\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 8.3780 - accuracy: 0.4864\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 8.3728 - accuracy: 0.4905\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 8.3774 - accuracy: 0.4858\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 8.3714 - accuracy: 0.4911\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 8.3765 - accuracy: 0.4882\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 8.3731 - accuracy: 0.4876\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 8.3760 - accuracy: 0.4882\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 8.3801 - accuracy: 0.4846\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 8.3744 - accuracy: 0.4840\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 8.3749 - accuracy: 0.4829\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 8.3726 - accuracy: 0.4888\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 527us/step - loss: 8.3747 - accuracy: 0.4852\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 512us/step - loss: 8.3804 - accuracy: 0.4894\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 8.3695 - accuracy: 0.4846\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 8.3732 - accuracy: 0.4876\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 473us/step - loss: 8.3741 - accuracy: 0.4864\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 8.3640 - accuracy: 0.4894\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 478us/step - loss: 8.3723 - accuracy: 0.4840\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 524us/step - loss: 8.3693 - accuracy: 0.4870\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 511us/step - loss: 8.3725 - accuracy: 0.4858\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 8.3616 - accuracy: 0.4894\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 8.3855 - accuracy: 0.4870\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 8.3793 - accuracy: 0.4882\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 8.3797 - accuracy: 0.4852\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 548us/step - loss: 8.3675 - accuracy: 0.4864\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 8.3707 - accuracy: 0.4858\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 8.3750 - accuracy: 0.4894\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 8.3676 - accuracy: 0.4911\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 784us/step - loss: 8.3685 - accuracy: 0.4876\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(len(X_train.columns), activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 414us/step\n",
      "[ 1.2126752   1.6975286  11.337424   13.793308    3.9474387   5.082057\n",
      "  4.645624    5.4389553  10.37679    10.253022    1.7802657   1.5439035\n",
      "  0.04401858  0.05191425]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>home_shots</th>\n",
       "      <th>away_shots</th>\n",
       "      <th>home_shots_on_target</th>\n",
       "      <th>away_shots_on_target</th>\n",
       "      <th>home_corners</th>\n",
       "      <th>away_corners</th>\n",
       "      <th>home_fouls</th>\n",
       "      <th>away_fouls</th>\n",
       "      <th>home_yellow_cards</th>\n",
       "      <th>away_yellow_cards</th>\n",
       "      <th>home_red_cards</th>\n",
       "      <th>away_red_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_goals  away_goals  home_shots  away_shots  home_shots_on_target  \\\n",
       "1634           2           1          13          16                     4   \n",
       "1479           2           4          16          15                     6   \n",
       "25             2           1           6          23                     2   \n",
       "1686           2           1          12          17                     4   \n",
       "1454           1           3           9          15                     3   \n",
       "\n",
       "      away_shots_on_target  home_corners  away_corners  home_fouls  \\\n",
       "1634                     3             3             5           8   \n",
       "1479                     9             3             3          13   \n",
       "25                       6             4             8          14   \n",
       "1686                     5             6             8          11   \n",
       "1454                     7             3             8           8   \n",
       "\n",
       "      away_fouls  home_yellow_cards  away_yellow_cards  home_red_cards  \\\n",
       "1634          10                  1                  1               0   \n",
       "1479          19                  6                  3               0   \n",
       "25            11                  4                  2               0   \n",
       "1686           7                  3                  1               0   \n",
       "1454          15                  0                  2               0   \n",
       "\n",
       "      away_red_cards  \n",
       "1634               0  \n",
       "1479               0  \n",
       "25                 0  \n",
       "1686               0  \n",
       "1454               0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=5\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/34 [==============================] - 0s 490us/step - loss: 28.6081 - accuracy: 0.4178\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 16.5957 - accuracy: 0.4740\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 12.0450 - accuracy: 0.4740\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 839us/step - loss: 9.9899 - accuracy: 0.4740\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 545us/step - loss: 9.0152 - accuracy: 0.4900\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 8.4597 - accuracy: 0.5296\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 8.1596 - accuracy: 0.5437\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 8.1780 - accuracy: 0.5414\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 509us/step - loss: 7.7837 - accuracy: 0.5461\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7.8060 - accuracy: 0.5485\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 452us/step - loss: 7.5684 - accuracy: 0.5414\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 7.5822 - accuracy: 0.5437\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 7.6463 - accuracy: 0.5390\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.5849 - accuracy: 0.5414\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 7.5316 - accuracy: 0.5443\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 7.5478 - accuracy: 0.5473\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 7.5419 - accuracy: 0.5514\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 7.5476 - accuracy: 0.5455\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 7.5419 - accuracy: 0.5473\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 7.4911 - accuracy: 0.5408\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 572us/step - loss: 7.4213 - accuracy: 0.5461\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 544us/step - loss: 7.4161 - accuracy: 0.5473\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 7.5562 - accuracy: 0.5437\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.4232 - accuracy: 0.5532\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7.4173 - accuracy: 0.5485\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.4264 - accuracy: 0.5473\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 7.4369 - accuracy: 0.5431\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 7.4425 - accuracy: 0.5461\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 7.3941 - accuracy: 0.5437\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 7.4189 - accuracy: 0.5467\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 7.4245 - accuracy: 0.5473\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 7.4089 - accuracy: 0.5467\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 7.4342 - accuracy: 0.5502\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 7.3662 - accuracy: 0.5514\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 7.4467 - accuracy: 0.5426\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 7.4353 - accuracy: 0.5449\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 7.3606 - accuracy: 0.5449\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 632us/step - loss: 7.3649 - accuracy: 0.5496\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 558us/step - loss: 7.3967 - accuracy: 0.5449\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.3770 - accuracy: 0.5473\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 7.3593 - accuracy: 0.5467\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 7.3702 - accuracy: 0.5420\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7.3556 - accuracy: 0.5431\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 7.3891 - accuracy: 0.5479\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 7.3860 - accuracy: 0.5443\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 7.3427 - accuracy: 0.5443\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.3991 - accuracy: 0.5502\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.3495 - accuracy: 0.5485\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 7.3882 - accuracy: 0.5485\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 7.3676 - accuracy: 0.5390\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.3634 - accuracy: 0.5437\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 608us/step - loss: 7.3869 - accuracy: 0.5455\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 567us/step - loss: 7.3568 - accuracy: 0.5455\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 663us/step - loss: 7.3610 - accuracy: 0.5449\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 697us/step - loss: 7.3375 - accuracy: 0.5502\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7.3365 - accuracy: 0.5479\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 7.3575 - accuracy: 0.5496\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 484us/step - loss: 7.3327 - accuracy: 0.5467\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 490us/step - loss: 7.3669 - accuracy: 0.5431\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 485us/step - loss: 7.3333 - accuracy: 0.5455\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 7.3348 - accuracy: 0.5609\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 7.3193 - accuracy: 0.5491\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 7.3274 - accuracy: 0.5520\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 7.3220 - accuracy: 0.5496\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.3233 - accuracy: 0.5473\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 7.3195 - accuracy: 0.5479\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.3482 - accuracy: 0.5467\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 372us/step - loss: 7.3320 - accuracy: 0.5443\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7.3258 - accuracy: 0.5443\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7.3280 - accuracy: 0.5461\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 776us/step - loss: 7.3288 - accuracy: 0.5508\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 534us/step - loss: 7.3278 - accuracy: 0.5467\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 7.3448 - accuracy: 0.5496\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.3000 - accuracy: 0.5491\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.3185 - accuracy: 0.5461\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 377us/step - loss: 7.3182 - accuracy: 0.5491\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.3006 - accuracy: 0.5449\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 7.3103 - accuracy: 0.5455\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 7.3064 - accuracy: 0.5496\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 374us/step - loss: 7.3053 - accuracy: 0.5473\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.2957 - accuracy: 0.5467\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.3152 - accuracy: 0.5491\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 7.2933 - accuracy: 0.5485\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 7.3080 - accuracy: 0.5479\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 467us/step - loss: 7.3004 - accuracy: 0.5420\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 7.3015 - accuracy: 0.5449\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 7.3108 - accuracy: 0.5508\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.3112 - accuracy: 0.5491\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 7.2877 - accuracy: 0.5491\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 7.3017 - accuracy: 0.5449\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 7.2939 - accuracy: 0.5473\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 7.2774 - accuracy: 0.5467\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 7.3198 - accuracy: 0.5485\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 7.2861 - accuracy: 0.5491\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 455us/step - loss: 7.2861 - accuracy: 0.5455\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 547us/step - loss: 7.2800 - accuracy: 0.5461\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 517us/step - loss: 7.3005 - accuracy: 0.5508\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 504us/step - loss: 7.3083 - accuracy: 0.5449\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 515us/step - loss: 7.3021 - accuracy: 0.5485\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 535us/step - loss: 7.2920 - accuracy: 0.5467\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 7.2888 - accuracy: 0.5526\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.2847 - accuracy: 0.5520\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 7.3043 - accuracy: 0.5467\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 461us/step - loss: 7.2822 - accuracy: 0.5443\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 374us/step - loss: 7.2896 - accuracy: 0.5491\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.2836 - accuracy: 0.5508\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 7.2817 - accuracy: 0.5479\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 7.2751 - accuracy: 0.5479\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 7.2665 - accuracy: 0.5467\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.3040 - accuracy: 0.5508\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.3025 - accuracy: 0.5437\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 7.2968 - accuracy: 0.5514\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7.2802 - accuracy: 0.5496\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.3048 - accuracy: 0.5502\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 7.2942 - accuracy: 0.5526\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 7.3020 - accuracy: 0.5502\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 7.2791 - accuracy: 0.5467\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 584us/step - loss: 7.2668 - accuracy: 0.5467\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 594us/step - loss: 7.2892 - accuracy: 0.5485\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 501us/step - loss: 7.2758 - accuracy: 0.5502\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 489us/step - loss: 7.2923 - accuracy: 0.5520\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 506us/step - loss: 7.2764 - accuracy: 0.5514\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 7.2934 - accuracy: 0.5508\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 606us/step - loss: 7.2895 - accuracy: 0.5491\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 594us/step - loss: 7.2654 - accuracy: 0.5514\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 560us/step - loss: 7.2681 - accuracy: 0.5532\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 522us/step - loss: 7.2851 - accuracy: 0.5479\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 7.2807 - accuracy: 0.5443\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 452us/step - loss: 7.2712 - accuracy: 0.5467\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 7.2803 - accuracy: 0.5473\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 373us/step - loss: 7.2867 - accuracy: 0.5502\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 7.2902 - accuracy: 0.5514\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 7.2725 - accuracy: 0.5479\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 363us/step - loss: 7.2843 - accuracy: 0.5431\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 7.2810 - accuracy: 0.5550\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 7.2681 - accuracy: 0.5502\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 7.2694 - accuracy: 0.5479\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 488us/step - loss: 7.2646 - accuracy: 0.5502\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.2828 - accuracy: 0.5508\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 7.2601 - accuracy: 0.5556\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 7.2719 - accuracy: 0.5485\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.2807 - accuracy: 0.5485\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 585us/step - loss: 7.2628 - accuracy: 0.5514\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.2771 - accuracy: 0.5496\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 7.2756 - accuracy: 0.5514\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 373us/step - loss: 7.2907 - accuracy: 0.5508\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 7.2848 - accuracy: 0.5556\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 373us/step - loss: 7.2689 - accuracy: 0.5485\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 7.2887 - accuracy: 0.5491\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 365us/step - loss: 7.2712 - accuracy: 0.5449\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 7.2675 - accuracy: 0.5473\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 7.2733 - accuracy: 0.5449\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 7.2767 - accuracy: 0.5479\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 474us/step - loss: 7.2872 - accuracy: 0.5502\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 7.2708 - accuracy: 0.5526\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 463us/step - loss: 7.2705 - accuracy: 0.5485\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 463us/step - loss: 7.2576 - accuracy: 0.5485\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 7.2663 - accuracy: 0.5473\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 7.2602 - accuracy: 0.5526\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 7.2703 - accuracy: 0.5502\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 599us/step - loss: 7.2817 - accuracy: 0.5449\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.3024 - accuracy: 0.5449\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 553us/step - loss: 7.2586 - accuracy: 0.5449\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.2724 - accuracy: 0.5473\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 517us/step - loss: 7.2701 - accuracy: 0.5467\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 7.2683 - accuracy: 0.5526\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 452us/step - loss: 7.2631 - accuracy: 0.5508\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 474us/step - loss: 7.2738 - accuracy: 0.5514\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 7.2553 - accuracy: 0.5544\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 467us/step - loss: 7.2842 - accuracy: 0.5491\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 778us/step - loss: 7.2614 - accuracy: 0.5496\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 738us/step - loss: 7.2701 - accuracy: 0.5485\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.2555 - accuracy: 0.5502\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 909us/step - loss: 7.2725 - accuracy: 0.5567\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.2706 - accuracy: 0.5485\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.2481 - accuracy: 0.5502\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 7.2623 - accuracy: 0.5443\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 7.2585 - accuracy: 0.5526\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 648us/step - loss: 7.2571 - accuracy: 0.5479\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7.2669 - accuracy: 0.5491\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 7.2629 - accuracy: 0.5473\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.2478 - accuracy: 0.5491\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 7.2604 - accuracy: 0.5532\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 7.2597 - accuracy: 0.5479\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 501us/step - loss: 7.2514 - accuracy: 0.5496\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7.2557 - accuracy: 0.5443\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 789us/step - loss: 7.2669 - accuracy: 0.5514\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 864us/step - loss: 7.2595 - accuracy: 0.5502\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 534us/step - loss: 7.2571 - accuracy: 0.5538\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 465us/step - loss: 7.2661 - accuracy: 0.5473\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 494us/step - loss: 7.2584 - accuracy: 0.5485\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7.2551 - accuracy: 0.5491\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 7.2520 - accuracy: 0.5455\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 523us/step - loss: 7.2558 - accuracy: 0.5514\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 7.2510 - accuracy: 0.5520\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7.2691 - accuracy: 0.5467\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 646us/step - loss: 7.2566 - accuracy: 0.5532\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 631us/step - loss: 7.2426 - accuracy: 0.5532\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 579us/step - loss: 7.2488 - accuracy: 0.5455\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 951us/step - loss: 7.2548 - accuracy: 0.5514\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 671us/step - loss: 7.2622 - accuracy: 0.5538\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 7.2471 - accuracy: 0.5496\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 468us/step - loss: 7.2703 - accuracy: 0.5473\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 7.2459 - accuracy: 0.5485\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 552us/step - loss: 7.2350 - accuracy: 0.5502\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 505us/step - loss: 7.2453 - accuracy: 0.5508\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 7.2619 - accuracy: 0.5514\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7.2474 - accuracy: 0.5485\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 617us/step - loss: 7.2492 - accuracy: 0.5526\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 484us/step - loss: 7.2474 - accuracy: 0.5502\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 554us/step - loss: 7.2508 - accuracy: 0.5479\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 7.2584 - accuracy: 0.5550\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 580us/step - loss: 7.2552 - accuracy: 0.5502\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 527us/step - loss: 7.2572 - accuracy: 0.5508\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 7.2625 - accuracy: 0.5496\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 455us/step - loss: 7.2402 - accuracy: 0.5449\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 473us/step - loss: 7.2501 - accuracy: 0.5485\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 503us/step - loss: 7.2469 - accuracy: 0.5443\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 554us/step - loss: 7.2627 - accuracy: 0.5538\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 596us/step - loss: 7.2556 - accuracy: 0.5479\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 579us/step - loss: 7.2513 - accuracy: 0.5496\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 697us/step - loss: 7.2623 - accuracy: 0.5479\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 803us/step - loss: 7.2498 - accuracy: 0.5502\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 623us/step - loss: 7.2535 - accuracy: 0.5479\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 497us/step - loss: 7.2529 - accuracy: 0.5473\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 496us/step - loss: 7.2325 - accuracy: 0.5556\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 7.2328 - accuracy: 0.5502\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 437us/step - loss: 7.2714 - accuracy: 0.5514\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7.2489 - accuracy: 0.5496\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 7.2515 - accuracy: 0.5520\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.2570 - accuracy: 0.5473\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.2506 - accuracy: 0.5491\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7.2518 - accuracy: 0.5479\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.2462 - accuracy: 0.5479\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 7.2628 - accuracy: 0.5496\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 492us/step - loss: 7.2657 - accuracy: 0.5508\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.2507 - accuracy: 0.5467\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.2500 - accuracy: 0.5455\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 7.2566 - accuracy: 0.5561\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.2416 - accuracy: 0.5508\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 7.2467 - accuracy: 0.5514\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7.2546 - accuracy: 0.5485\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.2637 - accuracy: 0.5455\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 7.2438 - accuracy: 0.5491\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 738us/step - loss: 7.2361 - accuracy: 0.5502\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 607us/step - loss: 7.2496 - accuracy: 0.5496\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 501us/step - loss: 7.2460 - accuracy: 0.5508\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 7.2421 - accuracy: 0.5520\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 470us/step - loss: 7.2469 - accuracy: 0.5496\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 490us/step - loss: 7.2496 - accuracy: 0.5532\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 501us/step - loss: 7.2379 - accuracy: 0.5514\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 7.2384 - accuracy: 0.5491\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 504us/step - loss: 7.2420 - accuracy: 0.5514\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 468us/step - loss: 7.2414 - accuracy: 0.5502\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 7.2571 - accuracy: 0.5479\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 547us/step - loss: 7.2431 - accuracy: 0.5544\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 7.2368 - accuracy: 0.5556\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 504us/step - loss: 7.2599 - accuracy: 0.5496\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 7.2507 - accuracy: 0.5508\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 7.2348 - accuracy: 0.5532\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 586us/step - loss: 7.2361 - accuracy: 0.5491\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 777us/step - loss: 7.2469 - accuracy: 0.5502\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 643us/step - loss: 7.2237 - accuracy: 0.5526\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 636us/step - loss: 7.2346 - accuracy: 0.5485\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 774us/step - loss: 7.2472 - accuracy: 0.5443\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7.2406 - accuracy: 0.5491\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.2361 - accuracy: 0.5496\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 7.2464 - accuracy: 0.5520\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.2325 - accuracy: 0.5544\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 594us/step - loss: 7.2506 - accuracy: 0.5538\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 731us/step - loss: 7.2317 - accuracy: 0.5526\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 7.2501 - accuracy: 0.5514\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 7.2460 - accuracy: 0.5502\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.2316 - accuracy: 0.5473\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 7.2583 - accuracy: 0.5467\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.2436 - accuracy: 0.5496\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 7.2346 - accuracy: 0.5526\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.2338 - accuracy: 0.5520\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.2356 - accuracy: 0.5508\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7.2360 - accuracy: 0.5502\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 7.2421 - accuracy: 0.5514\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 7.2454 - accuracy: 0.5431\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7.2298 - accuracy: 0.5520\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 7.2393 - accuracy: 0.5514\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 721us/step - loss: 7.2395 - accuracy: 0.5538\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7.2404 - accuracy: 0.5496\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 485us/step - loss: 7.2301 - accuracy: 0.5502\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 7.2289 - accuracy: 0.5508\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 7.2391 - accuracy: 0.5467\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 463us/step - loss: 7.2265 - accuracy: 0.5526\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 463us/step - loss: 7.2348 - accuracy: 0.5485\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 7.2252 - accuracy: 0.5491\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 515us/step - loss: 7.2267 - accuracy: 0.5514\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 564us/step - loss: 7.2403 - accuracy: 0.5508\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 505us/step - loss: 7.2418 - accuracy: 0.5479\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 538us/step - loss: 7.2292 - accuracy: 0.5485\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 7.2274 - accuracy: 0.5532\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 548us/step - loss: 7.2446 - accuracy: 0.5502\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 497us/step - loss: 7.2361 - accuracy: 0.5496\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.2439 - accuracy: 0.5496\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 7.2346 - accuracy: 0.5496\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 450us/step - loss: 7.2261 - accuracy: 0.5479\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 7.2295 - accuracy: 0.5479\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 488us/step - loss: 7.2390 - accuracy: 0.5502\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 7.2343 - accuracy: 0.5532\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7.2294 - accuracy: 0.5473\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 0s 494us/step - loss: 7.2214 - accuracy: 0.5508\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7.2300 - accuracy: 0.5479\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 7.2289 - accuracy: 0.5520\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.2290 - accuracy: 0.5514\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 636us/step - loss: 7.2323 - accuracy: 0.5520\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 525us/step - loss: 7.2357 - accuracy: 0.5502\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 7.2234 - accuracy: 0.5496\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 7.2453 - accuracy: 0.5479\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 7.2231 - accuracy: 0.5520\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 7.2437 - accuracy: 0.5544\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 7.2271 - accuracy: 0.5496\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 378us/step - loss: 7.2399 - accuracy: 0.5538\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.2273 - accuracy: 0.5496\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 517us/step - loss: 7.2219 - accuracy: 0.5485\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7.2285 - accuracy: 0.5514\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 474us/step - loss: 7.2431 - accuracy: 0.5520\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 513us/step - loss: 7.2320 - accuracy: 0.5526\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 7.2275 - accuracy: 0.5491\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7.2212 - accuracy: 0.5502\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 515us/step - loss: 7.2344 - accuracy: 0.5479\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 510us/step - loss: 7.2321 - accuracy: 0.5502\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 7.2293 - accuracy: 0.5479\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7.2392 - accuracy: 0.5479\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 7.2181 - accuracy: 0.5544\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 7.2318 - accuracy: 0.5461\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 500us/step - loss: 7.2307 - accuracy: 0.5538\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 7.2252 - accuracy: 0.5532\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 7.2165 - accuracy: 0.5449\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 7.2264 - accuracy: 0.5508\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 897us/step - loss: 7.2185 - accuracy: 0.5561\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 7.2242 - accuracy: 0.5520\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 513us/step - loss: 7.2245 - accuracy: 0.5479\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 611us/step - loss: 7.2168 - accuracy: 0.5538\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 500us/step - loss: 7.2254 - accuracy: 0.5550\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7.2344 - accuracy: 0.5502\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 467us/step - loss: 7.2291 - accuracy: 0.5561\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.2244 - accuracy: 0.5544\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.2262 - accuracy: 0.5514\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 7.2239 - accuracy: 0.5485\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 747us/step - loss: 7.2200 - accuracy: 0.5556\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 770us/step - loss: 7.2133 - accuracy: 0.5532\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 7.2264 - accuracy: 0.5538\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 7.2200 - accuracy: 0.5508\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.2267 - accuracy: 0.5514\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 477us/step - loss: 7.2295 - accuracy: 0.5485\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 526us/step - loss: 7.2136 - accuracy: 0.5526\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 7.2279 - accuracy: 0.5520\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7.2243 - accuracy: 0.5526\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 7.2133 - accuracy: 0.5496\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 7.2226 - accuracy: 0.5573\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 7.2190 - accuracy: 0.5520\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7.2335 - accuracy: 0.5491\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 853us/step - loss: 7.2242 - accuracy: 0.5526\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 7.2323 - accuracy: 0.5502\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 7.2233 - accuracy: 0.5609\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7.2264 - accuracy: 0.5496\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 7.2227 - accuracy: 0.5544\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.2292 - accuracy: 0.5526\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 7.2142 - accuracy: 0.5496\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 7.2328 - accuracy: 0.5502\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 465us/step - loss: 7.2167 - accuracy: 0.5491\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 7.2207 - accuracy: 0.5526\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.2190 - accuracy: 0.5508\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 479us/step - loss: 7.2105 - accuracy: 0.5526\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 7.2205 - accuracy: 0.5567\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 525us/step - loss: 7.2146 - accuracy: 0.5526\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 979us/step - loss: 7.2099 - accuracy: 0.5479\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 599us/step - loss: 7.2135 - accuracy: 0.5520\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 465us/step - loss: 7.2163 - accuracy: 0.5508\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 516us/step - loss: 7.2147 - accuracy: 0.5538\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 477us/step - loss: 7.2117 - accuracy: 0.5556\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 730us/step - loss: 7.2147 - accuracy: 0.5491\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 602us/step - loss: 7.2239 - accuracy: 0.5508\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 490us/step - loss: 7.2279 - accuracy: 0.5556\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.2168 - accuracy: 0.5556\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 561us/step - loss: 7.2113 - accuracy: 0.5532\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 7.2161 - accuracy: 0.5467\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 7.2244 - accuracy: 0.5526\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 0s 461us/step - loss: 7.2074 - accuracy: 0.5479\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 7.2177 - accuracy: 0.5532\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7.2116 - accuracy: 0.5561\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7.2243 - accuracy: 0.5514\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.2266 - accuracy: 0.5502\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 7.2196 - accuracy: 0.5514\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 7.2053 - accuracy: 0.5544\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 7.2302 - accuracy: 0.5550\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 474us/step - loss: 7.1991 - accuracy: 0.5520\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 7.2008 - accuracy: 0.5544\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.2109 - accuracy: 0.5526\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7.2100 - accuracy: 0.5520\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 7.2157 - accuracy: 0.5550\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 654us/step - loss: 7.2230 - accuracy: 0.5485\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 543us/step - loss: 7.2112 - accuracy: 0.5479\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 7.2249 - accuracy: 0.5508\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 7.2190 - accuracy: 0.5567\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 7.2041 - accuracy: 0.5532\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 7.2172 - accuracy: 0.5502\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 7.2210 - accuracy: 0.5502\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 7.2152 - accuracy: 0.5526\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 7.2103 - accuracy: 0.5550\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 7.2113 - accuracy: 0.5526\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 444us/step - loss: 7.2155 - accuracy: 0.5561\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7.2115 - accuracy: 0.5526\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 7.1965 - accuracy: 0.5556\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 7.1896 - accuracy: 0.5567\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7.2209 - accuracy: 0.5573\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.2136 - accuracy: 0.5532\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 7.2237 - accuracy: 0.5496\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 7.2038 - accuracy: 0.5550\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 7.2262 - accuracy: 0.5561\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 7.2071 - accuracy: 0.5502\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.2121 - accuracy: 0.5544\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 866us/step - loss: 7.2044 - accuracy: 0.5550\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7.2165 - accuracy: 0.5520\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 601us/step - loss: 7.1974 - accuracy: 0.5526\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7.2111 - accuracy: 0.5491\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 7.2215 - accuracy: 0.5544\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7.2094 - accuracy: 0.5526\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 7.2096 - accuracy: 0.5556\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 7.2020 - accuracy: 0.5573\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 7.2040 - accuracy: 0.5485\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 7.1970 - accuracy: 0.5538\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7.2080 - accuracy: 0.5496\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7.2067 - accuracy: 0.5496\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 7.1942 - accuracy: 0.5508\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 456us/step - loss: 7.2125 - accuracy: 0.5485\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 7.2100 - accuracy: 0.5526\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 7.1919 - accuracy: 0.5567\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 7.2079 - accuracy: 0.5502\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 549us/step - loss: 7.2015 - accuracy: 0.5585\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 517us/step - loss: 7.2056 - accuracy: 0.5514\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 496us/step - loss: 7.2107 - accuracy: 0.5550\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 762us/step - loss: 7.2144 - accuracy: 0.5556\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 496us/step - loss: 7.2055 - accuracy: 0.5561\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 568us/step - loss: 7.2063 - accuracy: 0.5520\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 7.2071 - accuracy: 0.5502\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 7.2089 - accuracy: 0.5532\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.2038 - accuracy: 0.5491\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 7.2112 - accuracy: 0.5544\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 7.2095 - accuracy: 0.5538\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 970us/step - loss: 7.2108 - accuracy: 0.5491\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.2056 - accuracy: 0.5573\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7.2047 - accuracy: 0.5514\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 7.2028 - accuracy: 0.5550\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 7.2129 - accuracy: 0.5544\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 7.1972 - accuracy: 0.5573\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.1982 - accuracy: 0.5514\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 556us/step - loss: 7.1997 - accuracy: 0.5573\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 577us/step - loss: 7.1977 - accuracy: 0.5550\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 7.1978 - accuracy: 0.5550\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7.1962 - accuracy: 0.5520\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.2102 - accuracy: 0.5491\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.1879 - accuracy: 0.5538\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 7.2024 - accuracy: 0.5520\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 7.1974 - accuracy: 0.5538\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 7.1870 - accuracy: 0.5591\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 7.2073 - accuracy: 0.5520\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 7.1900 - accuracy: 0.5609\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 7.2014 - accuracy: 0.5514\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 7.1987 - accuracy: 0.5526\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 7.2052 - accuracy: 0.5544\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 7.2051 - accuracy: 0.5544\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.2100 - accuracy: 0.5538\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 7.2010 - accuracy: 0.5520\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 7.1975 - accuracy: 0.5538\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 7.1953 - accuracy: 0.5556\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7.2088 - accuracy: 0.5514\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 568us/step - loss: 7.1970 - accuracy: 0.5520\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 7.2029 - accuracy: 0.5567\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 7.2076 - accuracy: 0.5544\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7.2009 - accuracy: 0.5532\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 7.2071 - accuracy: 0.5538\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7.2100 - accuracy: 0.5561\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 7.1940 - accuracy: 0.5526\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7.2030 - accuracy: 0.5502\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 7.2045 - accuracy: 0.5526\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7.2054 - accuracy: 0.5556\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 7.1848 - accuracy: 0.5520\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 369us/step - loss: 7.1970 - accuracy: 0.5532\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 561us/step - loss: 7.1922 - accuracy: 0.5538\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 523us/step - loss: 7.2008 - accuracy: 0.5544\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 762us/step - loss: 7.2025 - accuracy: 0.5526\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7.1954 - accuracy: 0.5479\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 377us/step - loss: 7.1897 - accuracy: 0.5550\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 7.1869 - accuracy: 0.5550\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 627us/step - loss: 7.1982 - accuracy: 0.5520\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 511us/step - loss: 7.1972 - accuracy: 0.5538\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 7.1972 - accuracy: 0.5514\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.1950 - accuracy: 0.5526\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 7.2071 - accuracy: 0.5556\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 7.1880 - accuracy: 0.5544\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 465us/step - loss: 7.1857 - accuracy: 0.5544\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 521us/step - loss: 7.1920 - accuracy: 0.5561\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.1906 - accuracy: 0.5567\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(len(X_train.columns), activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 490us/step\n",
      "[ 0.62460506  2.328727    8.83404    16.118572    2.9156485   5.951101\n",
      "  4.319941    6.0615544  10.708959   10.262156    1.5895889   1.4489145\n",
      "  0.01628119  0.02619744]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>home_shots</th>\n",
       "      <th>away_shots</th>\n",
       "      <th>home_shots_on_target</th>\n",
       "      <th>away_shots_on_target</th>\n",
       "      <th>home_corners</th>\n",
       "      <th>away_corners</th>\n",
       "      <th>home_fouls</th>\n",
       "      <th>away_fouls</th>\n",
       "      <th>home_yellow_cards</th>\n",
       "      <th>away_yellow_cards</th>\n",
       "      <th>home_red_cards</th>\n",
       "      <th>away_red_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_goals  away_goals  home_shots  away_shots  home_shots_on_target  \\\n",
       "1634           2           1          13          16                     4   \n",
       "1479           2           4          16          15                     6   \n",
       "25             2           1           6          23                     2   \n",
       "1686           2           1          12          17                     4   \n",
       "1454           1           3           9          15                     3   \n",
       "\n",
       "      away_shots_on_target  home_corners  away_corners  home_fouls  \\\n",
       "1634                     3             3             5           8   \n",
       "1479                     9             3             3          13   \n",
       "25                       6             4             8          14   \n",
       "1686                     5             6             8          11   \n",
       "1454                     7             3             8           8   \n",
       "\n",
       "      away_fouls  home_yellow_cards  away_yellow_cards  home_red_cards  \\\n",
       "1634          10                  1                  1               0   \n",
       "1479          19                  6                  3               0   \n",
       "25            11                  4                  2               0   \n",
       "1686           7                  3                  1               0   \n",
       "1454          15                  0                  2               0   \n",
       "\n",
       "      away_red_cards  \n",
       "1634               0  \n",
       "1479               0  \n",
       "25                 0  \n",
       "1686               0  \n",
       "1454               0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/34 [==============================] - 0s 509us/step - loss: 27.0220 - accuracy: 0.4113\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 13.4067 - accuracy: 0.4976\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 501us/step - loss: 11.0250 - accuracy: 0.5136\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 9.6123 - accuracy: 0.5378\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 450us/step - loss: 8.8378 - accuracy: 0.5467\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 8.3774 - accuracy: 0.5491\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 8.1178 - accuracy: 0.5538\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.9609 - accuracy: 0.5420\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7.7976 - accuracy: 0.5437\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 7.8257 - accuracy: 0.5437\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 7.6898 - accuracy: 0.5496\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 7.5557 - accuracy: 0.5496\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 576us/step - loss: 7.6310 - accuracy: 0.5443\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 7.5669 - accuracy: 0.5426\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 378us/step - loss: 7.6152 - accuracy: 0.5461\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.5526 - accuracy: 0.5479\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.4967 - accuracy: 0.5467\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.6123 - accuracy: 0.5473\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 7.4241 - accuracy: 0.5467\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 377us/step - loss: 7.3847 - accuracy: 0.5491\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7.4115 - accuracy: 0.5485\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 7.4276 - accuracy: 0.5414\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 474us/step - loss: 7.3795 - accuracy: 0.5426\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 572us/step - loss: 7.4397 - accuracy: 0.5461\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 462us/step - loss: 7.3677 - accuracy: 0.5491\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 794us/step - loss: 7.3478 - accuracy: 0.5431\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 7.3920 - accuracy: 0.5473\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 7.4007 - accuracy: 0.5496\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 7.3321 - accuracy: 0.5508\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.3455 - accuracy: 0.5443\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.3371 - accuracy: 0.5496\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.3343 - accuracy: 0.5455\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 7.3726 - accuracy: 0.5544\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 444us/step - loss: 7.3420 - accuracy: 0.5455\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 437us/step - loss: 7.3290 - accuracy: 0.5526\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7.3336 - accuracy: 0.5520\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 467us/step - loss: 7.3446 - accuracy: 0.5502\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 7.3111 - accuracy: 0.5508\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 7.3398 - accuracy: 0.5461\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 595us/step - loss: 7.2726 - accuracy: 0.5455\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 7.2776 - accuracy: 0.5544\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 924us/step - loss: 7.3261 - accuracy: 0.5485\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 691us/step - loss: 7.3131 - accuracy: 0.5461\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 634us/step - loss: 7.2742 - accuracy: 0.5544\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 7.3017 - accuracy: 0.5538\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.2670 - accuracy: 0.5520\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 691us/step - loss: 7.2519 - accuracy: 0.5538\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 7.2543 - accuracy: 0.5538\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 7.2578 - accuracy: 0.5514\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 506us/step - loss: 7.2523 - accuracy: 0.5514\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 7.2605 - accuracy: 0.5544\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7.2841 - accuracy: 0.5408\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 7.2868 - accuracy: 0.5473\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 490us/step - loss: 7.2645 - accuracy: 0.5526\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 7.2567 - accuracy: 0.5538\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 7.2385 - accuracy: 0.5538\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.2420 - accuracy: 0.5544\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 7.2259 - accuracy: 0.5526\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 7.2269 - accuracy: 0.5491\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 7.2467 - accuracy: 0.5567\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 375us/step - loss: 7.2480 - accuracy: 0.5520\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 7.2072 - accuracy: 0.5573\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 7.2229 - accuracy: 0.5556\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.2163 - accuracy: 0.5514\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 377us/step - loss: 7.2011 - accuracy: 0.5573\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 373us/step - loss: 7.2159 - accuracy: 0.5496\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.2104 - accuracy: 0.5544\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 374us/step - loss: 7.2805 - accuracy: 0.5502\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 7.2132 - accuracy: 0.5573\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 7.1852 - accuracy: 0.5544\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 7.2028 - accuracy: 0.5502\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 7.1797 - accuracy: 0.5556\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 7.2372 - accuracy: 0.5479\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 376us/step - loss: 7.1779 - accuracy: 0.5467\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 378us/step - loss: 7.1960 - accuracy: 0.5502\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7.1840 - accuracy: 0.5479\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 369us/step - loss: 7.1967 - accuracy: 0.5502\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 7.2046 - accuracy: 0.5532\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 543us/step - loss: 7.1697 - accuracy: 0.5514\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 682us/step - loss: 7.2088 - accuracy: 0.5544\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 7.1819 - accuracy: 0.5556\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 7.1782 - accuracy: 0.5485\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 7.1838 - accuracy: 0.5508\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 7.1963 - accuracy: 0.5479\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 377us/step - loss: 7.1667 - accuracy: 0.5514\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.1734 - accuracy: 0.5561\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 7.1867 - accuracy: 0.5514\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 368us/step - loss: 7.1944 - accuracy: 0.5508\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 7.2208 - accuracy: 0.5508\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 7.1679 - accuracy: 0.5520\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 7.1638 - accuracy: 0.5479\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 378us/step - loss: 7.1701 - accuracy: 0.5514\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 378us/step - loss: 7.1634 - accuracy: 0.5514\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 7.1371 - accuracy: 0.5520\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 7.1554 - accuracy: 0.5556\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.1585 - accuracy: 0.5508\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 7.1459 - accuracy: 0.5473\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 7.1847 - accuracy: 0.5538\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 7.1558 - accuracy: 0.5573\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 377us/step - loss: 7.1688 - accuracy: 0.5502\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.1399 - accuracy: 0.5532\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 7.1714 - accuracy: 0.5585\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 7.1431 - accuracy: 0.5550\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.1591 - accuracy: 0.5532\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.1299 - accuracy: 0.5520\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.1448 - accuracy: 0.5561\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 7.1573 - accuracy: 0.5561\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.1374 - accuracy: 0.5520\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 7.1361 - accuracy: 0.5532\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7.1262 - accuracy: 0.5485\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 7.1278 - accuracy: 0.5567\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7.1196 - accuracy: 0.5556\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7.1604 - accuracy: 0.5526\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.1216 - accuracy: 0.5496\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.1453 - accuracy: 0.5508\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 7.1418 - accuracy: 0.5508\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 377us/step - loss: 7.1200 - accuracy: 0.5556\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 7.1353 - accuracy: 0.5461\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 983us/step - loss: 7.1304 - accuracy: 0.5579\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 7.1152 - accuracy: 0.5544\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 372us/step - loss: 7.1247 - accuracy: 0.5514\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 7.1315 - accuracy: 0.5526\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 7.1096 - accuracy: 0.5550\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 7.0862 - accuracy: 0.5567\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 7.1058 - accuracy: 0.5520\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.1183 - accuracy: 0.5597\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.1297 - accuracy: 0.5532\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 7.1167 - accuracy: 0.5526\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.1117 - accuracy: 0.5609\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 7.1104 - accuracy: 0.5550\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 7.1110 - accuracy: 0.5485\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7.1052 - accuracy: 0.5526\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 7.1199 - accuracy: 0.5556\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 7.1022 - accuracy: 0.5597\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 375us/step - loss: 7.0969 - accuracy: 0.5556\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7.0907 - accuracy: 0.5603\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 7.0902 - accuracy: 0.5538\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.0862 - accuracy: 0.5538\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.0910 - accuracy: 0.5532\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 7.1039 - accuracy: 0.5556\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.0913 - accuracy: 0.5561\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 7.0935 - accuracy: 0.5609\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 7.0912 - accuracy: 0.5556\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.0891 - accuracy: 0.5538\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 375us/step - loss: 7.0899 - accuracy: 0.5579\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.0953 - accuracy: 0.5567\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.0756 - accuracy: 0.5573\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 7.0888 - accuracy: 0.5573\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 473us/step - loss: 7.0807 - accuracy: 0.5544\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 7.0920 - accuracy: 0.5597\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.0620 - accuracy: 0.5491\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 670us/step - loss: 7.0805 - accuracy: 0.5597\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 7.1116 - accuracy: 0.5514\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 7.0561 - accuracy: 0.5544\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 7.0944 - accuracy: 0.5573\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 7.0806 - accuracy: 0.5550\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.0872 - accuracy: 0.5561\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 7.0603 - accuracy: 0.5615\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 458us/step - loss: 7.0759 - accuracy: 0.5585\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 569us/step - loss: 7.0876 - accuracy: 0.5508\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7.0740 - accuracy: 0.5603\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 7.0788 - accuracy: 0.5603\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 485us/step - loss: 7.0626 - accuracy: 0.5567\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 616us/step - loss: 7.0604 - accuracy: 0.5544\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 7.0422 - accuracy: 0.5544\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 7.0788 - accuracy: 0.5556\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.0716 - accuracy: 0.5638\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 7.0535 - accuracy: 0.5573\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 7.0421 - accuracy: 0.5591\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 7.0580 - accuracy: 0.5579\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.0568 - accuracy: 0.5626\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 843us/step - loss: 7.0438 - accuracy: 0.5626\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 641us/step - loss: 7.0715 - accuracy: 0.5597\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 7.0812 - accuracy: 0.5573\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 517us/step - loss: 7.0356 - accuracy: 0.5579\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 492us/step - loss: 7.0740 - accuracy: 0.5561\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 519us/step - loss: 7.0636 - accuracy: 0.5585\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 7.0486 - accuracy: 0.5591\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 7.0581 - accuracy: 0.5591\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 7.0596 - accuracy: 0.5508\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 7.0348 - accuracy: 0.5603\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 7.0299 - accuracy: 0.5573\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 7.0278 - accuracy: 0.5538\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 7.0358 - accuracy: 0.5579\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 896us/step - loss: 7.0377 - accuracy: 0.5556\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 7.0267 - accuracy: 0.5561\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 7.0558 - accuracy: 0.5585\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 529us/step - loss: 7.0495 - accuracy: 0.5579\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.0389 - accuracy: 0.5609\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 7.0248 - accuracy: 0.5615\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 558us/step - loss: 7.0278 - accuracy: 0.5556\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 503us/step - loss: 7.0469 - accuracy: 0.5632\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 516us/step - loss: 7.0374 - accuracy: 0.5556\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 444us/step - loss: 7.0384 - accuracy: 0.5561\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 452us/step - loss: 7.0269 - accuracy: 0.5597\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 473us/step - loss: 7.0190 - accuracy: 0.5591\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 7.0315 - accuracy: 0.5561\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 516us/step - loss: 7.0168 - accuracy: 0.5591\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.0163 - accuracy: 0.5632\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 569us/step - loss: 7.0262 - accuracy: 0.5573\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 565us/step - loss: 7.0286 - accuracy: 0.5573\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 494us/step - loss: 7.0298 - accuracy: 0.5591\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 7.0227 - accuracy: 0.5626\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 553us/step - loss: 7.0239 - accuracy: 0.5538\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 623us/step - loss: 7.0102 - accuracy: 0.5615\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 688us/step - loss: 7.0326 - accuracy: 0.5573\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 472us/step - loss: 7.0235 - accuracy: 0.5544\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 565us/step - loss: 7.0186 - accuracy: 0.5532\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.0192 - accuracy: 0.5573\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.0206 - accuracy: 0.5579\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 509us/step - loss: 7.0141 - accuracy: 0.5609\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 7.0204 - accuracy: 0.5561\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 7.0081 - accuracy: 0.5567\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 484us/step - loss: 7.0058 - accuracy: 0.5561\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 7.0015 - accuracy: 0.5585\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 7.0005 - accuracy: 0.5567\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 515us/step - loss: 7.0069 - accuracy: 0.5567\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 455us/step - loss: 7.0063 - accuracy: 0.5538\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 458us/step - loss: 7.0013 - accuracy: 0.5573\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 946us/step - loss: 7.0046 - accuracy: 0.5579\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 674us/step - loss: 6.9896 - accuracy: 0.5561\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 505us/step - loss: 7.0034 - accuracy: 0.5597\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 488us/step - loss: 7.0136 - accuracy: 0.5579\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 534us/step - loss: 6.9954 - accuracy: 0.5544\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 6.9961 - accuracy: 0.5556\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7.0127 - accuracy: 0.5550\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 7.0047 - accuracy: 0.5603\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 7.0025 - accuracy: 0.5556\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.0003 - accuracy: 0.5573\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 0s 763us/step - loss: 6.9921 - accuracy: 0.5585\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 532us/step - loss: 6.9897 - accuracy: 0.5561\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 565us/step - loss: 6.9914 - accuracy: 0.5579\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 559us/step - loss: 6.9886 - accuracy: 0.5567\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 517us/step - loss: 6.9887 - accuracy: 0.5561\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 510us/step - loss: 6.9987 - accuracy: 0.5680\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 733us/step - loss: 6.9709 - accuracy: 0.5579\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 621us/step - loss: 7.0045 - accuracy: 0.5556\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 0s 537us/step - loss: 6.9891 - accuracy: 0.5621\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 609us/step - loss: 6.9798 - accuracy: 0.5597\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 902us/step - loss: 6.9937 - accuracy: 0.5573\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 552us/step - loss: 6.9951 - accuracy: 0.5532\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 629us/step - loss: 6.9893 - accuracy: 0.5579\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 637us/step - loss: 6.9763 - accuracy: 0.5597\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 677us/step - loss: 6.9949 - accuracy: 0.5544\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 6.9854 - accuracy: 0.5615\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 595us/step - loss: 6.9757 - accuracy: 0.5585\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 6.9919 - accuracy: 0.5579\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 6.9648 - accuracy: 0.5556\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.9698 - accuracy: 0.5567\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 6.9925 - accuracy: 0.5591\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 6.9642 - accuracy: 0.5556\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.9692 - accuracy: 0.5609\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 6.9664 - accuracy: 0.5550\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 527us/step - loss: 6.9698 - accuracy: 0.5579\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 6.9525 - accuracy: 0.5538\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 766us/step - loss: 6.9591 - accuracy: 0.5585\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 511us/step - loss: 6.9683 - accuracy: 0.5573\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 621us/step - loss: 6.9677 - accuracy: 0.5603\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 550us/step - loss: 6.9799 - accuracy: 0.5597\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 497us/step - loss: 6.9596 - accuracy: 0.5538\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 492us/step - loss: 6.9695 - accuracy: 0.5591\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 6.9325 - accuracy: 0.5561\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 573us/step - loss: 6.9617 - accuracy: 0.5603\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.9691 - accuracy: 0.5567\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 788us/step - loss: 6.9589 - accuracy: 0.5585\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.9461 - accuracy: 0.5597\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.9557 - accuracy: 0.5544\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 6.9675 - accuracy: 0.5591\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6.9476 - accuracy: 0.5550\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 6.9460 - accuracy: 0.5621\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.9455 - accuracy: 0.5585\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6.9448 - accuracy: 0.5585\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 6.9427 - accuracy: 0.5603\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 6.9597 - accuracy: 0.5585\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 491us/step - loss: 6.9501 - accuracy: 0.5573\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 6.9295 - accuracy: 0.5561\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 6.9283 - accuracy: 0.5508\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 6.9538 - accuracy: 0.5561\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.9566 - accuracy: 0.5556\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 981us/step - loss: 6.9523 - accuracy: 0.5502\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 662us/step - loss: 6.9380 - accuracy: 0.5603\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 742us/step - loss: 6.9271 - accuracy: 0.5591\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 597us/step - loss: 6.9404 - accuracy: 0.5591\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 656us/step - loss: 6.9198 - accuracy: 0.5561\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 585us/step - loss: 6.9286 - accuracy: 0.5556\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.9349 - accuracy: 0.5561\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 690us/step - loss: 6.9253 - accuracy: 0.5597\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 511us/step - loss: 6.9553 - accuracy: 0.5597\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 6.9348 - accuracy: 0.5638\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.9307 - accuracy: 0.5567\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 805us/step - loss: 6.9044 - accuracy: 0.5585\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 564us/step - loss: 6.9269 - accuracy: 0.5561\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 565us/step - loss: 6.9278 - accuracy: 0.5567\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 615us/step - loss: 6.9190 - accuracy: 0.5597\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 6.9360 - accuracy: 0.5573\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 6.9095 - accuracy: 0.5585\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 6.9505 - accuracy: 0.5585\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 479us/step - loss: 6.9104 - accuracy: 0.5585\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 6.9124 - accuracy: 0.5579\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 6.9134 - accuracy: 0.5603\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 6.9335 - accuracy: 0.5550\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 450us/step - loss: 6.9181 - accuracy: 0.5538\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 712us/step - loss: 6.9143 - accuracy: 0.5544\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 566us/step - loss: 6.9126 - accuracy: 0.5538\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 472us/step - loss: 6.9106 - accuracy: 0.5573\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 610us/step - loss: 6.9134 - accuracy: 0.5567\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 0s 569us/step - loss: 6.9124 - accuracy: 0.5638\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 0s 537us/step - loss: 6.9261 - accuracy: 0.5591\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 6.9141 - accuracy: 0.5579\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 535us/step - loss: 6.9087 - accuracy: 0.5615\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 523us/step - loss: 6.8960 - accuracy: 0.5573\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 6.9115 - accuracy: 0.5544\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 6.8999 - accuracy: 0.5597\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 801us/step - loss: 6.9118 - accuracy: 0.5621\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 606us/step - loss: 6.8967 - accuracy: 0.5561\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 6.9189 - accuracy: 0.5621\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 6.8867 - accuracy: 0.5550\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 527us/step - loss: 6.8939 - accuracy: 0.5609\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 6.9228 - accuracy: 0.5621\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 564us/step - loss: 6.9009 - accuracy: 0.5573\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 693us/step - loss: 6.9042 - accuracy: 0.5603\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 6.8871 - accuracy: 0.5561\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 484us/step - loss: 6.8930 - accuracy: 0.5567\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.8946 - accuracy: 0.5609\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 698us/step - loss: 6.9036 - accuracy: 0.5597\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 727us/step - loss: 6.8916 - accuracy: 0.5621\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 698us/step - loss: 6.9051 - accuracy: 0.5603\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 556us/step - loss: 6.8943 - accuracy: 0.5544\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 536us/step - loss: 6.8772 - accuracy: 0.5609\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 602us/step - loss: 6.8946 - accuracy: 0.5609\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 617us/step - loss: 6.8762 - accuracy: 0.5638\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 6.8775 - accuracy: 0.5550\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 515us/step - loss: 6.8787 - accuracy: 0.5579\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 6.8855 - accuracy: 0.5585\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 6.9006 - accuracy: 0.5609\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 505us/step - loss: 6.8713 - accuracy: 0.5609\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 6.8919 - accuracy: 0.5591\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 461us/step - loss: 6.8758 - accuracy: 0.5621\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 458us/step - loss: 6.8697 - accuracy: 0.5632\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.8983 - accuracy: 0.5615\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 694us/step - loss: 6.8922 - accuracy: 0.5632\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 6.8763 - accuracy: 0.5644\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 450us/step - loss: 6.8663 - accuracy: 0.5579\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 6.8670 - accuracy: 0.5514\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.8716 - accuracy: 0.5597\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 6.8831 - accuracy: 0.5538\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 781us/step - loss: 6.8833 - accuracy: 0.5638\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 717us/step - loss: 6.8781 - accuracy: 0.5556\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.8709 - accuracy: 0.5585\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 6.8601 - accuracy: 0.5615\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 563us/step - loss: 6.8756 - accuracy: 0.5603\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 6.8590 - accuracy: 0.5656\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 6.8727 - accuracy: 0.5579\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 6.8678 - accuracy: 0.5632\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 512us/step - loss: 6.8721 - accuracy: 0.5674\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 6.8564 - accuracy: 0.5597\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 513us/step - loss: 6.8821 - accuracy: 0.5591\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 518us/step - loss: 6.8673 - accuracy: 0.5585\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 768us/step - loss: 6.8589 - accuracy: 0.5644\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 503us/step - loss: 6.8465 - accuracy: 0.5626\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 478us/step - loss: 6.8552 - accuracy: 0.5591\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 6.8466 - accuracy: 0.5585\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 508us/step - loss: 6.8399 - accuracy: 0.5561\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 470us/step - loss: 6.8619 - accuracy: 0.5597\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 604us/step - loss: 6.8526 - accuracy: 0.5609\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6.8646 - accuracy: 0.5579\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 489us/step - loss: 6.8523 - accuracy: 0.5579\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 470us/step - loss: 6.8452 - accuracy: 0.5621\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.8499 - accuracy: 0.5615\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 6.8448 - accuracy: 0.5626\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.8497 - accuracy: 0.5567\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 6.8509 - accuracy: 0.5615\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 6.8500 - accuracy: 0.5591\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.8446 - accuracy: 0.5609\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 6.8496 - accuracy: 0.5609\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 6.8365 - accuracy: 0.5585\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 6.8540 - accuracy: 0.5662\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 6.8231 - accuracy: 0.5597\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 6.8448 - accuracy: 0.5621\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 798us/step - loss: 6.8347 - accuracy: 0.5603\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 883us/step - loss: 6.8364 - accuracy: 0.5644\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 762us/step - loss: 6.8453 - accuracy: 0.5567\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 523us/step - loss: 6.8267 - accuracy: 0.5626\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.8467 - accuracy: 0.5638\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 0s 679us/step - loss: 6.8297 - accuracy: 0.5626\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 6.8352 - accuracy: 0.5615\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 6.8407 - accuracy: 0.5650\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 6.8350 - accuracy: 0.5632\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.8255 - accuracy: 0.5650\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.8392 - accuracy: 0.5668\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6.8338 - accuracy: 0.5603\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 6.8360 - accuracy: 0.5638\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 6.8365 - accuracy: 0.5621\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 6.8168 - accuracy: 0.5603\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 6.8286 - accuracy: 0.5621\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 6.8406 - accuracy: 0.5603\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 467us/step - loss: 6.8370 - accuracy: 0.5644\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 6.8224 - accuracy: 0.5603\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 6.8267 - accuracy: 0.5567\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6.8160 - accuracy: 0.5615\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 6.8198 - accuracy: 0.5597\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 6.8120 - accuracy: 0.5674\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 6.8207 - accuracy: 0.5609\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 6.8216 - accuracy: 0.5609\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 6.8082 - accuracy: 0.5644\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 6.8155 - accuracy: 0.5650\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 6.8184 - accuracy: 0.5579\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 564us/step - loss: 6.8084 - accuracy: 0.5621\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 543us/step - loss: 6.8164 - accuracy: 0.5650\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 485us/step - loss: 6.8152 - accuracy: 0.5644\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 456us/step - loss: 6.8072 - accuracy: 0.5626\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 468us/step - loss: 6.8014 - accuracy: 0.5638\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 6.7893 - accuracy: 0.5662\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.7990 - accuracy: 0.5632\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 6.7948 - accuracy: 0.5638\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 6.8183 - accuracy: 0.5579\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 6.7894 - accuracy: 0.5632\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 444us/step - loss: 6.7975 - accuracy: 0.5597\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 6.8154 - accuracy: 0.5638\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6.8030 - accuracy: 0.5621\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 6.8047 - accuracy: 0.5561\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 6.7955 - accuracy: 0.5609\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 6.7881 - accuracy: 0.5632\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.7923 - accuracy: 0.5550\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 6.7786 - accuracy: 0.5609\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 6.8007 - accuracy: 0.5591\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.7978 - accuracy: 0.5579\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 6.7910 - accuracy: 0.5609\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 571us/step - loss: 6.7906 - accuracy: 0.5609\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 6.7795 - accuracy: 0.5626\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 596us/step - loss: 6.7879 - accuracy: 0.5650\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 6.7784 - accuracy: 0.5715\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 467us/step - loss: 6.7746 - accuracy: 0.5656\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 479us/step - loss: 6.7762 - accuracy: 0.5609\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 573us/step - loss: 6.7804 - accuracy: 0.5626\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 518us/step - loss: 6.7678 - accuracy: 0.5650\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 6.7651 - accuracy: 0.5644\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.7789 - accuracy: 0.5621\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 6.7800 - accuracy: 0.5662\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.7846 - accuracy: 0.5656\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 375us/step - loss: 6.7712 - accuracy: 0.5656\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 6.7839 - accuracy: 0.5597\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 6.7768 - accuracy: 0.5603\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.7673 - accuracy: 0.5585\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.7598 - accuracy: 0.5668\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 6.7668 - accuracy: 0.5621\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 6.7900 - accuracy: 0.5609\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 625us/step - loss: 6.7668 - accuracy: 0.5668\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 536us/step - loss: 6.7666 - accuracy: 0.5691\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.7745 - accuracy: 0.5674\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.7731 - accuracy: 0.5644\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 6.7566 - accuracy: 0.5686\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 461us/step - loss: 6.7610 - accuracy: 0.5609\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 6.7691 - accuracy: 0.5603\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 477us/step - loss: 6.7722 - accuracy: 0.5727\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 478us/step - loss: 6.7471 - accuracy: 0.5662\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 6.7525 - accuracy: 0.5662\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 6.7462 - accuracy: 0.5656\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 6.7537 - accuracy: 0.5638\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.7658 - accuracy: 0.5609\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 6.7679 - accuracy: 0.5621\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 6.7639 - accuracy: 0.5680\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 6.7339 - accuracy: 0.5680\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 6.7499 - accuracy: 0.5615\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 365us/step - loss: 6.7585 - accuracy: 0.5697\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 458us/step - loss: 6.7496 - accuracy: 0.5703\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 6.7486 - accuracy: 0.5638\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 6.7476 - accuracy: 0.5703\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 479us/step - loss: 6.7429 - accuracy: 0.5585\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 611us/step - loss: 6.7511 - accuracy: 0.5615\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 530us/step - loss: 6.7344 - accuracy: 0.5609\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 6.7411 - accuracy: 0.5691\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 6.7434 - accuracy: 0.5638\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 6.7363 - accuracy: 0.5721\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 0s 482us/step - loss: 6.7337 - accuracy: 0.5674\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 477us/step - loss: 6.7392 - accuracy: 0.5621\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 0s 514us/step - loss: 6.7269 - accuracy: 0.5703\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 455us/step - loss: 6.7362 - accuracy: 0.5680\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 519us/step - loss: 6.7494 - accuracy: 0.5615\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.7253 - accuracy: 0.5650\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.7182 - accuracy: 0.5644\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 6.7394 - accuracy: 0.5674\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 6.7309 - accuracy: 0.5697\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 6.7280 - accuracy: 0.5597\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 6.7401 - accuracy: 0.5626\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 6.7195 - accuracy: 0.5650\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 6.7238 - accuracy: 0.5674\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 6.7278 - accuracy: 0.5703\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.7468 - accuracy: 0.5680\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6.7274 - accuracy: 0.5674\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 575us/step - loss: 6.7327 - accuracy: 0.5680\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 6.7234 - accuracy: 0.5691\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 500us/step - loss: 6.7157 - accuracy: 0.5691\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 697us/step - loss: 6.7362 - accuracy: 0.5632\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 752us/step - loss: 6.7073 - accuracy: 0.5662\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 6.7242 - accuracy: 0.5632\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 6.7227 - accuracy: 0.5621\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 6.7171 - accuracy: 0.5727\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 6.7134 - accuracy: 0.5650\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 6.7127 - accuracy: 0.5597\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(len(X_train.columns), activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 622us/step\n",
      "[ 0.35337526  3.1799393   8.975191   16.397812    2.56419     7.182465\n",
      "  4.547227    6.0369043   9.223312    8.905641    1.3283552   1.1601696\n",
      "  0.09176815 -0.0370064 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>home_shots</th>\n",
       "      <th>away_shots</th>\n",
       "      <th>home_shots_on_target</th>\n",
       "      <th>away_shots_on_target</th>\n",
       "      <th>home_corners</th>\n",
       "      <th>away_corners</th>\n",
       "      <th>home_fouls</th>\n",
       "      <th>away_fouls</th>\n",
       "      <th>home_yellow_cards</th>\n",
       "      <th>away_yellow_cards</th>\n",
       "      <th>home_red_cards</th>\n",
       "      <th>away_red_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_goals  away_goals  home_shots  away_shots  home_shots_on_target  \\\n",
       "1634           2           1          13          16                     4   \n",
       "1479           2           4          16          15                     6   \n",
       "25             2           1           6          23                     2   \n",
       "1686           2           1          12          17                     4   \n",
       "1454           1           3           9          15                     3   \n",
       "\n",
       "      away_shots_on_target  home_corners  away_corners  home_fouls  \\\n",
       "1634                     3             3             5           8   \n",
       "1479                     9             3             3          13   \n",
       "25                       6             4             8          14   \n",
       "1686                     5             6             8          11   \n",
       "1454                     7             3             8           8   \n",
       "\n",
       "      away_fouls  home_yellow_cards  away_yellow_cards  home_red_cards  \\\n",
       "1634          10                  1                  1               0   \n",
       "1479          19                  6                  3               0   \n",
       "25            11                  4                  2               0   \n",
       "1686           7                  3                  1               0   \n",
       "1454          15                  0                  2               0   \n",
       "\n",
       "      away_red_cards  \n",
       "1634               0  \n",
       "1479               0  \n",
       "25                 0  \n",
       "1686               0  \n",
       "1454               0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=15\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/34 [==============================] - 0s 496us/step - loss: 27.1674 - accuracy: 0.4007\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 13.9142 - accuracy: 0.4716\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 505us/step - loss: 11.2993 - accuracy: 0.4775\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 9.9981 - accuracy: 0.4911\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 591us/step - loss: 9.2709 - accuracy: 0.5106\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 517us/step - loss: 8.7824 - accuracy: 0.5313\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 512us/step - loss: 8.4520 - accuracy: 0.5296\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 8.2184 - accuracy: 0.5343\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 477us/step - loss: 8.0595 - accuracy: 0.5443\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 7.9394 - accuracy: 0.5437\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 7.7978 - accuracy: 0.5467\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 652us/step - loss: 7.7029 - accuracy: 0.5496\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.7589 - accuracy: 0.5491\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 7.5934 - accuracy: 0.5461\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 7.5482 - accuracy: 0.5431\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7.5059 - accuracy: 0.5467\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.4590 - accuracy: 0.5491\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.4474 - accuracy: 0.5473\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 7.4719 - accuracy: 0.5520\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7.4447 - accuracy: 0.5544\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 7.3718 - accuracy: 0.5479\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 455us/step - loss: 7.4302 - accuracy: 0.5449\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 7.3478 - accuracy: 0.5473\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 7.3340 - accuracy: 0.5485\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.4384 - accuracy: 0.5449\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 7.3404 - accuracy: 0.5496\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 7.3228 - accuracy: 0.5508\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 7.2838 - accuracy: 0.5532\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 7.3136 - accuracy: 0.5461\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 7.2667 - accuracy: 0.5473\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 560us/step - loss: 7.2688 - accuracy: 0.5479\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 7.2424 - accuracy: 0.5455\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 7.2809 - accuracy: 0.5437\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 7.2630 - accuracy: 0.5496\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 7.2195 - accuracy: 0.5437\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 7.2642 - accuracy: 0.5514\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 7.2448 - accuracy: 0.5461\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 7.2471 - accuracy: 0.5532\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 7.2336 - accuracy: 0.5502\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.1987 - accuracy: 0.5526\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.1954 - accuracy: 0.5514\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 491us/step - loss: 7.2276 - accuracy: 0.5544\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 494us/step - loss: 7.2304 - accuracy: 0.5496\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 489us/step - loss: 7.1635 - accuracy: 0.5514\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 477us/step - loss: 7.1610 - accuracy: 0.5473\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 506us/step - loss: 7.1831 - accuracy: 0.5538\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 520us/step - loss: 7.2029 - accuracy: 0.5508\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 7.2153 - accuracy: 0.5520\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 437us/step - loss: 7.1568 - accuracy: 0.5514\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 7.1671 - accuracy: 0.5520\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 7.1440 - accuracy: 0.5502\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 672us/step - loss: 7.1665 - accuracy: 0.5544\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 505us/step - loss: 7.1685 - accuracy: 0.5514\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 7.1694 - accuracy: 0.5514\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 7.1739 - accuracy: 0.5544\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 7.1362 - accuracy: 0.5526\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 7.1357 - accuracy: 0.5538\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 7.1356 - accuracy: 0.5508\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.1136 - accuracy: 0.5496\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 7.1347 - accuracy: 0.5502\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 7.0974 - accuracy: 0.5502\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 524us/step - loss: 7.1299 - accuracy: 0.5520\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 474us/step - loss: 7.1207 - accuracy: 0.5502\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 7.1141 - accuracy: 0.5603\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 515us/step - loss: 7.1432 - accuracy: 0.5544\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 491us/step - loss: 7.1146 - accuracy: 0.5538\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 7.0870 - accuracy: 0.5573\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 462us/step - loss: 7.1296 - accuracy: 0.5585\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 7.1118 - accuracy: 0.5496\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 7.0811 - accuracy: 0.5479\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 7.0837 - accuracy: 0.5591\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.0882 - accuracy: 0.5526\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 7.0891 - accuracy: 0.5538\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 7.0912 - accuracy: 0.5556\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 7.1133 - accuracy: 0.5538\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 7.0667 - accuracy: 0.5550\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 370us/step - loss: 7.0652 - accuracy: 0.5550\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 7.0673 - accuracy: 0.5532\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 7.0755 - accuracy: 0.5514\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 376us/step - loss: 7.0640 - accuracy: 0.5567\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 7.0340 - accuracy: 0.5597\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 7.0595 - accuracy: 0.5496\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 376us/step - loss: 7.0396 - accuracy: 0.5556\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 7.0424 - accuracy: 0.5573\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 7.0514 - accuracy: 0.5585\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 7.0487 - accuracy: 0.5561\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 474us/step - loss: 7.0427 - accuracy: 0.5567\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 7.0449 - accuracy: 0.5550\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 7.0514 - accuracy: 0.5502\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 7.0431 - accuracy: 0.5544\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 7.0447 - accuracy: 0.5514\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 7.0328 - accuracy: 0.5609\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 7.0235 - accuracy: 0.5591\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 7.0187 - accuracy: 0.5621\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 7.0316 - accuracy: 0.5544\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 7.0037 - accuracy: 0.5597\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7.0250 - accuracy: 0.5514\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 7.0220 - accuracy: 0.5573\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 462us/step - loss: 7.0205 - accuracy: 0.5597\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 598us/step - loss: 7.0218 - accuracy: 0.5561\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 672us/step - loss: 7.0470 - accuracy: 0.5573\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 609us/step - loss: 7.0018 - accuracy: 0.5585\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 550us/step - loss: 7.0024 - accuracy: 0.5621\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 553us/step - loss: 7.0049 - accuracy: 0.5632\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 531us/step - loss: 7.0081 - accuracy: 0.5603\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 7.0079 - accuracy: 0.5567\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 534us/step - loss: 6.9928 - accuracy: 0.5591\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 6.9792 - accuracy: 0.5609\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 508us/step - loss: 6.9941 - accuracy: 0.5550\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 521us/step - loss: 6.9778 - accuracy: 0.5632\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 488us/step - loss: 6.9840 - accuracy: 0.5603\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 6.9855 - accuracy: 0.5579\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 6.9792 - accuracy: 0.5597\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 6.9704 - accuracy: 0.5644\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 6.9899 - accuracy: 0.5591\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.9726 - accuracy: 0.5638\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 6.9709 - accuracy: 0.5615\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.9941 - accuracy: 0.5626\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 6.9866 - accuracy: 0.5573\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 6.9606 - accuracy: 0.5621\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 6.9667 - accuracy: 0.5650\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 542us/step - loss: 6.9697 - accuracy: 0.5603\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 496us/step - loss: 6.9426 - accuracy: 0.5626\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 473us/step - loss: 6.9489 - accuracy: 0.5626\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 6.9419 - accuracy: 0.5603\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 494us/step - loss: 6.9306 - accuracy: 0.5567\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 463us/step - loss: 6.9549 - accuracy: 0.5638\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 6.9639 - accuracy: 0.5621\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 6.9418 - accuracy: 0.5650\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 529us/step - loss: 6.9472 - accuracy: 0.5609\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 542us/step - loss: 6.9456 - accuracy: 0.5615\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 6.9264 - accuracy: 0.5615\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 6.9387 - accuracy: 0.5626\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.9226 - accuracy: 0.5603\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 584us/step - loss: 6.9186 - accuracy: 0.5674\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 512us/step - loss: 6.9344 - accuracy: 0.5632\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6.9191 - accuracy: 0.5609\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 6.9076 - accuracy: 0.5591\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 6.9052 - accuracy: 0.5662\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.9148 - accuracy: 0.5609\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 6.9062 - accuracy: 0.5621\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 364us/step - loss: 6.9397 - accuracy: 0.5644\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 340us/step - loss: 6.9036 - accuracy: 0.5662\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 368us/step - loss: 6.9221 - accuracy: 0.5656\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 468us/step - loss: 6.9067 - accuracy: 0.5650\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 629us/step - loss: 6.9189 - accuracy: 0.5638\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 6.8988 - accuracy: 0.5609\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 6.9043 - accuracy: 0.5626\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 6.8813 - accuracy: 0.5638\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 369us/step - loss: 6.9000 - accuracy: 0.5662\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 5ms/step - loss: 6.8865 - accuracy: 0.5638\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 897us/step - loss: 6.8978 - accuracy: 0.5674\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 903us/step - loss: 6.8887 - accuracy: 0.5621\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 816us/step - loss: 6.8755 - accuracy: 0.5703\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 814us/step - loss: 6.8916 - accuracy: 0.5715\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 836us/step - loss: 6.8893 - accuracy: 0.5668\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.8817 - accuracy: 0.5626\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.8762 - accuracy: 0.5674\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.8574 - accuracy: 0.5668\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.8548 - accuracy: 0.5668\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 896us/step - loss: 6.8581 - accuracy: 0.5715\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 558us/step - loss: 6.8676 - accuracy: 0.5715\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 867us/step - loss: 6.8561 - accuracy: 0.5632\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 828us/step - loss: 6.8595 - accuracy: 0.5686\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 6.8521 - accuracy: 0.5662\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 462us/step - loss: 6.8560 - accuracy: 0.5674\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 6.8594 - accuracy: 0.5691\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 6.8495 - accuracy: 0.5638\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 586us/step - loss: 6.8698 - accuracy: 0.5621\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 644us/step - loss: 6.8525 - accuracy: 0.5686\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 6.8387 - accuracy: 0.5644\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 582us/step - loss: 6.8308 - accuracy: 0.5727\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.8352 - accuracy: 0.5674\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 838us/step - loss: 6.8480 - accuracy: 0.5703\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 626us/step - loss: 6.8314 - accuracy: 0.5697\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 6.8271 - accuracy: 0.5703\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 578us/step - loss: 6.8220 - accuracy: 0.5703\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 773us/step - loss: 6.8173 - accuracy: 0.5662\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 665us/step - loss: 6.8223 - accuracy: 0.5686\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 769us/step - loss: 6.8390 - accuracy: 0.5686\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.8264 - accuracy: 0.5745\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 909us/step - loss: 6.8228 - accuracy: 0.5721\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 541us/step - loss: 6.8097 - accuracy: 0.5727\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 741us/step - loss: 6.8353 - accuracy: 0.5780\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 782us/step - loss: 6.8209 - accuracy: 0.5715\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 710us/step - loss: 6.8085 - accuracy: 0.5691\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 320us/step - loss: 6.8057 - accuracy: 0.5715\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 775us/step - loss: 6.8149 - accuracy: 0.5751\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 864us/step - loss: 6.8058 - accuracy: 0.5733\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 875us/step - loss: 6.8041 - accuracy: 0.5739\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6.8009 - accuracy: 0.5745\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 363us/step - loss: 6.8150 - accuracy: 0.5733\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.7870 - accuracy: 0.5709\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 6.7824 - accuracy: 0.5733\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 547us/step - loss: 6.7984 - accuracy: 0.5703\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6.7927 - accuracy: 0.5739\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 336us/step - loss: 6.7901 - accuracy: 0.5703\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 6.7784 - accuracy: 0.5727\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 605us/step - loss: 6.7793 - accuracy: 0.5768\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 362us/step - loss: 6.7983 - accuracy: 0.5745\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 348us/step - loss: 6.7922 - accuracy: 0.5721\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 532us/step - loss: 6.7634 - accuracy: 0.5727\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 6.7633 - accuracy: 0.5757\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 357us/step - loss: 6.7653 - accuracy: 0.5739\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 6.7810 - accuracy: 0.5739\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 516us/step - loss: 6.7576 - accuracy: 0.5739\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 6.7733 - accuracy: 0.5774\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 796us/step - loss: 6.7596 - accuracy: 0.5792\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 556us/step - loss: 6.7615 - accuracy: 0.5727\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 325us/step - loss: 6.7569 - accuracy: 0.5757\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 6.7605 - accuracy: 0.5715\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 484us/step - loss: 6.7547 - accuracy: 0.5751\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 345us/step - loss: 6.7435 - accuracy: 0.5751\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 327us/step - loss: 6.7505 - accuracy: 0.5745\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 362us/step - loss: 6.7403 - accuracy: 0.5721\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 340us/step - loss: 6.7367 - accuracy: 0.5739\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 541us/step - loss: 6.7311 - accuracy: 0.5733\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 631us/step - loss: 6.7226 - accuracy: 0.5703\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.7329 - accuracy: 0.5715\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 504us/step - loss: 6.7239 - accuracy: 0.5786\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 468us/step - loss: 6.7298 - accuracy: 0.5768\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 6.7227 - accuracy: 0.5745\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 363us/step - loss: 6.7342 - accuracy: 0.5662\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 6.7164 - accuracy: 0.5792\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 638us/step - loss: 6.7138 - accuracy: 0.5798\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 6.7159 - accuracy: 0.5762\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 6.7268 - accuracy: 0.5774\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.7031 - accuracy: 0.5822\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 6.6933 - accuracy: 0.5768\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 6.7094 - accuracy: 0.5727\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 6.7134 - accuracy: 0.5780\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 6.7145 - accuracy: 0.5810\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 650us/step - loss: 6.7027 - accuracy: 0.5745\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 544us/step - loss: 6.6962 - accuracy: 0.5715\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 559us/step - loss: 6.6996 - accuracy: 0.5757\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.7112 - accuracy: 0.5762\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 6.6920 - accuracy: 0.5757\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.6934 - accuracy: 0.5762\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 6.6930 - accuracy: 0.5757\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 6.6879 - accuracy: 0.5745\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 6.6820 - accuracy: 0.5733\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 6.7021 - accuracy: 0.5745\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6.6650 - accuracy: 0.5757\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 371us/step - loss: 6.6741 - accuracy: 0.5733\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 374us/step - loss: 6.6793 - accuracy: 0.5792\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 6.6836 - accuracy: 0.5792\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 492us/step - loss: 6.6804 - accuracy: 0.5810\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 6.6562 - accuracy: 0.5757\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 346us/step - loss: 6.6723 - accuracy: 0.5798\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 6.6595 - accuracy: 0.5780\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 367us/step - loss: 6.6583 - accuracy: 0.5751\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.6540 - accuracy: 0.5733\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 6.6720 - accuracy: 0.5745\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 749us/step - loss: 6.6611 - accuracy: 0.5798\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 563us/step - loss: 6.6518 - accuracy: 0.5804\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 6.6310 - accuracy: 0.5768\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.6496 - accuracy: 0.5804\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 351us/step - loss: 6.6324 - accuracy: 0.5774\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 377us/step - loss: 6.6421 - accuracy: 0.5774\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 6.6595 - accuracy: 0.5827\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 6.6181 - accuracy: 0.5780\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 6.6386 - accuracy: 0.5822\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 6.6297 - accuracy: 0.5745\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 6.6233 - accuracy: 0.5762\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 357us/step - loss: 6.6210 - accuracy: 0.5810\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.6242 - accuracy: 0.5798\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 370us/step - loss: 6.6574 - accuracy: 0.5762\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 377us/step - loss: 6.6102 - accuracy: 0.5810\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 373us/step - loss: 6.6322 - accuracy: 0.5774\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 6.6126 - accuracy: 0.5816\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 6.6204 - accuracy: 0.5745\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 6.5902 - accuracy: 0.5798\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 361us/step - loss: 6.6198 - accuracy: 0.5822\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 373us/step - loss: 6.6034 - accuracy: 0.5792\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 613us/step - loss: 6.6132 - accuracy: 0.5768\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 499us/step - loss: 6.5938 - accuracy: 0.5804\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 367us/step - loss: 6.5932 - accuracy: 0.5792\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 437us/step - loss: 6.5936 - accuracy: 0.5810\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 6.5871 - accuracy: 0.5762\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 372us/step - loss: 6.6072 - accuracy: 0.5792\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 6.5824 - accuracy: 0.5851\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 372us/step - loss: 6.5730 - accuracy: 0.5792\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.5931 - accuracy: 0.5768\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 374us/step - loss: 6.5728 - accuracy: 0.5757\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 6.5847 - accuracy: 0.5774\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 352us/step - loss: 6.5778 - accuracy: 0.5757\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 542us/step - loss: 6.5777 - accuracy: 0.5833\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 482us/step - loss: 6.5760 - accuracy: 0.5863\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 523us/step - loss: 6.5612 - accuracy: 0.5786\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 519us/step - loss: 6.5586 - accuracy: 0.5857\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 6.5813 - accuracy: 0.5845\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 6.5551 - accuracy: 0.5733\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 375us/step - loss: 6.5535 - accuracy: 0.5798\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 374us/step - loss: 6.5608 - accuracy: 0.5792\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 6.5623 - accuracy: 0.5757\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 540us/step - loss: 6.5469 - accuracy: 0.5810\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 703us/step - loss: 6.5442 - accuracy: 0.5869\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 901us/step - loss: 6.5269 - accuracy: 0.5845\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 335us/step - loss: 6.5446 - accuracy: 0.5798\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 360us/step - loss: 6.5208 - accuracy: 0.5810\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 6.5337 - accuracy: 0.5875\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 6.5364 - accuracy: 0.5833\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 6.5310 - accuracy: 0.5833\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 715us/step - loss: 6.5476 - accuracy: 0.5822\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 999us/step - loss: 6.5174 - accuracy: 0.5857\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 908us/step - loss: 6.5195 - accuracy: 0.5827\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 0s 554us/step - loss: 6.5224 - accuracy: 0.5798\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 0s 587us/step - loss: 6.5216 - accuracy: 0.5863\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 620us/step - loss: 6.5080 - accuracy: 0.5845\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 544us/step - loss: 6.5122 - accuracy: 0.5845\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 591us/step - loss: 6.5004 - accuracy: 0.5839\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 569us/step - loss: 6.5165 - accuracy: 0.5839\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 523us/step - loss: 6.5141 - accuracy: 0.5833\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 6.5277 - accuracy: 0.5816\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 779us/step - loss: 6.5004 - accuracy: 0.5887\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 0s 624us/step - loss: 6.4802 - accuracy: 0.5875\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 594us/step - loss: 6.4800 - accuracy: 0.5768\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 591us/step - loss: 6.4954 - accuracy: 0.5881\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 0s 621us/step - loss: 6.4906 - accuracy: 0.5816\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 492us/step - loss: 6.4761 - accuracy: 0.5839\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 617us/step - loss: 6.4744 - accuracy: 0.5875\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 635us/step - loss: 6.4740 - accuracy: 0.5892\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 632us/step - loss: 6.4775 - accuracy: 0.5851\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 681us/step - loss: 6.4903 - accuracy: 0.5851\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 770us/step - loss: 6.4674 - accuracy: 0.5816\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 754us/step - loss: 6.4905 - accuracy: 0.5833\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 513us/step - loss: 6.4629 - accuracy: 0.5869\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 603us/step - loss: 6.4711 - accuracy: 0.5887\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 589us/step - loss: 6.4622 - accuracy: 0.5898\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 6.4725 - accuracy: 0.5881\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 627us/step - loss: 6.4504 - accuracy: 0.5869\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6.4534 - accuracy: 0.5875\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 614us/step - loss: 6.4582 - accuracy: 0.5898\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.4498 - accuracy: 0.5863\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 609us/step - loss: 6.4349 - accuracy: 0.5857\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 617us/step - loss: 6.4453 - accuracy: 0.5922\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 712us/step - loss: 6.4551 - accuracy: 0.5822\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 534us/step - loss: 6.4282 - accuracy: 0.5869\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 585us/step - loss: 6.4212 - accuracy: 0.5833\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 552us/step - loss: 6.4252 - accuracy: 0.5875\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 6.4402 - accuracy: 0.5904\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 6.4207 - accuracy: 0.5869\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 516us/step - loss: 6.4246 - accuracy: 0.5875\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 578us/step - loss: 6.4114 - accuracy: 0.5904\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 601us/step - loss: 6.4088 - accuracy: 0.5869\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 6.4181 - accuracy: 0.5928\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 504us/step - loss: 6.3967 - accuracy: 0.5904\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 648us/step - loss: 6.4188 - accuracy: 0.5934\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 656us/step - loss: 6.4072 - accuracy: 0.5827\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 582us/step - loss: 6.4164 - accuracy: 0.5904\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 452us/step - loss: 6.3857 - accuracy: 0.5922\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 6.3955 - accuracy: 0.5822\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 558us/step - loss: 6.3902 - accuracy: 0.5934\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 631us/step - loss: 6.4033 - accuracy: 0.5887\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 526us/step - loss: 6.3969 - accuracy: 0.5922\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 541us/step - loss: 6.3804 - accuracy: 0.5916\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 550us/step - loss: 6.3940 - accuracy: 0.5810\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 503us/step - loss: 6.3948 - accuracy: 0.5875\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 920us/step - loss: 6.3858 - accuracy: 0.5863\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 624us/step - loss: 6.3724 - accuracy: 0.5892\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 683us/step - loss: 6.3670 - accuracy: 0.5957\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 610us/step - loss: 6.3557 - accuracy: 0.5922\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.3760 - accuracy: 0.5922\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 815us/step - loss: 6.3655 - accuracy: 0.5898\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.3636 - accuracy: 0.5963\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 619us/step - loss: 6.3731 - accuracy: 0.5981\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 584us/step - loss: 6.3700 - accuracy: 0.5987\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 552us/step - loss: 6.3361 - accuracy: 0.5904\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 538us/step - loss: 6.3379 - accuracy: 0.5922\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 647us/step - loss: 6.3509 - accuracy: 0.5963\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 6.3582 - accuracy: 0.5898\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 815us/step - loss: 6.3080 - accuracy: 0.5957\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 607us/step - loss: 6.3493 - accuracy: 0.5934\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 621us/step - loss: 6.3460 - accuracy: 0.5910\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 604us/step - loss: 6.3086 - accuracy: 0.5851\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 619us/step - loss: 6.3462 - accuracy: 0.5845\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 579us/step - loss: 6.3176 - accuracy: 0.5993\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 700us/step - loss: 6.3163 - accuracy: 0.5957\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 728us/step - loss: 6.3164 - accuracy: 0.5928\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 583us/step - loss: 6.3349 - accuracy: 0.5922\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 701us/step - loss: 6.3291 - accuracy: 0.5887\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 555us/step - loss: 6.3439 - accuracy: 0.5934\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 492us/step - loss: 6.3314 - accuracy: 0.5887\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 6.2870 - accuracy: 0.5975\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 0s 470us/step - loss: 6.3300 - accuracy: 0.5892\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 6.3290 - accuracy: 0.5863\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 6.3018 - accuracy: 0.5928\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 711us/step - loss: 6.2862 - accuracy: 0.5940\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 492us/step - loss: 6.3106 - accuracy: 0.5940\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 6.2897 - accuracy: 0.5957\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 762us/step - loss: 6.3090 - accuracy: 0.5999\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 524us/step - loss: 6.2973 - accuracy: 0.5946\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 489us/step - loss: 6.2775 - accuracy: 0.6017\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 6.2951 - accuracy: 0.5922\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 6.2745 - accuracy: 0.5851\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 0s 606us/step - loss: 6.2734 - accuracy: 0.5957\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 6.2807 - accuracy: 0.5904\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 6.2793 - accuracy: 0.5928\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6.2756 - accuracy: 0.5892\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.2478 - accuracy: 0.5946\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 6.2571 - accuracy: 0.6005\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 6.2534 - accuracy: 0.5999\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 6.2582 - accuracy: 0.5957\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 378us/step - loss: 6.2775 - accuracy: 0.5910\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.2455 - accuracy: 0.5981\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6.2703 - accuracy: 0.5922\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 6.2572 - accuracy: 0.5946\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 6.2225 - accuracy: 0.5946\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 6.2262 - accuracy: 0.5928\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 378us/step - loss: 6.2347 - accuracy: 0.5952\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 6.2392 - accuracy: 0.5952\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 6.2350 - accuracy: 0.5963\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 6.2257 - accuracy: 0.5981\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 367us/step - loss: 6.2461 - accuracy: 0.5987\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 538us/step - loss: 6.2401 - accuracy: 0.5975\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 513us/step - loss: 6.2193 - accuracy: 0.6017\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 458us/step - loss: 6.2143 - accuracy: 0.5987\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.2152 - accuracy: 0.5981\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 6.2044 - accuracy: 0.5916\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 6.2061 - accuracy: 0.5934\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 6.2148 - accuracy: 0.6028\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 6.2292 - accuracy: 0.5934\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 6.2154 - accuracy: 0.5999\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.2087 - accuracy: 0.5934\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.1867 - accuracy: 0.5940\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 973us/step - loss: 6.1849 - accuracy: 0.5969\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 562us/step - loss: 6.2043 - accuracy: 0.6046\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 6.1973 - accuracy: 0.6011\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 6.1714 - accuracy: 0.5981\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 6.1923 - accuracy: 0.5969\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 6.1993 - accuracy: 0.5952\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.1795 - accuracy: 0.6034\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 6.1720 - accuracy: 0.6005\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 6.1603 - accuracy: 0.5999\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.2034 - accuracy: 0.5928\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 6.1342 - accuracy: 0.5999\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 380us/step - loss: 6.1685 - accuracy: 0.5946\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 6.1276 - accuracy: 0.6099\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.1740 - accuracy: 0.6022\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 6.1594 - accuracy: 0.6005\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 647us/step - loss: 6.1326 - accuracy: 0.5987\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 579us/step - loss: 6.1451 - accuracy: 0.5963\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 463us/step - loss: 6.1329 - accuracy: 0.6028\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 6.1487 - accuracy: 0.6017\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 6.1562 - accuracy: 0.5910\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 465us/step - loss: 6.1466 - accuracy: 0.5957\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 6.1222 - accuracy: 0.5952\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 6.1235 - accuracy: 0.5993\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 521us/step - loss: 6.1202 - accuracy: 0.6005\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 6.1206 - accuracy: 0.5981\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 6.0969 - accuracy: 0.5987\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 6.1240 - accuracy: 0.6022\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 6.1372 - accuracy: 0.5999\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.1021 - accuracy: 0.5922\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 6.1218 - accuracy: 0.6082\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.1027 - accuracy: 0.6064\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 498us/step - loss: 6.1005 - accuracy: 0.5952\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.0776 - accuracy: 0.6017\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 604us/step - loss: 6.0904 - accuracy: 0.6017\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 6.0951 - accuracy: 0.6034\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.1137 - accuracy: 0.5975\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 6.1053 - accuracy: 0.5952\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 0s 478us/step - loss: 6.1088 - accuracy: 0.6005\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 6.0703 - accuracy: 0.6064\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 479us/step - loss: 6.1228 - accuracy: 0.6005\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 6.0772 - accuracy: 0.5957\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6.1002 - accuracy: 0.6028\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 6.0937 - accuracy: 0.6058\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 6.0731 - accuracy: 0.5934\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.0677 - accuracy: 0.5946\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.0766 - accuracy: 0.6005\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 6.0828 - accuracy: 0.5957\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 6.0769 - accuracy: 0.6064\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 6.0357 - accuracy: 0.6022\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 6.0869 - accuracy: 0.6058\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 608us/step - loss: 6.0709 - accuracy: 0.5952\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 0s 530us/step - loss: 6.0127 - accuracy: 0.6028\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 6.0513 - accuracy: 0.6052\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.0444 - accuracy: 0.5969\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 6.0483 - accuracy: 0.5981\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 6.0701 - accuracy: 0.6011\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.0266 - accuracy: 0.6052\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 6.0526 - accuracy: 0.6058\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.0398 - accuracy: 0.6064\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 6.0329 - accuracy: 0.6064\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.0332 - accuracy: 0.6005\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.0150 - accuracy: 0.6082\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 6.0151 - accuracy: 0.5993\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 574us/step - loss: 6.0204 - accuracy: 0.6052\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.0397 - accuracy: 0.6034\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 6.0098 - accuracy: 0.6046\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5.9667 - accuracy: 0.6076\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 5.9819 - accuracy: 0.6052\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6.0364 - accuracy: 0.6011\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 5.9837 - accuracy: 0.6082\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 496us/step - loss: 5.9934 - accuracy: 0.6034\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 475us/step - loss: 6.0046 - accuracy: 0.6028\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 5.9983 - accuracy: 0.5946\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 6.0040 - accuracy: 0.6129\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 5.9982 - accuracy: 0.6099\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(len(X_train.columns), activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 694us/step\n",
      "[ 0.33033273  3.3477943  11.707733   17.451344    2.9178748   7.6897697\n",
      "  4.7381835   6.1555448   8.939465    8.124514    1.1674167   1.312059\n",
      "  0.3542312   0.15888253]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>home_shots</th>\n",
       "      <th>away_shots</th>\n",
       "      <th>home_shots_on_target</th>\n",
       "      <th>away_shots_on_target</th>\n",
       "      <th>home_corners</th>\n",
       "      <th>away_corners</th>\n",
       "      <th>home_fouls</th>\n",
       "      <th>away_fouls</th>\n",
       "      <th>home_yellow_cards</th>\n",
       "      <th>away_yellow_cards</th>\n",
       "      <th>home_red_cards</th>\n",
       "      <th>away_red_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_goals  away_goals  home_shots  away_shots  home_shots_on_target  \\\n",
       "1634           2           1          13          16                     4   \n",
       "1479           2           4          16          15                     6   \n",
       "25             2           1           6          23                     2   \n",
       "1686           2           1          12          17                     4   \n",
       "1454           1           3           9          15                     3   \n",
       "\n",
       "      away_shots_on_target  home_corners  away_corners  home_fouls  \\\n",
       "1634                     3             3             5           8   \n",
       "1479                     9             3             3          13   \n",
       "25                       6             4             8          14   \n",
       "1686                     5             6             8          11   \n",
       "1454                     7             3             8           8   \n",
       "\n",
       "      away_fouls  home_yellow_cards  away_yellow_cards  home_red_cards  \\\n",
       "1634          10                  1                  1               0   \n",
       "1479          19                  6                  3               0   \n",
       "25            11                  4                  2               0   \n",
       "1686           7                  3                  1               0   \n",
       "1454          15                  0                  2               0   \n",
       "\n",
       "      away_red_cards  \n",
       "1634               0  \n",
       "1479               0  \n",
       "25                 0  \n",
       "1686               0  \n",
       "1454               0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=20\n",
    "X = n_components[n][['pca'+ str(x) for x in range(n)]]\n",
    "Y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=629) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34/34 [==============================] - 0s 525us/step - loss: 26.2263 - accuracy: 0.4462\n",
      "Epoch 2/500\n",
      "34/34 [==============================] - 0s 473us/step - loss: 13.2371 - accuracy: 0.4835\n",
      "Epoch 3/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10.7760 - accuracy: 0.4959\n",
      "Epoch 4/500\n",
      "34/34 [==============================] - 0s 748us/step - loss: 9.7415 - accuracy: 0.5112\n",
      "Epoch 5/500\n",
      "34/34 [==============================] - 0s 889us/step - loss: 9.0670 - accuracy: 0.5236\n",
      "Epoch 6/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 8.6053 - accuracy: 0.5449\n",
      "Epoch 7/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 8.2820 - accuracy: 0.5426\n",
      "Epoch 8/500\n",
      "34/34 [==============================] - 0s 437us/step - loss: 8.1104 - accuracy: 0.5437\n",
      "Epoch 9/500\n",
      "34/34 [==============================] - 0s 461us/step - loss: 7.9506 - accuracy: 0.5461\n",
      "Epoch 10/500\n",
      "34/34 [==============================] - 0s 366us/step - loss: 7.7976 - accuracy: 0.5461\n",
      "Epoch 11/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 7.7067 - accuracy: 0.5467\n",
      "Epoch 12/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 7.6774 - accuracy: 0.5449\n",
      "Epoch 13/500\n",
      "34/34 [==============================] - 0s 367us/step - loss: 7.6022 - accuracy: 0.5473\n",
      "Epoch 14/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 7.5614 - accuracy: 0.5485\n",
      "Epoch 15/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 7.5462 - accuracy: 0.5426\n",
      "Epoch 16/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.5001 - accuracy: 0.5520\n",
      "Epoch 17/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 7.4490 - accuracy: 0.5479\n",
      "Epoch 18/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 7.3970 - accuracy: 0.5426\n",
      "Epoch 19/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 7.3676 - accuracy: 0.5514\n",
      "Epoch 20/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 7.3707 - accuracy: 0.5473\n",
      "Epoch 21/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 7.3818 - accuracy: 0.5514\n",
      "Epoch 22/500\n",
      "34/34 [==============================] - 0s 668us/step - loss: 7.3061 - accuracy: 0.5526\n",
      "Epoch 23/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 7.2676 - accuracy: 0.5449\n",
      "Epoch 24/500\n",
      "34/34 [==============================] - 0s 535us/step - loss: 7.3221 - accuracy: 0.5479\n",
      "Epoch 25/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 7.2273 - accuracy: 0.5538\n",
      "Epoch 26/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 7.2582 - accuracy: 0.5502\n",
      "Epoch 27/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 7.3064 - accuracy: 0.5479\n",
      "Epoch 28/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 7.2223 - accuracy: 0.5550\n",
      "Epoch 29/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 7.2111 - accuracy: 0.5508\n",
      "Epoch 30/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 7.2474 - accuracy: 0.5449\n",
      "Epoch 31/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 7.1741 - accuracy: 0.5508\n",
      "Epoch 32/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 7.1510 - accuracy: 0.5520\n",
      "Epoch 33/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 7.1606 - accuracy: 0.5514\n",
      "Epoch 34/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 7.1369 - accuracy: 0.5550\n",
      "Epoch 35/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 7.1370 - accuracy: 0.5485\n",
      "Epoch 36/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 7.0986 - accuracy: 0.5491\n",
      "Epoch 37/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 7.1007 - accuracy: 0.5508\n",
      "Epoch 38/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 7.0928 - accuracy: 0.5508\n",
      "Epoch 39/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 7.1249 - accuracy: 0.5579\n",
      "Epoch 40/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 7.0815 - accuracy: 0.5520\n",
      "Epoch 41/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 7.1129 - accuracy: 0.5538\n",
      "Epoch 42/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 7.0501 - accuracy: 0.5520\n",
      "Epoch 43/500\n",
      "34/34 [==============================] - 0s 578us/step - loss: 7.0457 - accuracy: 0.5520\n",
      "Epoch 44/500\n",
      "34/34 [==============================] - 0s 579us/step - loss: 7.0195 - accuracy: 0.5520\n",
      "Epoch 45/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 7.1091 - accuracy: 0.5544\n",
      "Epoch 46/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 7.0659 - accuracy: 0.5520\n",
      "Epoch 47/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 7.0065 - accuracy: 0.5544\n",
      "Epoch 48/500\n",
      "34/34 [==============================] - 0s 521us/step - loss: 7.0377 - accuracy: 0.5585\n",
      "Epoch 49/500\n",
      "34/34 [==============================] - 0s 526us/step - loss: 6.9951 - accuracy: 0.5538\n",
      "Epoch 50/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 7.0010 - accuracy: 0.5526\n",
      "Epoch 51/500\n",
      "34/34 [==============================] - 0s 497us/step - loss: 7.0066 - accuracy: 0.5609\n",
      "Epoch 52/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 6.9710 - accuracy: 0.5591\n",
      "Epoch 53/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6.9729 - accuracy: 0.5550\n",
      "Epoch 54/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 6.9949 - accuracy: 0.5544\n",
      "Epoch 55/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.9563 - accuracy: 0.5532\n",
      "Epoch 56/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 6.9501 - accuracy: 0.5561\n",
      "Epoch 57/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 6.9794 - accuracy: 0.5585\n",
      "Epoch 58/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 6.9390 - accuracy: 0.5597\n",
      "Epoch 59/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 6.9371 - accuracy: 0.5561\n",
      "Epoch 60/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.9682 - accuracy: 0.5532\n",
      "Epoch 61/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 6.9347 - accuracy: 0.5585\n",
      "Epoch 62/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 6.9055 - accuracy: 0.5597\n",
      "Epoch 63/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.9567 - accuracy: 0.5626\n",
      "Epoch 64/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 6.9105 - accuracy: 0.5632\n",
      "Epoch 65/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 6.8925 - accuracy: 0.5662\n",
      "Epoch 66/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.8687 - accuracy: 0.5638\n",
      "Epoch 67/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 6.8673 - accuracy: 0.5603\n",
      "Epoch 68/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 6.8939 - accuracy: 0.5632\n",
      "Epoch 69/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 6.8634 - accuracy: 0.5626\n",
      "Epoch 70/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.8705 - accuracy: 0.5656\n",
      "Epoch 71/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 6.8291 - accuracy: 0.5556\n",
      "Epoch 72/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 6.8405 - accuracy: 0.5668\n",
      "Epoch 73/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 6.8628 - accuracy: 0.5668\n",
      "Epoch 74/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.8425 - accuracy: 0.5603\n",
      "Epoch 75/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 6.8302 - accuracy: 0.5597\n",
      "Epoch 76/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 6.8576 - accuracy: 0.5644\n",
      "Epoch 77/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 6.8194 - accuracy: 0.5662\n",
      "Epoch 78/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 6.8457 - accuracy: 0.5579\n",
      "Epoch 79/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 6.7978 - accuracy: 0.5603\n",
      "Epoch 80/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.8222 - accuracy: 0.5668\n",
      "Epoch 81/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.8028 - accuracy: 0.5621\n",
      "Epoch 82/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.8153 - accuracy: 0.5674\n",
      "Epoch 83/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 6.7821 - accuracy: 0.5615\n",
      "Epoch 84/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 6.7683 - accuracy: 0.5709\n",
      "Epoch 85/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 6.7798 - accuracy: 0.5621\n",
      "Epoch 86/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6.7623 - accuracy: 0.5691\n",
      "Epoch 87/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 6.7416 - accuracy: 0.5662\n",
      "Epoch 88/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 6.8069 - accuracy: 0.5686\n",
      "Epoch 89/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 6.7856 - accuracy: 0.5715\n",
      "Epoch 90/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 6.7398 - accuracy: 0.5697\n",
      "Epoch 91/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 6.7747 - accuracy: 0.5668\n",
      "Epoch 92/500\n",
      "34/34 [==============================] - 0s 882us/step - loss: 6.7686 - accuracy: 0.5697\n",
      "Epoch 93/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6.6969 - accuracy: 0.5733\n",
      "Epoch 94/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 6.7241 - accuracy: 0.5615\n",
      "Epoch 95/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 6.7211 - accuracy: 0.5686\n",
      "Epoch 96/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.7220 - accuracy: 0.5697\n",
      "Epoch 97/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.6855 - accuracy: 0.5703\n",
      "Epoch 98/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 6.7187 - accuracy: 0.5650\n",
      "Epoch 99/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 6.6881 - accuracy: 0.5697\n",
      "Epoch 100/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6.7044 - accuracy: 0.5733\n",
      "Epoch 101/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6.6895 - accuracy: 0.5709\n",
      "Epoch 102/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6.6833 - accuracy: 0.5691\n",
      "Epoch 103/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 6.6623 - accuracy: 0.5709\n",
      "Epoch 104/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 6.6917 - accuracy: 0.5703\n",
      "Epoch 105/500\n",
      "34/34 [==============================] - 0s 532us/step - loss: 6.6819 - accuracy: 0.5621\n",
      "Epoch 106/500\n",
      "34/34 [==============================] - 0s 588us/step - loss: 6.6294 - accuracy: 0.5751\n",
      "Epoch 107/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 6.6852 - accuracy: 0.5703\n",
      "Epoch 108/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 6.6370 - accuracy: 0.5757\n",
      "Epoch 109/500\n",
      "34/34 [==============================] - 0s 399us/step - loss: 6.6544 - accuracy: 0.5727\n",
      "Epoch 110/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 6.6473 - accuracy: 0.5709\n",
      "Epoch 111/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 6.6139 - accuracy: 0.5709\n",
      "Epoch 112/500\n",
      "34/34 [==============================] - 0s 385us/step - loss: 6.6111 - accuracy: 0.5721\n",
      "Epoch 113/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.6492 - accuracy: 0.5739\n",
      "Epoch 114/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 6.6206 - accuracy: 0.5762\n",
      "Epoch 115/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 6.5998 - accuracy: 0.5727\n",
      "Epoch 116/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.6004 - accuracy: 0.5715\n",
      "Epoch 117/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 6.5903 - accuracy: 0.5733\n",
      "Epoch 118/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 6.6088 - accuracy: 0.5691\n",
      "Epoch 119/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 6.5650 - accuracy: 0.5745\n",
      "Epoch 120/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.5790 - accuracy: 0.5751\n",
      "Epoch 121/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 6.5614 - accuracy: 0.5721\n",
      "Epoch 122/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 6.5604 - accuracy: 0.5709\n",
      "Epoch 123/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.5626 - accuracy: 0.5768\n",
      "Epoch 124/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 6.6033 - accuracy: 0.5650\n",
      "Epoch 125/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 6.5437 - accuracy: 0.5686\n",
      "Epoch 126/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 6.5450 - accuracy: 0.5798\n",
      "Epoch 127/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 6.5326 - accuracy: 0.5751\n",
      "Epoch 128/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 6.5505 - accuracy: 0.5745\n",
      "Epoch 129/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 6.5365 - accuracy: 0.5733\n",
      "Epoch 130/500\n",
      "34/34 [==============================] - 0s 502us/step - loss: 6.5479 - accuracy: 0.5780\n",
      "Epoch 131/500\n",
      "34/34 [==============================] - 0s 455us/step - loss: 6.5173 - accuracy: 0.5733\n",
      "Epoch 132/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 6.5113 - accuracy: 0.5745\n",
      "Epoch 133/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 6.4895 - accuracy: 0.5721\n",
      "Epoch 134/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 6.5192 - accuracy: 0.5733\n",
      "Epoch 135/500\n",
      "34/34 [==============================] - 0s 507us/step - loss: 6.5633 - accuracy: 0.5757\n",
      "Epoch 136/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 6.4973 - accuracy: 0.5733\n",
      "Epoch 137/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 6.4796 - accuracy: 0.5727\n",
      "Epoch 138/500\n",
      "34/34 [==============================] - 0s 559us/step - loss: 6.4738 - accuracy: 0.5792\n",
      "Epoch 139/500\n",
      "34/34 [==============================] - 0s 510us/step - loss: 6.4826 - accuracy: 0.5833\n",
      "Epoch 140/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 6.4692 - accuracy: 0.5739\n",
      "Epoch 141/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 6.4619 - accuracy: 0.5839\n",
      "Epoch 142/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 6.4663 - accuracy: 0.5757\n",
      "Epoch 143/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 6.4782 - accuracy: 0.5810\n",
      "Epoch 144/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.4697 - accuracy: 0.5768\n",
      "Epoch 145/500\n",
      "34/34 [==============================] - 0s 407us/step - loss: 6.4279 - accuracy: 0.5751\n",
      "Epoch 146/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 6.4230 - accuracy: 0.5680\n",
      "Epoch 147/500\n",
      "34/34 [==============================] - 0s 382us/step - loss: 6.4410 - accuracy: 0.5810\n",
      "Epoch 148/500\n",
      "34/34 [==============================] - 0s 384us/step - loss: 6.4676 - accuracy: 0.5745\n",
      "Epoch 149/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 6.4302 - accuracy: 0.5780\n",
      "Epoch 150/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6.4533 - accuracy: 0.5816\n",
      "Epoch 151/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.4172 - accuracy: 0.5822\n",
      "Epoch 152/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 6.3998 - accuracy: 0.5745\n",
      "Epoch 153/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 6.3775 - accuracy: 0.5774\n",
      "Epoch 154/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.4617 - accuracy: 0.5798\n",
      "Epoch 155/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 6.4125 - accuracy: 0.5804\n",
      "Epoch 156/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 6.3756 - accuracy: 0.5792\n",
      "Epoch 157/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 6.3795 - accuracy: 0.5762\n",
      "Epoch 158/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 6.3873 - accuracy: 0.5739\n",
      "Epoch 159/500\n",
      "34/34 [==============================] - 0s 794us/step - loss: 6.3780 - accuracy: 0.5768\n",
      "Epoch 160/500\n",
      "34/34 [==============================] - 0s 417us/step - loss: 6.3409 - accuracy: 0.5863\n",
      "Epoch 161/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6.3458 - accuracy: 0.5774\n",
      "Epoch 162/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.3987 - accuracy: 0.5780\n",
      "Epoch 163/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.3384 - accuracy: 0.5827\n",
      "Epoch 164/500\n",
      "34/34 [==============================] - 0s 396us/step - loss: 6.3843 - accuracy: 0.5768\n",
      "Epoch 165/500\n",
      "34/34 [==============================] - 0s 393us/step - loss: 6.3352 - accuracy: 0.5804\n",
      "Epoch 166/500\n",
      "34/34 [==============================] - 0s 387us/step - loss: 6.3683 - accuracy: 0.5810\n",
      "Epoch 167/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 6.3702 - accuracy: 0.5804\n",
      "Epoch 168/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 6.3330 - accuracy: 0.5839\n",
      "Epoch 169/500\n",
      "34/34 [==============================] - 0s 389us/step - loss: 6.3076 - accuracy: 0.5827\n",
      "Epoch 170/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 6.3313 - accuracy: 0.5863\n",
      "Epoch 171/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.3425 - accuracy: 0.5768\n",
      "Epoch 172/500\n",
      "34/34 [==============================] - 0s 413us/step - loss: 6.3014 - accuracy: 0.5757\n",
      "Epoch 173/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.2808 - accuracy: 0.5786\n",
      "Epoch 174/500\n",
      "34/34 [==============================] - 0s 379us/step - loss: 6.2981 - accuracy: 0.5839\n",
      "Epoch 175/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 6.2769 - accuracy: 0.5810\n",
      "Epoch 176/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 6.2547 - accuracy: 0.5827\n",
      "Epoch 177/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 6.3072 - accuracy: 0.5857\n",
      "Epoch 178/500\n",
      "34/34 [==============================] - 0s 386us/step - loss: 6.2654 - accuracy: 0.5827\n",
      "Epoch 179/500\n",
      "34/34 [==============================] - 0s 400us/step - loss: 6.2646 - accuracy: 0.5851\n",
      "Epoch 180/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6.2767 - accuracy: 0.5768\n",
      "Epoch 181/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 6.2759 - accuracy: 0.5792\n",
      "Epoch 182/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6.2698 - accuracy: 0.5839\n",
      "Epoch 183/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6.2214 - accuracy: 0.5822\n",
      "Epoch 184/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 6.2872 - accuracy: 0.5810\n",
      "Epoch 185/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 6.2136 - accuracy: 0.5839\n",
      "Epoch 186/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.2089 - accuracy: 0.5857\n",
      "Epoch 187/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 6.2093 - accuracy: 0.5845\n",
      "Epoch 188/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 6.2166 - accuracy: 0.5851\n",
      "Epoch 189/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 6.2403 - accuracy: 0.5857\n",
      "Epoch 190/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 6.1808 - accuracy: 0.5845\n",
      "Epoch 191/500\n",
      "34/34 [==============================] - 0s 392us/step - loss: 6.2439 - accuracy: 0.5810\n",
      "Epoch 192/500\n",
      "34/34 [==============================] - 0s 409us/step - loss: 6.1767 - accuracy: 0.5940\n",
      "Epoch 193/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 6.1937 - accuracy: 0.5839\n",
      "Epoch 194/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 6.1591 - accuracy: 0.5934\n",
      "Epoch 195/500\n",
      "34/34 [==============================] - 0s 437us/step - loss: 6.1574 - accuracy: 0.5810\n",
      "Epoch 196/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 6.2082 - accuracy: 0.5857\n",
      "Epoch 197/500\n",
      "34/34 [==============================] - 0s 463us/step - loss: 6.1829 - accuracy: 0.5816\n",
      "Epoch 198/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 6.1618 - accuracy: 0.5857\n",
      "Epoch 199/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 6.1385 - accuracy: 0.5851\n",
      "Epoch 200/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 6.1402 - accuracy: 0.5804\n",
      "Epoch 201/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.1514 - accuracy: 0.5810\n",
      "Epoch 202/500\n",
      "34/34 [==============================] - 0s 437us/step - loss: 6.1494 - accuracy: 0.5839\n",
      "Epoch 203/500\n",
      "34/34 [==============================] - 0s 423us/step - loss: 6.1211 - accuracy: 0.5898\n",
      "Epoch 204/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 6.0942 - accuracy: 0.5857\n",
      "Epoch 205/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.0925 - accuracy: 0.5851\n",
      "Epoch 206/500\n",
      "34/34 [==============================] - 0s 509us/step - loss: 6.1670 - accuracy: 0.5833\n",
      "Epoch 207/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 6.0580 - accuracy: 0.5916\n",
      "Epoch 208/500\n",
      "34/34 [==============================] - 0s 578us/step - loss: 6.0827 - accuracy: 0.5910\n",
      "Epoch 209/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 6.1099 - accuracy: 0.5904\n",
      "Epoch 210/500\n",
      "34/34 [==============================] - 0s 414us/step - loss: 6.0943 - accuracy: 0.5875\n",
      "Epoch 211/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 6.0981 - accuracy: 0.5910\n",
      "Epoch 212/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 6.0891 - accuracy: 0.5892\n",
      "Epoch 213/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 6.0808 - accuracy: 0.5934\n",
      "Epoch 214/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 6.0626 - accuracy: 0.5887\n",
      "Epoch 215/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 6.0702 - accuracy: 0.5928\n",
      "Epoch 216/500\n",
      "34/34 [==============================] - 0s 471us/step - loss: 6.0462 - accuracy: 0.5904\n",
      "Epoch 217/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 6.0377 - accuracy: 0.5922\n",
      "Epoch 218/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 6.0587 - accuracy: 0.5928\n",
      "Epoch 219/500\n",
      "34/34 [==============================] - 0s 394us/step - loss: 6.0133 - accuracy: 0.5904\n",
      "Epoch 220/500\n",
      "34/34 [==============================] - 0s 402us/step - loss: 6.0439 - accuracy: 0.5910\n",
      "Epoch 221/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 6.0307 - accuracy: 0.5904\n",
      "Epoch 222/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 6.0067 - accuracy: 0.5892\n",
      "Epoch 223/500\n",
      "34/34 [==============================] - 0s 381us/step - loss: 6.0185 - accuracy: 0.5887\n",
      "Epoch 224/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 5.9855 - accuracy: 0.5946\n",
      "Epoch 225/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 6.0305 - accuracy: 0.5934\n",
      "Epoch 226/500\n",
      "34/34 [==============================] - 0s 430us/step - loss: 5.9799 - accuracy: 0.5922\n",
      "Epoch 227/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 5.9898 - accuracy: 0.5946\n",
      "Epoch 228/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 5.9809 - accuracy: 0.5940\n",
      "Epoch 229/500\n",
      "34/34 [==============================] - 0s 760us/step - loss: 5.9489 - accuracy: 0.5999\n",
      "Epoch 230/500\n",
      "34/34 [==============================] - 0s 667us/step - loss: 5.9558 - accuracy: 0.6046\n",
      "Epoch 231/500\n",
      "34/34 [==============================] - 0s 510us/step - loss: 5.9405 - accuracy: 0.5969\n",
      "Epoch 232/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5.9332 - accuracy: 0.6022\n",
      "Epoch 233/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 5.9297 - accuracy: 0.5916\n",
      "Epoch 234/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 5.9465 - accuracy: 0.5993\n",
      "Epoch 235/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 5.9345 - accuracy: 0.5946\n",
      "Epoch 236/500\n",
      "34/34 [==============================] - 0s 422us/step - loss: 5.9182 - accuracy: 0.5969\n",
      "Epoch 237/500\n",
      "34/34 [==============================] - 0s 461us/step - loss: 5.9145 - accuracy: 0.6028\n",
      "Epoch 238/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 5.9263 - accuracy: 0.6005\n",
      "Epoch 239/500\n",
      "34/34 [==============================] - 0s 583us/step - loss: 5.9123 - accuracy: 0.6017\n",
      "Epoch 240/500\n",
      "34/34 [==============================] - 0s 482us/step - loss: 5.9128 - accuracy: 0.6034\n",
      "Epoch 241/500\n",
      "34/34 [==============================] - 0s 528us/step - loss: 5.8961 - accuracy: 0.5975\n",
      "Epoch 242/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5.9125 - accuracy: 0.6046\n",
      "Epoch 243/500\n",
      "34/34 [==============================] - 0s 773us/step - loss: 5.8979 - accuracy: 0.5957\n",
      "Epoch 244/500\n",
      "34/34 [==============================] - 0s 542us/step - loss: 5.8669 - accuracy: 0.5916\n",
      "Epoch 245/500\n",
      "34/34 [==============================] - 0s 518us/step - loss: 5.8688 - accuracy: 0.5975\n",
      "Epoch 246/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 5.8362 - accuracy: 0.5940\n",
      "Epoch 247/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 5.8652 - accuracy: 0.6022\n",
      "Epoch 248/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 5.8507 - accuracy: 0.5969\n",
      "Epoch 249/500\n",
      "34/34 [==============================] - 0s 489us/step - loss: 5.8541 - accuracy: 0.5957\n",
      "Epoch 250/500\n",
      "34/34 [==============================] - 0s 757us/step - loss: 5.8369 - accuracy: 0.5963\n",
      "Epoch 251/500\n",
      "34/34 [==============================] - 0s 507us/step - loss: 5.8331 - accuracy: 0.6017\n",
      "Epoch 252/500\n",
      "34/34 [==============================] - 0s 511us/step - loss: 5.8708 - accuracy: 0.6017\n",
      "Epoch 253/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 5.8821 - accuracy: 0.5975\n",
      "Epoch 254/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 5.8245 - accuracy: 0.5993\n",
      "Epoch 255/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 5.8672 - accuracy: 0.6082\n",
      "Epoch 256/500\n",
      "34/34 [==============================] - 0s 505us/step - loss: 5.8487 - accuracy: 0.6046\n",
      "Epoch 257/500\n",
      "34/34 [==============================] - 0s 701us/step - loss: 5.8232 - accuracy: 0.5957\n",
      "Epoch 258/500\n",
      "34/34 [==============================] - 0s 624us/step - loss: 5.7824 - accuracy: 0.6093\n",
      "Epoch 259/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 5.8052 - accuracy: 0.6022\n",
      "Epoch 260/500\n",
      "34/34 [==============================] - 0s 545us/step - loss: 5.7797 - accuracy: 0.6058\n",
      "Epoch 261/500\n",
      "34/34 [==============================] - 0s 538us/step - loss: 5.8269 - accuracy: 0.6052\n",
      "Epoch 262/500\n",
      "34/34 [==============================] - 0s 500us/step - loss: 5.7622 - accuracy: 0.5999\n",
      "Epoch 263/500\n",
      "34/34 [==============================] - 0s 694us/step - loss: 5.8095 - accuracy: 0.5987\n",
      "Epoch 264/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5.7537 - accuracy: 0.5999\n",
      "Epoch 265/500\n",
      "34/34 [==============================] - 0s 461us/step - loss: 5.7727 - accuracy: 0.6117\n",
      "Epoch 266/500\n",
      "34/34 [==============================] - 0s 531us/step - loss: 5.7436 - accuracy: 0.6034\n",
      "Epoch 267/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 5.7811 - accuracy: 0.5963\n",
      "Epoch 268/500\n",
      "34/34 [==============================] - 0s 645us/step - loss: 5.7337 - accuracy: 0.6022\n",
      "Epoch 269/500\n",
      "34/34 [==============================] - 0s 520us/step - loss: 5.7228 - accuracy: 0.6070\n",
      "Epoch 270/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 5.7347 - accuracy: 0.6017\n",
      "Epoch 271/500\n",
      "34/34 [==============================] - 0s 497us/step - loss: 5.6999 - accuracy: 0.6028\n",
      "Epoch 272/500\n",
      "34/34 [==============================] - 0s 561us/step - loss: 5.7634 - accuracy: 0.6028\n",
      "Epoch 273/500\n",
      "34/34 [==============================] - 0s 608us/step - loss: 5.6991 - accuracy: 0.6070\n",
      "Epoch 274/500\n",
      "34/34 [==============================] - 0s 488us/step - loss: 5.7145 - accuracy: 0.6076\n",
      "Epoch 275/500\n",
      "34/34 [==============================] - 0s 991us/step - loss: 5.6900 - accuracy: 0.6105\n",
      "Epoch 276/500\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5.7423 - accuracy: 0.6005\n",
      "Epoch 277/500\n",
      "34/34 [==============================] - 0s 778us/step - loss: 5.6829 - accuracy: 0.6099\n",
      "Epoch 278/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5.6744 - accuracy: 0.6135\n",
      "Epoch 279/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5.7414 - accuracy: 0.6052\n",
      "Epoch 280/500\n",
      "34/34 [==============================] - 0s 680us/step - loss: 5.7112 - accuracy: 0.6076\n",
      "Epoch 281/500\n",
      "34/34 [==============================] - 0s 488us/step - loss: 5.6701 - accuracy: 0.6135\n",
      "Epoch 282/500\n",
      "34/34 [==============================] - 0s 395us/step - loss: 5.6346 - accuracy: 0.6164\n",
      "Epoch 283/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 5.6537 - accuracy: 0.6129\n",
      "Epoch 284/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 5.6777 - accuracy: 0.6011\n",
      "Epoch 285/500\n",
      "34/34 [==============================] - 0s 438us/step - loss: 5.6603 - accuracy: 0.6123\n",
      "Epoch 286/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 5.6302 - accuracy: 0.6082\n",
      "Epoch 287/500\n",
      "34/34 [==============================] - 0s 523us/step - loss: 5.6343 - accuracy: 0.6064\n",
      "Epoch 288/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 5.6251 - accuracy: 0.6105\n",
      "Epoch 289/500\n",
      "34/34 [==============================] - 0s 525us/step - loss: 5.6182 - accuracy: 0.6147\n",
      "Epoch 290/500\n",
      "34/34 [==============================] - 0s 518us/step - loss: 5.6518 - accuracy: 0.6105\n",
      "Epoch 291/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 5.6229 - accuracy: 0.6123\n",
      "Epoch 292/500\n",
      "34/34 [==============================] - 0s 473us/step - loss: 5.6231 - accuracy: 0.6064\n",
      "Epoch 293/500\n",
      "34/34 [==============================] - 0s 486us/step - loss: 5.6526 - accuracy: 0.6076\n",
      "Epoch 294/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 5.5774 - accuracy: 0.6087\n",
      "Epoch 295/500\n",
      "34/34 [==============================] - 0s 509us/step - loss: 5.5630 - accuracy: 0.6105\n",
      "Epoch 296/500\n",
      "34/34 [==============================] - 0s 485us/step - loss: 5.5418 - accuracy: 0.6129\n",
      "Epoch 297/500\n",
      "34/34 [==============================] - 0s 660us/step - loss: 5.5945 - accuracy: 0.6170\n",
      "Epoch 298/500\n",
      "34/34 [==============================] - 0s 746us/step - loss: 5.6073 - accuracy: 0.6141\n",
      "Epoch 299/500\n",
      "34/34 [==============================] - 0s 488us/step - loss: 5.5573 - accuracy: 0.6129\n",
      "Epoch 300/500\n",
      "34/34 [==============================] - 0s 659us/step - loss: 5.5652 - accuracy: 0.6152\n",
      "Epoch 301/500\n",
      "34/34 [==============================] - 0s 452us/step - loss: 5.5670 - accuracy: 0.6117\n",
      "Epoch 302/500\n",
      "34/34 [==============================] - 0s 460us/step - loss: 5.5569 - accuracy: 0.6111\n",
      "Epoch 303/500\n",
      "34/34 [==============================] - 0s 548us/step - loss: 5.5323 - accuracy: 0.6147\n",
      "Epoch 304/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 5.5761 - accuracy: 0.6117\n",
      "Epoch 305/500\n",
      "34/34 [==============================] - 0s 506us/step - loss: 5.5535 - accuracy: 0.6135\n",
      "Epoch 306/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 5.5434 - accuracy: 0.6188\n",
      "Epoch 307/500\n",
      "34/34 [==============================] - 0s 442us/step - loss: 5.5209 - accuracy: 0.6152\n",
      "Epoch 308/500\n",
      "34/34 [==============================] - 0s 560us/step - loss: 5.5450 - accuracy: 0.6070\n",
      "Epoch 309/500\n",
      "34/34 [==============================] - 0s 525us/step - loss: 5.5125 - accuracy: 0.6129\n",
      "Epoch 310/500\n",
      "34/34 [==============================] - 0s 531us/step - loss: 5.4639 - accuracy: 0.6217\n",
      "Epoch 311/500\n",
      "34/34 [==============================] - 0s 482us/step - loss: 5.5142 - accuracy: 0.6212\n",
      "Epoch 312/500\n",
      "34/34 [==============================] - 0s 555us/step - loss: 5.4843 - accuracy: 0.6170\n",
      "Epoch 313/500\n",
      "34/34 [==============================] - 0s 519us/step - loss: 5.5119 - accuracy: 0.6229\n",
      "Epoch 314/500\n",
      "34/34 [==============================] - 0s 493us/step - loss: 5.4827 - accuracy: 0.6158\n",
      "Epoch 315/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 5.4839 - accuracy: 0.6206\n",
      "Epoch 316/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 5.4738 - accuracy: 0.6212\n",
      "Epoch 317/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5.4586 - accuracy: 0.6152\n",
      "Epoch 318/500\n",
      "34/34 [==============================] - 0s 503us/step - loss: 5.4778 - accuracy: 0.6158\n",
      "Epoch 319/500\n",
      "34/34 [==============================] - 0s 670us/step - loss: 5.4496 - accuracy: 0.6200\n",
      "Epoch 320/500\n",
      "34/34 [==============================] - 0s 469us/step - loss: 5.4984 - accuracy: 0.6188\n",
      "Epoch 321/500\n",
      "34/34 [==============================] - 0s 433us/step - loss: 5.4433 - accuracy: 0.6253\n",
      "Epoch 322/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 5.4597 - accuracy: 0.6170\n",
      "Epoch 323/500\n",
      "34/34 [==============================] - 0s 574us/step - loss: 5.4272 - accuracy: 0.6182\n",
      "Epoch 324/500\n",
      "34/34 [==============================] - 0s 494us/step - loss: 5.4376 - accuracy: 0.6253\n",
      "Epoch 325/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 5.4045 - accuracy: 0.6241\n",
      "Epoch 326/500\n",
      "34/34 [==============================] - 0s 390us/step - loss: 5.4018 - accuracy: 0.6200\n",
      "Epoch 327/500\n",
      "34/34 [==============================] - 0s 578us/step - loss: 5.3964 - accuracy: 0.6283\n",
      "Epoch 328/500\n",
      "34/34 [==============================] - 0s 577us/step - loss: 5.3741 - accuracy: 0.6217\n",
      "Epoch 329/500\n",
      "34/34 [==============================] - 0s 467us/step - loss: 5.4255 - accuracy: 0.6206\n",
      "Epoch 330/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 5.4063 - accuracy: 0.6217\n",
      "Epoch 331/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 5.4328 - accuracy: 0.6277\n",
      "Epoch 332/500\n",
      "34/34 [==============================] - 0s 391us/step - loss: 5.3892 - accuracy: 0.6300\n",
      "Epoch 333/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 5.4015 - accuracy: 0.6194\n",
      "Epoch 334/500\n",
      "34/34 [==============================] - 0s 521us/step - loss: 5.3951 - accuracy: 0.6259\n",
      "Epoch 335/500\n",
      "34/34 [==============================] - 0s 468us/step - loss: 5.3456 - accuracy: 0.6365\n",
      "Epoch 336/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 5.3434 - accuracy: 0.6271\n",
      "Epoch 337/500\n",
      "34/34 [==============================] - 0s 405us/step - loss: 5.3424 - accuracy: 0.6294\n",
      "Epoch 338/500\n",
      "34/34 [==============================] - 0s 498us/step - loss: 5.3161 - accuracy: 0.6294\n",
      "Epoch 339/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 5.3625 - accuracy: 0.6277\n",
      "Epoch 340/500\n",
      "34/34 [==============================] - 0s 507us/step - loss: 5.3367 - accuracy: 0.6253\n",
      "Epoch 341/500\n",
      "34/34 [==============================] - 0s 518us/step - loss: 5.3539 - accuracy: 0.6277\n",
      "Epoch 342/500\n",
      "34/34 [==============================] - 0s 512us/step - loss: 5.3216 - accuracy: 0.6253\n",
      "Epoch 343/500\n",
      "34/34 [==============================] - 0s 583us/step - loss: 5.3479 - accuracy: 0.6259\n",
      "Epoch 344/500\n",
      "34/34 [==============================] - 0s 500us/step - loss: 5.3499 - accuracy: 0.6259\n",
      "Epoch 345/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 5.3268 - accuracy: 0.6223\n",
      "Epoch 346/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 5.3283 - accuracy: 0.6259\n",
      "Epoch 347/500\n",
      "34/34 [==============================] - 0s 858us/step - loss: 5.3682 - accuracy: 0.6283\n",
      "Epoch 348/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5.3121 - accuracy: 0.6312\n",
      "Epoch 349/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 5.3095 - accuracy: 0.6359\n",
      "Epoch 350/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 5.2934 - accuracy: 0.6283\n",
      "Epoch 351/500\n",
      "34/34 [==============================] - 0s 538us/step - loss: 5.2865 - accuracy: 0.6277\n",
      "Epoch 352/500\n",
      "34/34 [==============================] - 0s 680us/step - loss: 5.2874 - accuracy: 0.6359\n",
      "Epoch 353/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 5.2779 - accuracy: 0.6330\n",
      "Epoch 354/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 5.2550 - accuracy: 0.6312\n",
      "Epoch 355/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 5.2632 - accuracy: 0.6247\n",
      "Epoch 356/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 5.3011 - accuracy: 0.6288\n",
      "Epoch 357/500\n",
      "34/34 [==============================] - 0s 468us/step - loss: 5.2560 - accuracy: 0.6300\n",
      "Epoch 358/500\n",
      "34/34 [==============================] - 0s 512us/step - loss: 5.3074 - accuracy: 0.6294\n",
      "Epoch 359/500\n",
      "34/34 [==============================] - 0s 524us/step - loss: 5.2477 - accuracy: 0.6288\n",
      "Epoch 360/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 5.2262 - accuracy: 0.6371\n",
      "Epoch 361/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 5.2357 - accuracy: 0.6312\n",
      "Epoch 362/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 5.2473 - accuracy: 0.6359\n",
      "Epoch 363/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 5.2134 - accuracy: 0.6288\n",
      "Epoch 364/500\n",
      "34/34 [==============================] - 0s 416us/step - loss: 5.2419 - accuracy: 0.6336\n",
      "Epoch 365/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 5.2768 - accuracy: 0.6353\n",
      "Epoch 366/500\n",
      "34/34 [==============================] - 0s 376us/step - loss: 5.2253 - accuracy: 0.6318\n",
      "Epoch 367/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 5.2300 - accuracy: 0.6324\n",
      "Epoch 368/500\n",
      "34/34 [==============================] - 0s 371us/step - loss: 5.1911 - accuracy: 0.6306\n",
      "Epoch 369/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 5.2084 - accuracy: 0.6407\n",
      "Epoch 370/500\n",
      "34/34 [==============================] - 0s 428us/step - loss: 5.2407 - accuracy: 0.6348\n",
      "Epoch 371/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 5.1349 - accuracy: 0.6377\n",
      "Epoch 372/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 5.1870 - accuracy: 0.6418\n",
      "Epoch 373/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 5.1716 - accuracy: 0.6401\n",
      "Epoch 374/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 5.2479 - accuracy: 0.6277\n",
      "Epoch 375/500\n",
      "34/34 [==============================] - 0s 806us/step - loss: 5.1776 - accuracy: 0.6277\n",
      "Epoch 376/500\n",
      "34/34 [==============================] - 0s 646us/step - loss: 5.1264 - accuracy: 0.6407\n",
      "Epoch 377/500\n",
      "34/34 [==============================] - 0s 550us/step - loss: 5.1873 - accuracy: 0.6442\n",
      "Epoch 378/500\n",
      "34/34 [==============================] - 0s 533us/step - loss: 5.1635 - accuracy: 0.6401\n",
      "Epoch 379/500\n",
      "34/34 [==============================] - 0s 555us/step - loss: 5.1575 - accuracy: 0.6353\n",
      "Epoch 380/500\n",
      "34/34 [==============================] - 0s 461us/step - loss: 5.1287 - accuracy: 0.6418\n",
      "Epoch 381/500\n",
      "34/34 [==============================] - 0s 481us/step - loss: 5.1766 - accuracy: 0.6306\n",
      "Epoch 382/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 5.1469 - accuracy: 0.6365\n",
      "Epoch 383/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 5.1646 - accuracy: 0.6418\n",
      "Epoch 384/500\n",
      "34/34 [==============================] - 0s 498us/step - loss: 5.0889 - accuracy: 0.6324\n",
      "Epoch 385/500\n",
      "34/34 [==============================] - 0s 480us/step - loss: 5.0935 - accuracy: 0.6395\n",
      "Epoch 386/500\n",
      "34/34 [==============================] - 0s 461us/step - loss: 5.0981 - accuracy: 0.6401\n",
      "Epoch 387/500\n",
      "34/34 [==============================] - 0s 478us/step - loss: 5.1319 - accuracy: 0.6448\n",
      "Epoch 388/500\n",
      "34/34 [==============================] - 0s 544us/step - loss: 5.0634 - accuracy: 0.6424\n",
      "Epoch 389/500\n",
      "34/34 [==============================] - 0s 1ms/step - loss: 5.1018 - accuracy: 0.6436\n",
      "Epoch 390/500\n",
      "34/34 [==============================] - 0s 621us/step - loss: 5.1029 - accuracy: 0.6330\n",
      "Epoch 391/500\n",
      "34/34 [==============================] - 0s 545us/step - loss: 5.0640 - accuracy: 0.6418\n",
      "Epoch 392/500\n",
      "34/34 [==============================] - 0s 574us/step - loss: 5.0689 - accuracy: 0.6495\n",
      "Epoch 393/500\n",
      "34/34 [==============================] - 0s 454us/step - loss: 5.0676 - accuracy: 0.6454\n",
      "Epoch 394/500\n",
      "34/34 [==============================] - 0s 431us/step - loss: 5.0490 - accuracy: 0.6413\n",
      "Epoch 395/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 5.0754 - accuracy: 0.6442\n",
      "Epoch 396/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 5.0620 - accuracy: 0.6513\n",
      "Epoch 397/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 5.0633 - accuracy: 0.6424\n",
      "Epoch 398/500\n",
      "34/34 [==============================] - 0s 466us/step - loss: 5.0218 - accuracy: 0.6460\n",
      "Epoch 399/500\n",
      "34/34 [==============================] - 0s 447us/step - loss: 4.9950 - accuracy: 0.6460\n",
      "Epoch 400/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 4.9862 - accuracy: 0.6548\n",
      "Epoch 401/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 5.0330 - accuracy: 0.6430\n",
      "Epoch 402/500\n",
      "34/34 [==============================] - 0s 415us/step - loss: 4.9938 - accuracy: 0.6454\n",
      "Epoch 403/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 5.0315 - accuracy: 0.6436\n",
      "Epoch 404/500\n",
      "34/34 [==============================] - 0s 420us/step - loss: 5.0351 - accuracy: 0.6413\n",
      "Epoch 405/500\n",
      "34/34 [==============================] - 0s 404us/step - loss: 4.9877 - accuracy: 0.6460\n",
      "Epoch 406/500\n",
      "34/34 [==============================] - 0s 421us/step - loss: 5.0020 - accuracy: 0.6442\n",
      "Epoch 407/500\n",
      "34/34 [==============================] - 0s 704us/step - loss: 4.9775 - accuracy: 0.6466\n",
      "Epoch 408/500\n",
      "34/34 [==============================] - 0s 709us/step - loss: 5.0602 - accuracy: 0.6407\n",
      "Epoch 409/500\n",
      "34/34 [==============================] - 0s 590us/step - loss: 5.0282 - accuracy: 0.6342\n",
      "Epoch 410/500\n",
      "34/34 [==============================] - 0s 555us/step - loss: 4.9813 - accuracy: 0.6507\n",
      "Epoch 411/500\n",
      "34/34 [==============================] - 0s 875us/step - loss: 4.9604 - accuracy: 0.6395\n",
      "Epoch 412/500\n",
      "34/34 [==============================] - 0s 590us/step - loss: 4.9596 - accuracy: 0.6519\n",
      "Epoch 413/500\n",
      "34/34 [==============================] - 0s 406us/step - loss: 4.9630 - accuracy: 0.6513\n",
      "Epoch 414/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 4.9901 - accuracy: 0.6430\n",
      "Epoch 415/500\n",
      "34/34 [==============================] - 0s 426us/step - loss: 4.9607 - accuracy: 0.6519\n",
      "Epoch 416/500\n",
      "34/34 [==============================] - 0s 485us/step - loss: 4.9757 - accuracy: 0.6454\n",
      "Epoch 417/500\n",
      "34/34 [==============================] - 0s 444us/step - loss: 4.9496 - accuracy: 0.6442\n",
      "Epoch 418/500\n",
      "34/34 [==============================] - 0s 398us/step - loss: 4.9327 - accuracy: 0.6501\n",
      "Epoch 419/500\n",
      "34/34 [==============================] - 0s 488us/step - loss: 4.9481 - accuracy: 0.6537\n",
      "Epoch 420/500\n",
      "34/34 [==============================] - 0s 477us/step - loss: 4.8925 - accuracy: 0.6436\n",
      "Epoch 421/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 4.8982 - accuracy: 0.6566\n",
      "Epoch 422/500\n",
      "34/34 [==============================] - 0s 462us/step - loss: 4.9165 - accuracy: 0.6513\n",
      "Epoch 423/500\n",
      "34/34 [==============================] - 0s 412us/step - loss: 4.9363 - accuracy: 0.6578\n",
      "Epoch 424/500\n",
      "34/34 [==============================] - 0s 459us/step - loss: 4.9763 - accuracy: 0.6413\n",
      "Epoch 425/500\n",
      "34/34 [==============================] - 0s 455us/step - loss: 4.8990 - accuracy: 0.6507\n",
      "Epoch 426/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 4.9027 - accuracy: 0.6608\n",
      "Epoch 427/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 4.9347 - accuracy: 0.6501\n",
      "Epoch 428/500\n",
      "34/34 [==============================] - 0s 483us/step - loss: 4.8929 - accuracy: 0.6548\n",
      "Epoch 429/500\n",
      "34/34 [==============================] - 0s 605us/step - loss: 4.8694 - accuracy: 0.6548\n",
      "Epoch 430/500\n",
      "34/34 [==============================] - 0s 980us/step - loss: 4.9592 - accuracy: 0.6507\n",
      "Epoch 431/500\n",
      "34/34 [==============================] - 0s 545us/step - loss: 4.8830 - accuracy: 0.6578\n",
      "Epoch 432/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 4.8660 - accuracy: 0.6572\n",
      "Epoch 433/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 4.8745 - accuracy: 0.6513\n",
      "Epoch 434/500\n",
      "34/34 [==============================] - 0s 429us/step - loss: 4.8136 - accuracy: 0.6566\n",
      "Epoch 435/500\n",
      "34/34 [==============================] - 0s 714us/step - loss: 4.9485 - accuracy: 0.6466\n",
      "Epoch 436/500\n",
      "34/34 [==============================] - 0s 698us/step - loss: 4.8740 - accuracy: 0.6448\n",
      "Epoch 437/500\n",
      "34/34 [==============================] - 0s 443us/step - loss: 4.8349 - accuracy: 0.6548\n",
      "Epoch 438/500\n",
      "34/34 [==============================] - 0s 432us/step - loss: 4.9272 - accuracy: 0.6560\n",
      "Epoch 439/500\n",
      "34/34 [==============================] - 0s 451us/step - loss: 4.8710 - accuracy: 0.6566\n",
      "Epoch 440/500\n",
      "34/34 [==============================] - 0s 418us/step - loss: 4.8421 - accuracy: 0.6554\n",
      "Epoch 441/500\n",
      "34/34 [==============================] - 0s 424us/step - loss: 4.8695 - accuracy: 0.6596\n",
      "Epoch 442/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 4.8184 - accuracy: 0.6513\n",
      "Epoch 443/500\n",
      "34/34 [==============================] - 0s 425us/step - loss: 4.8239 - accuracy: 0.6507\n",
      "Epoch 444/500\n",
      "34/34 [==============================] - 0s 436us/step - loss: 4.8639 - accuracy: 0.6572\n",
      "Epoch 445/500\n",
      "34/34 [==============================] - 0s 419us/step - loss: 4.7761 - accuracy: 0.6608\n",
      "Epoch 446/500\n",
      "34/34 [==============================] - 0s 450us/step - loss: 4.9056 - accuracy: 0.6548\n",
      "Epoch 447/500\n",
      "34/34 [==============================] - 0s 487us/step - loss: 4.7648 - accuracy: 0.6578\n",
      "Epoch 448/500\n",
      "34/34 [==============================] - 0s 700us/step - loss: 4.8358 - accuracy: 0.6602\n",
      "Epoch 449/500\n",
      "34/34 [==============================] - 0s 532us/step - loss: 4.7863 - accuracy: 0.6661\n",
      "Epoch 450/500\n",
      "34/34 [==============================] - 0s 453us/step - loss: 4.7981 - accuracy: 0.6631\n",
      "Epoch 451/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 4.7795 - accuracy: 0.6548\n",
      "Epoch 452/500\n",
      "34/34 [==============================] - 0s 484us/step - loss: 4.8174 - accuracy: 0.6619\n",
      "Epoch 453/500\n",
      "34/34 [==============================] - 0s 657us/step - loss: 4.7498 - accuracy: 0.6525\n",
      "Epoch 454/500\n",
      "34/34 [==============================] - 0s 564us/step - loss: 4.8365 - accuracy: 0.6590\n",
      "Epoch 455/500\n",
      "34/34 [==============================] - 0s 495us/step - loss: 4.8069 - accuracy: 0.6548\n",
      "Epoch 456/500\n",
      "34/34 [==============================] - 0s 444us/step - loss: 4.8423 - accuracy: 0.6608\n",
      "Epoch 457/500\n",
      "34/34 [==============================] - 0s 628us/step - loss: 4.7455 - accuracy: 0.6661\n",
      "Epoch 458/500\n",
      "34/34 [==============================] - 0s 656us/step - loss: 4.8119 - accuracy: 0.6625\n",
      "Epoch 459/500\n",
      "34/34 [==============================] - 0s 444us/step - loss: 4.7529 - accuracy: 0.6625\n",
      "Epoch 460/500\n",
      "34/34 [==============================] - 0s 401us/step - loss: 4.7364 - accuracy: 0.6696\n",
      "Epoch 461/500\n",
      "34/34 [==============================] - 0s 468us/step - loss: 4.7146 - accuracy: 0.6572\n",
      "Epoch 462/500\n",
      "34/34 [==============================] - 0s 457us/step - loss: 4.7329 - accuracy: 0.6678\n",
      "Epoch 463/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 4.7222 - accuracy: 0.6613\n",
      "Epoch 464/500\n",
      "34/34 [==============================] - 0s 488us/step - loss: 4.7223 - accuracy: 0.6608\n",
      "Epoch 465/500\n",
      "34/34 [==============================] - 0s 552us/step - loss: 4.7299 - accuracy: 0.6625\n",
      "Epoch 466/500\n",
      "34/34 [==============================] - 0s 448us/step - loss: 4.7259 - accuracy: 0.6678\n",
      "Epoch 467/500\n",
      "34/34 [==============================] - 0s 445us/step - loss: 4.7281 - accuracy: 0.6702\n",
      "Epoch 468/500\n",
      "34/34 [==============================] - 0s 479us/step - loss: 4.7256 - accuracy: 0.6643\n",
      "Epoch 469/500\n",
      "34/34 [==============================] - 0s 446us/step - loss: 4.7363 - accuracy: 0.6548\n",
      "Epoch 470/500\n",
      "34/34 [==============================] - 0s 463us/step - loss: 4.7432 - accuracy: 0.6566\n",
      "Epoch 471/500\n",
      "34/34 [==============================] - 0s 449us/step - loss: 4.6489 - accuracy: 0.6708\n",
      "Epoch 472/500\n",
      "34/34 [==============================] - 0s 383us/step - loss: 4.6606 - accuracy: 0.6619\n",
      "Epoch 473/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 4.6402 - accuracy: 0.6732\n",
      "Epoch 474/500\n",
      "34/34 [==============================] - 0s 397us/step - loss: 4.7337 - accuracy: 0.6673\n",
      "Epoch 475/500\n",
      "34/34 [==============================] - 0s 403us/step - loss: 4.7040 - accuracy: 0.6584\n",
      "Epoch 476/500\n",
      "34/34 [==============================] - 0s 410us/step - loss: 4.6952 - accuracy: 0.6708\n",
      "Epoch 477/500\n",
      "34/34 [==============================] - 0s 372us/step - loss: 4.6012 - accuracy: 0.6714\n",
      "Epoch 478/500\n",
      "34/34 [==============================] - 0s 368us/step - loss: 4.8863 - accuracy: 0.6489\n",
      "Epoch 479/500\n",
      "34/34 [==============================] - 0s 427us/step - loss: 4.6497 - accuracy: 0.6702\n",
      "Epoch 480/500\n",
      "34/34 [==============================] - 0s 441us/step - loss: 4.5936 - accuracy: 0.6732\n",
      "Epoch 481/500\n",
      "34/34 [==============================] - 0s 365us/step - loss: 4.7392 - accuracy: 0.6643\n",
      "Epoch 482/500\n",
      "34/34 [==============================] - 0s 879us/step - loss: 4.6880 - accuracy: 0.6690\n",
      "Epoch 483/500\n",
      "34/34 [==============================] - 0s 982us/step - loss: 4.5954 - accuracy: 0.6785\n",
      "Epoch 484/500\n",
      "34/34 [==============================] - 0s 434us/step - loss: 4.6073 - accuracy: 0.6720\n",
      "Epoch 485/500\n",
      "34/34 [==============================] - 0s 439us/step - loss: 4.6801 - accuracy: 0.6696\n",
      "Epoch 486/500\n",
      "34/34 [==============================] - 0s 440us/step - loss: 4.7153 - accuracy: 0.6619\n",
      "Epoch 487/500\n",
      "34/34 [==============================] - 0s 408us/step - loss: 4.6341 - accuracy: 0.6613\n",
      "Epoch 488/500\n",
      "34/34 [==============================] - 0s 525us/step - loss: 4.6721 - accuracy: 0.6696\n",
      "Epoch 489/500\n",
      "34/34 [==============================] - 0s 542us/step - loss: 4.5962 - accuracy: 0.6655\n",
      "Epoch 490/500\n",
      "34/34 [==============================] - 0s 435us/step - loss: 4.7511 - accuracy: 0.6625\n",
      "Epoch 491/500\n",
      "34/34 [==============================] - 0s 464us/step - loss: 4.6802 - accuracy: 0.6667\n",
      "Epoch 492/500\n",
      "34/34 [==============================] - 0s 476us/step - loss: 4.6143 - accuracy: 0.6655\n",
      "Epoch 493/500\n",
      "34/34 [==============================] - 0s 582us/step - loss: 4.5883 - accuracy: 0.6773\n",
      "Epoch 494/500\n",
      "34/34 [==============================] - 0s 501us/step - loss: 4.5948 - accuracy: 0.6761\n",
      "Epoch 495/500\n",
      "34/34 [==============================] - 0s 550us/step - loss: 4.6675 - accuracy: 0.6743\n",
      "Epoch 496/500\n",
      "34/34 [==============================] - 0s 531us/step - loss: 4.7017 - accuracy: 0.6678\n",
      "Epoch 497/500\n",
      "34/34 [==============================] - 0s 490us/step - loss: 4.6532 - accuracy: 0.6708\n",
      "Epoch 498/500\n",
      "34/34 [==============================] - 0s 388us/step - loss: 4.5723 - accuracy: 0.6631\n",
      "Epoch 499/500\n",
      "34/34 [==============================] - 0s 411us/step - loss: 4.5738 - accuracy: 0.6832\n",
      "Epoch 500/500\n",
      "34/34 [==============================] - 0s 702us/step - loss: 4.5848 - accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(32, activation='relu', input_dim=len(X_train.columns)),\n",
    "\ttf.keras.layers.Dense(128, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 408us/step\n",
      "[ 0.13192686  2.9038932   6.558611   19.83437     1.3866603   8.018319\n",
      "  3.737169    7.422592   13.322785   10.82431     1.7998607   1.0251163\n",
      " -0.02559202  0.21237509]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_goals</th>\n",
       "      <th>away_goals</th>\n",
       "      <th>home_shots</th>\n",
       "      <th>away_shots</th>\n",
       "      <th>home_shots_on_target</th>\n",
       "      <th>away_shots_on_target</th>\n",
       "      <th>home_corners</th>\n",
       "      <th>away_corners</th>\n",
       "      <th>home_fouls</th>\n",
       "      <th>away_fouls</th>\n",
       "      <th>home_yellow_cards</th>\n",
       "      <th>away_yellow_cards</th>\n",
       "      <th>home_red_cards</th>\n",
       "      <th>away_red_cards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      home_goals  away_goals  home_shots  away_shots  home_shots_on_target  \\\n",
       "1634           2           1          13          16                     4   \n",
       "1479           2           4          16          15                     6   \n",
       "25             2           1           6          23                     2   \n",
       "1686           2           1          12          17                     4   \n",
       "1454           1           3           9          15                     3   \n",
       "\n",
       "      away_shots_on_target  home_corners  away_corners  home_fouls  \\\n",
       "1634                     3             3             5           8   \n",
       "1479                     9             3             3          13   \n",
       "25                       6             4             8          14   \n",
       "1686                     5             6             8          11   \n",
       "1454                     7             3             8           8   \n",
       "\n",
       "      away_fouls  home_yellow_cards  away_yellow_cards  home_red_cards  \\\n",
       "1634          10                  1                  1               0   \n",
       "1479          19                  6                  3               0   \n",
       "25            11                  4                  2               0   \n",
       "1686           7                  3                  1               0   \n",
       "1454          15                  0                  2               0   \n",
       "\n",
       "      away_red_cards  \n",
       "1634               0  \n",
       "1479               0  \n",
       "25                 0  \n",
       "1686               0  \n",
       "1454               0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "print(y_hat[1])\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above experiments show us the accuracy of each model increases with an increased number of features up to a point, it seem somewhere between 15 and 20 features, where the accuracy on the training data peaks. I will use 15 principal components going forward for the investigations, as this seems to yield the highest accuracy of those tested here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of predicting exact values for the match facts, I am not expecting exact matches between model and the actual results, just hoping for a close approximation, or at the very least, the correct side with the higher value, i.e. home team scores more goals than the away team is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15 PC model build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         goals   assists  direct_goal_contributions  non_penalty_goals  \\\n",
      "618   0.282813  0.073807                   0.356620           0.269951   \n",
      "1581  1.264687  0.842364                   2.107051           1.242048   \n",
      "1600  0.043288 -0.022940                   0.020348           0.069050   \n",
      "812  -0.163778 -0.007934                  -0.171712          -0.144840   \n",
      "2113 -0.150000 -0.039141                  -0.189141          -0.137002   \n",
      "...        ...       ...                        ...                ...   \n",
      "1542 -0.093617 -0.254741                  -0.348359          -0.078979   \n",
      "2062 -0.081567  0.127542                   0.045975          -0.044369   \n",
      "479  -0.660662 -0.268441                  -0.929103          -0.544726   \n",
      "561  -0.200871  0.054574                  -0.146297          -0.221102   \n",
      "1785 -0.501214 -0.169302                  -0.670516          -0.484662   \n",
      "\n",
      "      penalties_scored  penalties_attempted  yellow_cards  red_cards  \\\n",
      "618           0.012862             0.047048     -0.051462   0.010154   \n",
      "1581          0.022639             0.009442      0.984779   0.058485   \n",
      "1600         -0.025762            -0.021131      0.497787   0.004745   \n",
      "812          -0.018938            -0.049900      0.391365   0.036478   \n",
      "2113         -0.012998            -0.012998     -0.092022  -0.001071   \n",
      "...                ...                  ...           ...        ...   \n",
      "1542         -0.014639            -0.013673     -0.627743  -0.041233   \n",
      "2062         -0.037198            -0.056972      0.147570  -0.016625   \n",
      "479          -0.115936            -0.129202     -0.484446   0.012940   \n",
      "561           0.020231             0.000382     -0.386519  -0.041188   \n",
      "1785         -0.016552            -0.023804     -0.299180  -0.009939   \n",
      "\n",
      "      expected_goals  non_penalty_expected_goals  ...  clean_sheets  \\\n",
      "618         0.159696                    0.122860  ...      0.073613   \n",
      "1581        1.128495                    1.121746  ...      0.199451   \n",
      "1600        0.119355                    0.134902  ...     -0.086652   \n",
      "812        -0.336455                   -0.296380  ...      0.540534   \n",
      "2113       -0.084528                   -0.074129  ...      0.023546   \n",
      "...              ...                         ...  ...           ...   \n",
      "1542       -0.135970                   -0.129062  ...     -0.326425   \n",
      "2062       -0.080749                   -0.036624  ...     -0.091512   \n",
      "479        -0.653208                   -0.549162  ...      0.416948   \n",
      "561        -0.217464                   -0.214285  ...     -0.180560   \n",
      "1785       -0.577368                   -0.559658  ...     -0.129443   \n",
      "\n",
      "      penalties_faced  penalties_allowed  penalties_saved  penalties_missed  \\\n",
      "618          0.027645           0.023213         0.004432          0.000000   \n",
      "1581         0.228345           0.199423         0.016306          0.012616   \n",
      "1600        -0.118558          -0.107670        -0.003631         -0.007258   \n",
      "812          0.151777           0.115975         0.035802          0.000000   \n",
      "2113         0.023546           0.023546         0.000000          0.000000   \n",
      "...               ...                ...              ...               ...   \n",
      "1542        -0.151474          -0.128745        -0.020360         -0.002368   \n",
      "2062        -0.094377          -0.064168        -0.015281         -0.014928   \n",
      "479          0.100399           0.074238         0.016466          0.009695   \n",
      "561         -0.054894          -0.051570        -0.003324          0.000000   \n",
      "1785        -0.056176          -0.042719        -0.009117         -0.004340   \n",
      "\n",
      "      home_team_at_home_mean_goal_difference  \\\n",
      "618                                      0.2   \n",
      "1581                                     0.0   \n",
      "1600                                     0.0   \n",
      "812                                      0.6   \n",
      "2113                                    -0.6   \n",
      "...                                      ...   \n",
      "1542                                     0.0   \n",
      "2062                                     1.8   \n",
      "479                                     -0.2   \n",
      "561                                      2.6   \n",
      "1785                                     0.6   \n",
      "\n",
      "      home_team_overall_mean_goal_difference  \\\n",
      "618                                     -1.6   \n",
      "1581                                     0.6   \n",
      "1600                                     0.0   \n",
      "812                                      0.6   \n",
      "2113                                     0.4   \n",
      "...                                      ...   \n",
      "1542                                     0.2   \n",
      "2062                                     0.2   \n",
      "479                                      0.0   \n",
      "561                                      0.8   \n",
      "1785                                     1.8   \n",
      "\n",
      "      away_team_at_away_mean_goal_difference  \\\n",
      "618                                     -1.0   \n",
      "1581                                    -0.8   \n",
      "1600                                    -0.8   \n",
      "812                                      0.4   \n",
      "2113                                     1.2   \n",
      "...                                      ...   \n",
      "1542                                    -0.4   \n",
      "2062                                    -0.4   \n",
      "479                                     -1.6   \n",
      "561                                     -0.6   \n",
      "1785                                    -1.4   \n",
      "\n",
      "      away_team_overall_mean_goal_difference  head_to_head_goal_difference  \n",
      "618                                      0.2                             4  \n",
      "1581                                    -2.4                             2  \n",
      "1600                                    -2.4                             1  \n",
      "812                                      0.8                            -6  \n",
      "2113                                     1.2                            -1  \n",
      "...                                      ...                           ...  \n",
      "1542                                     0.2                             4  \n",
      "2062                                     0.0                             2  \n",
      "479                                      0.2                             1  \n",
      "561                                      0.2                             3  \n",
      "1785                                    -1.6                            -2  \n",
      "\n",
      "[1692 rows x 75 columns]\n"
     ]
    }
   ],
   "source": [
    "X = combined[stats_columns]\n",
    "y = combined[output_columns]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=543)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_x_scaler = StandardScaler(copy=True).fit(X)\n",
    "whole_x_train = whole_x_scaler.transform(X)\n",
    "dump(whole_x_scaler, '../prediction_scaler.bin')\n",
    "\n",
    "\n",
    "# y_scaler = StandardScaler(copy=True).fit(y_train)\n",
    "\n",
    "X_scaler = StandardScaler(copy=True).fit(X_train)\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# y_train = y_scaler.transform(y_train)\n",
    "# y_test = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=15\n",
    "# print(X_train)\n",
    "# pca = PCA(n_components = n, random_state=576)\n",
    "# pca.fit(X)\n",
    "# feature_to_pc_map = pd.DataFrame(pca.components_, columns=stats_columns)\n",
    "# feature_to_pc_map.to_csv(\"../files/feature_to_15_pcs.csv\")\n",
    "\n",
    "# dump(pca, '../prediction_pca.bin')\n",
    "# whole_X_pca = pca.transform(whole_x_train)\n",
    "\n",
    "# pca = PCA(n_components = n, random_state=576)\n",
    "# pca.fit(X_train)\n",
    "# X_train = pca.transform(X_train)\n",
    "# X_test = pca.transform(X_test)\n",
    "\n",
    "\n",
    "# feature_to_pc_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below table shows the breakdown of each principle component in terms of the proportion of the value from each of the table columns used to make it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>goals</th>\n",
       "      <th>assists</th>\n",
       "      <th>direct_goal_contributions</th>\n",
       "      <th>non_penalty_goals</th>\n",
       "      <th>penalties_scored</th>\n",
       "      <th>penalties_attempted</th>\n",
       "      <th>yellow_cards</th>\n",
       "      <th>red_cards</th>\n",
       "      <th>expected_goals</th>\n",
       "      <th>non_penalty_expected_goals</th>\n",
       "      <th>...</th>\n",
       "      <th>clean_sheets</th>\n",
       "      <th>penalties_faced</th>\n",
       "      <th>penalties_allowed</th>\n",
       "      <th>penalties_saved</th>\n",
       "      <th>penalties_missed</th>\n",
       "      <th>home_team_at_home_mean_goal_difference</th>\n",
       "      <th>home_team_overall_mean_goal_difference</th>\n",
       "      <th>away_team_at_away_mean_goal_difference</th>\n",
       "      <th>away_team_overall_mean_goal_difference</th>\n",
       "      <th>head_to_head_goal_difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>principle_component_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.113774</td>\n",
       "      <td>0.125960</td>\n",
       "      <td>0.124219</td>\n",
       "      <td>0.114204</td>\n",
       "      <td>0.067503</td>\n",
       "      <td>0.069344</td>\n",
       "      <td>0.132306</td>\n",
       "      <td>0.067179</td>\n",
       "      <td>0.119271</td>\n",
       "      <td>0.120094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050092</td>\n",
       "      <td>0.055879</td>\n",
       "      <td>0.053978</td>\n",
       "      <td>0.046351</td>\n",
       "      <td>0.033491</td>\n",
       "      <td>0.006673</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>-0.008737</td>\n",
       "      <td>-0.020654</td>\n",
       "      <td>0.010048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.108341</td>\n",
       "      <td>-0.087107</td>\n",
       "      <td>-0.105071</td>\n",
       "      <td>-0.107247</td>\n",
       "      <td>-0.073311</td>\n",
       "      <td>-0.076950</td>\n",
       "      <td>0.013237</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>-0.100288</td>\n",
       "      <td>-0.097775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265032</td>\n",
       "      <td>0.273328</td>\n",
       "      <td>0.261904</td>\n",
       "      <td>0.226938</td>\n",
       "      <td>0.179223</td>\n",
       "      <td>0.011752</td>\n",
       "      <td>0.009510</td>\n",
       "      <td>-0.015483</td>\n",
       "      <td>-0.010714</td>\n",
       "      <td>0.007697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.202537</td>\n",
       "      <td>0.086986</td>\n",
       "      <td>0.165897</td>\n",
       "      <td>0.189020</td>\n",
       "      <td>0.205997</td>\n",
       "      <td>0.208038</td>\n",
       "      <td>-0.093832</td>\n",
       "      <td>-0.062279</td>\n",
       "      <td>0.180007</td>\n",
       "      <td>0.164145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155262</td>\n",
       "      <td>0.171381</td>\n",
       "      <td>0.165930</td>\n",
       "      <td>0.140269</td>\n",
       "      <td>0.103225</td>\n",
       "      <td>-0.004638</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>-0.005040</td>\n",
       "      <td>-0.006613</td>\n",
       "      <td>-0.009494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.077722</td>\n",
       "      <td>-0.073888</td>\n",
       "      <td>0.020491</td>\n",
       "      <td>0.016399</td>\n",
       "      <td>0.416381</td>\n",
       "      <td>0.403185</td>\n",
       "      <td>0.063660</td>\n",
       "      <td>0.043584</td>\n",
       "      <td>0.074828</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042587</td>\n",
       "      <td>-0.046033</td>\n",
       "      <td>-0.036961</td>\n",
       "      <td>-0.045541</td>\n",
       "      <td>-0.070445</td>\n",
       "      <td>-0.212114</td>\n",
       "      <td>-0.169163</td>\n",
       "      <td>0.162730</td>\n",
       "      <td>0.147332</td>\n",
       "      <td>-0.237649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.022637</td>\n",
       "      <td>0.050171</td>\n",
       "      <td>0.005562</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>-0.211107</td>\n",
       "      <td>-0.205521</td>\n",
       "      <td>-0.007683</td>\n",
       "      <td>-0.014236</td>\n",
       "      <td>-0.023440</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022911</td>\n",
       "      <td>0.025706</td>\n",
       "      <td>0.038543</td>\n",
       "      <td>-0.024770</td>\n",
       "      <td>-0.004912</td>\n",
       "      <td>-0.456012</td>\n",
       "      <td>-0.278414</td>\n",
       "      <td>0.437228</td>\n",
       "      <td>0.264195</td>\n",
       "      <td>-0.510897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.165465</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>-0.052755</td>\n",
       "      <td>-0.200234</td>\n",
       "      <td>0.107008</td>\n",
       "      <td>0.111622</td>\n",
       "      <td>-0.081601</td>\n",
       "      <td>-0.314774</td>\n",
       "      <td>-0.190525</td>\n",
       "      <td>-0.229676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033917</td>\n",
       "      <td>0.014824</td>\n",
       "      <td>0.006680</td>\n",
       "      <td>0.047628</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>-0.002653</td>\n",
       "      <td>0.045517</td>\n",
       "      <td>0.071929</td>\n",
       "      <td>0.066960</td>\n",
       "      <td>-0.037169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.011909</td>\n",
       "      <td>0.024711</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>-0.012000</td>\n",
       "      <td>-0.006790</td>\n",
       "      <td>-0.005914</td>\n",
       "      <td>-0.017838</td>\n",
       "      <td>-0.019332</td>\n",
       "      <td>-0.017668</td>\n",
       "      <td>-0.018552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>-0.005595</td>\n",
       "      <td>-0.011613</td>\n",
       "      <td>0.006353</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>-0.361734</td>\n",
       "      <td>-0.567237</td>\n",
       "      <td>-0.407687</td>\n",
       "      <td>-0.606364</td>\n",
       "      <td>-0.019497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.131587</td>\n",
       "      <td>0.113940</td>\n",
       "      <td>0.130893</td>\n",
       "      <td>0.169485</td>\n",
       "      <td>-0.146680</td>\n",
       "      <td>-0.133791</td>\n",
       "      <td>-0.060934</td>\n",
       "      <td>-0.437499</td>\n",
       "      <td>0.107816</td>\n",
       "      <td>0.141169</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027321</td>\n",
       "      <td>-0.076557</td>\n",
       "      <td>-0.064223</td>\n",
       "      <td>-0.073002</td>\n",
       "      <td>-0.101401</td>\n",
       "      <td>0.021069</td>\n",
       "      <td>0.192434</td>\n",
       "      <td>-0.016546</td>\n",
       "      <td>-0.121426</td>\n",
       "      <td>-0.083916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.034019</td>\n",
       "      <td>-0.075770</td>\n",
       "      <td>-0.052478</td>\n",
       "      <td>-0.051972</td>\n",
       "      <td>0.086926</td>\n",
       "      <td>0.085749</td>\n",
       "      <td>0.049404</td>\n",
       "      <td>-0.386531</td>\n",
       "      <td>-0.005432</td>\n",
       "      <td>-0.020436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008438</td>\n",
       "      <td>0.024007</td>\n",
       "      <td>0.025153</td>\n",
       "      <td>0.073619</td>\n",
       "      <td>-0.095625</td>\n",
       "      <td>-0.200095</td>\n",
       "      <td>0.460412</td>\n",
       "      <td>0.207967</td>\n",
       "      <td>-0.491725</td>\n",
       "      <td>-0.213783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.012980</td>\n",
       "      <td>-0.041272</td>\n",
       "      <td>-0.008222</td>\n",
       "      <td>0.012620</td>\n",
       "      <td>0.010156</td>\n",
       "      <td>0.016755</td>\n",
       "      <td>0.037689</td>\n",
       "      <td>-0.593559</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>0.037388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001387</td>\n",
       "      <td>-0.013282</td>\n",
       "      <td>-0.043227</td>\n",
       "      <td>-0.223207</td>\n",
       "      <td>0.595638</td>\n",
       "      <td>0.107998</td>\n",
       "      <td>-0.269437</td>\n",
       "      <td>-0.017506</td>\n",
       "      <td>0.188874</td>\n",
       "      <td>0.116769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.020034</td>\n",
       "      <td>0.067225</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.026806</td>\n",
       "      <td>-0.028354</td>\n",
       "      <td>-0.022371</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>0.411767</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035855</td>\n",
       "      <td>-0.027361</td>\n",
       "      <td>-0.086603</td>\n",
       "      <td>-0.162037</td>\n",
       "      <td>0.679639</td>\n",
       "      <td>-0.111514</td>\n",
       "      <td>0.324372</td>\n",
       "      <td>0.090993</td>\n",
       "      <td>-0.246258</td>\n",
       "      <td>-0.173898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.037877</td>\n",
       "      <td>-0.002338</td>\n",
       "      <td>0.023537</td>\n",
       "      <td>0.052542</td>\n",
       "      <td>-0.064792</td>\n",
       "      <td>-0.051419</td>\n",
       "      <td>0.054849</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.047436</td>\n",
       "      <td>0.060775</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012202</td>\n",
       "      <td>0.046192</td>\n",
       "      <td>0.081103</td>\n",
       "      <td>-0.028183</td>\n",
       "      <td>-0.125955</td>\n",
       "      <td>0.385285</td>\n",
       "      <td>-0.297501</td>\n",
       "      <td>0.609694</td>\n",
       "      <td>-0.376999</td>\n",
       "      <td>0.142304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.082474</td>\n",
       "      <td>-0.002857</td>\n",
       "      <td>-0.054448</td>\n",
       "      <td>-0.112476</td>\n",
       "      <td>0.129482</td>\n",
       "      <td>0.105364</td>\n",
       "      <td>-0.110646</td>\n",
       "      <td>0.077151</td>\n",
       "      <td>-0.093361</td>\n",
       "      <td>-0.120725</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>-0.073607</td>\n",
       "      <td>-0.093274</td>\n",
       "      <td>-0.083006</td>\n",
       "      <td>0.160096</td>\n",
       "      <td>0.266924</td>\n",
       "      <td>-0.162213</td>\n",
       "      <td>0.291565</td>\n",
       "      <td>-0.177232</td>\n",
       "      <td>0.008622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.068248</td>\n",
       "      <td>-0.062600</td>\n",
       "      <td>0.018911</td>\n",
       "      <td>0.081906</td>\n",
       "      <td>-0.040033</td>\n",
       "      <td>-0.047270</td>\n",
       "      <td>0.040359</td>\n",
       "      <td>-0.069113</td>\n",
       "      <td>0.065236</td>\n",
       "      <td>0.080136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012656</td>\n",
       "      <td>0.032328</td>\n",
       "      <td>-0.016961</td>\n",
       "      <td>0.194793</td>\n",
       "      <td>0.079855</td>\n",
       "      <td>0.262871</td>\n",
       "      <td>-0.079464</td>\n",
       "      <td>-0.097071</td>\n",
       "      <td>-0.007509</td>\n",
       "      <td>-0.341852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.039708</td>\n",
       "      <td>0.050936</td>\n",
       "      <td>-0.005162</td>\n",
       "      <td>-0.047031</td>\n",
       "      <td>0.019545</td>\n",
       "      <td>0.018591</td>\n",
       "      <td>0.018343</td>\n",
       "      <td>0.045220</td>\n",
       "      <td>-0.026972</td>\n",
       "      <td>-0.032693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007309</td>\n",
       "      <td>0.009345</td>\n",
       "      <td>0.061394</td>\n",
       "      <td>-0.158549</td>\n",
       "      <td>-0.088958</td>\n",
       "      <td>0.504577</td>\n",
       "      <td>-0.059553</td>\n",
       "      <td>-0.294043</td>\n",
       "      <td>-0.035747</td>\n",
       "      <td>-0.643028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.075951</td>\n",
       "      <td>0.132382</td>\n",
       "      <td>0.102360</td>\n",
       "      <td>0.083162</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>-0.009322</td>\n",
       "      <td>-0.074060</td>\n",
       "      <td>0.043737</td>\n",
       "      <td>0.036077</td>\n",
       "      <td>0.041798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029288</td>\n",
       "      <td>-0.073384</td>\n",
       "      <td>-0.246642</td>\n",
       "      <td>0.586839</td>\n",
       "      <td>0.114230</td>\n",
       "      <td>0.054665</td>\n",
       "      <td>-0.122003</td>\n",
       "      <td>0.067957</td>\n",
       "      <td>0.063091</td>\n",
       "      <td>0.052716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.129811</td>\n",
       "      <td>0.090371</td>\n",
       "      <td>0.062424</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.001905</td>\n",
       "      <td>-0.083045</td>\n",
       "      <td>0.072434</td>\n",
       "      <td>0.044067</td>\n",
       "      <td>0.048315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.118970</td>\n",
       "      <td>0.299916</td>\n",
       "      <td>-0.573914</td>\n",
       "      <td>-0.111542</td>\n",
       "      <td>-0.053590</td>\n",
       "      <td>-0.023294</td>\n",
       "      <td>0.015888</td>\n",
       "      <td>0.038038</td>\n",
       "      <td>0.131247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.032315</td>\n",
       "      <td>0.102791</td>\n",
       "      <td>0.020485</td>\n",
       "      <td>-0.037167</td>\n",
       "      <td>0.009252</td>\n",
       "      <td>0.003508</td>\n",
       "      <td>0.106343</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>-0.031458</td>\n",
       "      <td>-0.035375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.670903</td>\n",
       "      <td>0.371526</td>\n",
       "      <td>0.406680</td>\n",
       "      <td>0.154468</td>\n",
       "      <td>0.139837</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>-0.002116</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.005778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.068132</td>\n",
       "      <td>0.166848</td>\n",
       "      <td>0.023118</td>\n",
       "      <td>-0.079061</td>\n",
       "      <td>0.023708</td>\n",
       "      <td>-0.022556</td>\n",
       "      <td>-0.009018</td>\n",
       "      <td>-0.005179</td>\n",
       "      <td>-0.013250</td>\n",
       "      <td>-0.011275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029049</td>\n",
       "      <td>0.031380</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>0.067883</td>\n",
       "      <td>-0.043775</td>\n",
       "      <td>-0.029572</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.069707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.064690</td>\n",
       "      <td>-0.283660</td>\n",
       "      <td>-0.072353</td>\n",
       "      <td>0.074294</td>\n",
       "      <td>-0.017861</td>\n",
       "      <td>-0.008688</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>-0.016851</td>\n",
       "      <td>0.070864</td>\n",
       "      <td>0.079688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.084707</td>\n",
       "      <td>0.215089</td>\n",
       "      <td>0.231063</td>\n",
       "      <td>0.140573</td>\n",
       "      <td>0.022562</td>\n",
       "      <td>-0.002150</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>-0.052653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.056095</td>\n",
       "      <td>0.271611</td>\n",
       "      <td>0.073059</td>\n",
       "      <td>-0.065622</td>\n",
       "      <td>0.022693</td>\n",
       "      <td>-0.007084</td>\n",
       "      <td>0.092527</td>\n",
       "      <td>-0.036816</td>\n",
       "      <td>-0.061714</td>\n",
       "      <td>-0.067575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.462774</td>\n",
       "      <td>0.224092</td>\n",
       "      <td>0.254266</td>\n",
       "      <td>0.112313</td>\n",
       "      <td>-0.016578</td>\n",
       "      <td>0.018693</td>\n",
       "      <td>-0.022814</td>\n",
       "      <td>-0.014252</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>0.015451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.011795</td>\n",
       "      <td>0.140706</td>\n",
       "      <td>0.049004</td>\n",
       "      <td>-0.011586</td>\n",
       "      <td>-0.008525</td>\n",
       "      <td>0.012608</td>\n",
       "      <td>0.315752</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>-0.021781</td>\n",
       "      <td>-0.025603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256353</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.012779</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.001875</td>\n",
       "      <td>-0.014602</td>\n",
       "      <td>-0.003235</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>0.014477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.247534</td>\n",
       "      <td>-0.085864</td>\n",
       "      <td>-0.194524</td>\n",
       "      <td>-0.280759</td>\n",
       "      <td>0.047171</td>\n",
       "      <td>-0.002537</td>\n",
       "      <td>0.235561</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>0.013658</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017255</td>\n",
       "      <td>-0.054641</td>\n",
       "      <td>-0.072659</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.023513</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>-0.010857</td>\n",
       "      <td>-0.003635</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>0.027704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.013021</td>\n",
       "      <td>-0.029614</td>\n",
       "      <td>-0.020333</td>\n",
       "      <td>-0.020627</td>\n",
       "      <td>0.037686</td>\n",
       "      <td>-0.039383</td>\n",
       "      <td>-0.688022</td>\n",
       "      <td>0.025674</td>\n",
       "      <td>-0.012655</td>\n",
       "      <td>-0.007211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041187</td>\n",
       "      <td>0.073229</td>\n",
       "      <td>0.089118</td>\n",
       "      <td>-0.001360</td>\n",
       "      <td>0.017265</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.005895</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>-0.003742</td>\n",
       "      <td>-0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.158714</td>\n",
       "      <td>-0.385318</td>\n",
       "      <td>-0.052503</td>\n",
       "      <td>0.177939</td>\n",
       "      <td>-0.017758</td>\n",
       "      <td>-0.002807</td>\n",
       "      <td>0.323226</td>\n",
       "      <td>0.016338</td>\n",
       "      <td>-0.013989</td>\n",
       "      <td>-0.015492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119615</td>\n",
       "      <td>0.065309</td>\n",
       "      <td>0.092856</td>\n",
       "      <td>-0.043872</td>\n",
       "      <td>-0.008702</td>\n",
       "      <td>-0.007830</td>\n",
       "      <td>-0.013492</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.016317</td>\n",
       "      <td>0.048045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               goals   assists  direct_goal_contributions  \\\n",
       "principle_component_number                                                  \n",
       "0                           0.113774  0.125960                   0.124219   \n",
       "1                          -0.108341 -0.087107                  -0.105071   \n",
       "2                           0.202537  0.086986                   0.165897   \n",
       "3                           0.077722 -0.073888                   0.020491   \n",
       "4                          -0.022637  0.050171                   0.005562   \n",
       "5                          -0.165465  0.134615                  -0.052755   \n",
       "6                          -0.011909  0.024711                   0.002249   \n",
       "7                           0.131587  0.113940                   0.130893   \n",
       "8                          -0.034019 -0.075770                  -0.052478   \n",
       "9                           0.012980 -0.041272                  -0.008222   \n",
       "10                          0.020034  0.067225                   0.040002   \n",
       "11                          0.037877 -0.002338                   0.023537   \n",
       "12                         -0.082474 -0.002857                  -0.054448   \n",
       "13                          0.068248 -0.062600                   0.018911   \n",
       "14                         -0.039708  0.050936                  -0.005162   \n",
       "15                          0.075951  0.132382                   0.102360   \n",
       "16                          0.059000  0.129811                   0.090371   \n",
       "17                         -0.032315  0.102791                   0.020485   \n",
       "18                         -0.068132  0.166848                   0.023118   \n",
       "19                          0.064690 -0.283660                  -0.072353   \n",
       "20                         -0.056095  0.271611                   0.073059   \n",
       "21                         -0.011795  0.140706                   0.049004   \n",
       "22                         -0.247534 -0.085864                  -0.194524   \n",
       "23                         -0.013021 -0.029614                  -0.020333   \n",
       "24                          0.158714 -0.385318                  -0.052503   \n",
       "\n",
       "                            non_penalty_goals  penalties_scored  \\\n",
       "principle_component_number                                        \n",
       "0                                    0.114204          0.067503   \n",
       "1                                   -0.107247         -0.073311   \n",
       "2                                    0.189020          0.205997   \n",
       "3                                    0.016399          0.416381   \n",
       "4                                    0.010173         -0.211107   \n",
       "5                                   -0.200234          0.107008   \n",
       "6                                   -0.012000         -0.006790   \n",
       "7                                    0.169485         -0.146680   \n",
       "8                                   -0.051972          0.086926   \n",
       "9                                    0.012620          0.010156   \n",
       "10                                   0.026806         -0.028354   \n",
       "11                                   0.052542         -0.064792   \n",
       "12                                  -0.112476          0.129482   \n",
       "13                                   0.081906         -0.040033   \n",
       "14                                  -0.047031          0.019545   \n",
       "15                                   0.083162          0.003457   \n",
       "16                                   0.062424          0.015771   \n",
       "17                                  -0.037167          0.009252   \n",
       "18                                  -0.079061          0.023708   \n",
       "19                                   0.074294         -0.017861   \n",
       "20                                  -0.065622          0.022693   \n",
       "21                                  -0.011586         -0.008525   \n",
       "22                                  -0.280759          0.047171   \n",
       "23                                  -0.020627          0.037686   \n",
       "24                                   0.177939         -0.017758   \n",
       "\n",
       "                            penalties_attempted  yellow_cards  red_cards  \\\n",
       "principle_component_number                                                 \n",
       "0                                      0.069344      0.132306   0.067179   \n",
       "1                                     -0.076950      0.013237   0.020605   \n",
       "2                                      0.208038     -0.093832  -0.062279   \n",
       "3                                      0.403185      0.063660   0.043584   \n",
       "4                                     -0.205521     -0.007683  -0.014236   \n",
       "5                                      0.111622     -0.081601  -0.314774   \n",
       "6                                     -0.005914     -0.017838  -0.019332   \n",
       "7                                     -0.133791     -0.060934  -0.437499   \n",
       "8                                      0.085749      0.049404  -0.386531   \n",
       "9                                      0.016755      0.037689  -0.593559   \n",
       "10                                    -0.022371      0.009392   0.411767   \n",
       "11                                    -0.051419      0.054849   0.031726   \n",
       "12                                     0.105364     -0.110646   0.077151   \n",
       "13                                    -0.047270      0.040359  -0.069113   \n",
       "14                                     0.018591      0.018343   0.045220   \n",
       "15                                    -0.009322     -0.074060   0.043737   \n",
       "16                                     0.001905     -0.083045   0.072434   \n",
       "17                                     0.003508      0.106343   0.001071   \n",
       "18                                    -0.022556     -0.009018  -0.005179   \n",
       "19                                    -0.008688     -0.036385  -0.016851   \n",
       "20                                    -0.007084      0.092527  -0.036816   \n",
       "21                                     0.012608      0.315752  -0.001330   \n",
       "22                                    -0.002537      0.235561   0.007029   \n",
       "23                                    -0.039383     -0.688022   0.025674   \n",
       "24                                    -0.002807      0.323226   0.016338   \n",
       "\n",
       "                            expected_goals  non_penalty_expected_goals  ...  \\\n",
       "principle_component_number                                              ...   \n",
       "0                                 0.119271                    0.120094  ...   \n",
       "1                                -0.100288                   -0.097775  ...   \n",
       "2                                 0.180007                    0.164145  ...   \n",
       "3                                 0.074828                    0.014778  ...   \n",
       "4                                -0.023440                    0.008881  ...   \n",
       "5                                -0.190525                   -0.229676  ...   \n",
       "6                                -0.017668                   -0.018552  ...   \n",
       "7                                 0.107816                    0.141169  ...   \n",
       "8                                -0.005432                   -0.020436  ...   \n",
       "9                                 0.036501                    0.037388  ...   \n",
       "10                                0.011563                    0.016566  ...   \n",
       "11                                0.047436                    0.060775  ...   \n",
       "12                               -0.093361                   -0.120725  ...   \n",
       "13                                0.065236                    0.080136  ...   \n",
       "14                               -0.026972                   -0.032693  ...   \n",
       "15                                0.036077                    0.041798  ...   \n",
       "16                                0.044067                    0.048315  ...   \n",
       "17                               -0.031458                   -0.035375  ...   \n",
       "18                               -0.013250                   -0.011275  ...   \n",
       "19                                0.070864                    0.079688  ...   \n",
       "20                               -0.061714                   -0.067575  ...   \n",
       "21                               -0.021781                   -0.025603  ...   \n",
       "22                                0.013658                    0.015183  ...   \n",
       "23                               -0.012655                   -0.007211  ...   \n",
       "24                               -0.013989                   -0.015492  ...   \n",
       "\n",
       "                            clean_sheets  penalties_faced  penalties_allowed  \\\n",
       "principle_component_number                                                     \n",
       "0                               0.050092         0.055879           0.053978   \n",
       "1                               0.265032         0.273328           0.261904   \n",
       "2                               0.155262         0.171381           0.165930   \n",
       "3                              -0.042587        -0.046033          -0.036961   \n",
       "4                               0.022911         0.025706           0.038543   \n",
       "5                               0.033917         0.014824           0.006680   \n",
       "6                               0.000182        -0.005595          -0.011613   \n",
       "7                              -0.027321        -0.076557          -0.064223   \n",
       "8                              -0.008438         0.024007           0.025153   \n",
       "9                              -0.001387        -0.013282          -0.043227   \n",
       "10                              0.035855        -0.027361          -0.086603   \n",
       "11                             -0.012202         0.046192           0.081103   \n",
       "12                              0.025200        -0.073607          -0.093274   \n",
       "13                              0.012656         0.032328          -0.016961   \n",
       "14                             -0.007309         0.009345           0.061394   \n",
       "15                             -0.029288        -0.073384          -0.246642   \n",
       "16                              0.005742         0.118970           0.299916   \n",
       "17                             -0.670903         0.371526           0.406680   \n",
       "18                             -0.029049         0.031380           0.028728   \n",
       "19                              0.084707         0.215089           0.231063   \n",
       "20                              0.462774         0.224092           0.254266   \n",
       "21                              0.256353         0.003143           0.012779   \n",
       "22                             -0.017255        -0.054641          -0.072659   \n",
       "23                              0.041187         0.073229           0.089118   \n",
       "24                              0.119615         0.065309           0.092856   \n",
       "\n",
       "                            penalties_saved  penalties_missed  \\\n",
       "principle_component_number                                      \n",
       "0                                  0.046351          0.033491   \n",
       "1                                  0.226938          0.179223   \n",
       "2                                  0.140269          0.103225   \n",
       "3                                 -0.045541         -0.070445   \n",
       "4                                 -0.024770         -0.004912   \n",
       "5                                  0.047628          0.002970   \n",
       "6                                  0.006353          0.023372   \n",
       "7                                 -0.073002         -0.101401   \n",
       "8                                  0.073619         -0.095625   \n",
       "9                                 -0.223207          0.595638   \n",
       "10                                -0.162037          0.679639   \n",
       "11                                -0.028183         -0.125955   \n",
       "12                                -0.083006          0.160096   \n",
       "13                                 0.194793          0.079855   \n",
       "14                                -0.158549         -0.088958   \n",
       "15                                 0.586839          0.114230   \n",
       "16                                -0.573914         -0.111542   \n",
       "17                                 0.154468          0.139837   \n",
       "18                                 0.067883         -0.043775   \n",
       "19                                 0.140573          0.022562   \n",
       "20                                 0.112313         -0.016578   \n",
       "21                                -0.036103         -0.001875   \n",
       "22                                 0.006384          0.023513   \n",
       "23                                -0.001360          0.017265   \n",
       "24                                -0.043872         -0.008702   \n",
       "\n",
       "                            home_team_at_home_mean_goal_difference  \\\n",
       "principle_component_number                                           \n",
       "0                                                         0.006673   \n",
       "1                                                         0.011752   \n",
       "2                                                        -0.004638   \n",
       "3                                                        -0.212114   \n",
       "4                                                        -0.456012   \n",
       "5                                                        -0.002653   \n",
       "6                                                        -0.361734   \n",
       "7                                                         0.021069   \n",
       "8                                                        -0.200095   \n",
       "9                                                         0.107998   \n",
       "10                                                       -0.111514   \n",
       "11                                                        0.385285   \n",
       "12                                                        0.266924   \n",
       "13                                                        0.262871   \n",
       "14                                                        0.504577   \n",
       "15                                                        0.054665   \n",
       "16                                                       -0.053590   \n",
       "17                                                        0.000149   \n",
       "18                                                       -0.029572   \n",
       "19                                                       -0.002150   \n",
       "20                                                        0.018693   \n",
       "21                                                       -0.014602   \n",
       "22                                                        0.002778   \n",
       "23                                                        0.000618   \n",
       "24                                                       -0.007830   \n",
       "\n",
       "                            home_team_overall_mean_goal_difference  \\\n",
       "principle_component_number                                           \n",
       "0                                                         0.019182   \n",
       "1                                                         0.009510   \n",
       "2                                                         0.008281   \n",
       "3                                                        -0.169163   \n",
       "4                                                        -0.278414   \n",
       "5                                                         0.045517   \n",
       "6                                                        -0.567237   \n",
       "7                                                         0.192434   \n",
       "8                                                         0.460412   \n",
       "9                                                        -0.269437   \n",
       "10                                                        0.324372   \n",
       "11                                                       -0.297501   \n",
       "12                                                       -0.162213   \n",
       "13                                                       -0.079464   \n",
       "14                                                       -0.059553   \n",
       "15                                                       -0.122003   \n",
       "16                                                       -0.023294   \n",
       "17                                                        0.004617   \n",
       "18                                                       -0.000337   \n",
       "19                                                       -0.000709   \n",
       "20                                                       -0.022814   \n",
       "21                                                       -0.003235   \n",
       "22                                                       -0.010857   \n",
       "23                                                        0.005895   \n",
       "24                                                       -0.013492   \n",
       "\n",
       "                            away_team_at_away_mean_goal_difference  \\\n",
       "principle_component_number                                           \n",
       "0                                                        -0.008737   \n",
       "1                                                        -0.015483   \n",
       "2                                                        -0.005040   \n",
       "3                                                         0.162730   \n",
       "4                                                         0.437228   \n",
       "5                                                         0.071929   \n",
       "6                                                        -0.407687   \n",
       "7                                                        -0.016546   \n",
       "8                                                         0.207967   \n",
       "9                                                        -0.017506   \n",
       "10                                                        0.090993   \n",
       "11                                                        0.609694   \n",
       "12                                                        0.291565   \n",
       "13                                                       -0.097071   \n",
       "14                                                       -0.294043   \n",
       "15                                                        0.067957   \n",
       "16                                                        0.015888   \n",
       "17                                                       -0.002116   \n",
       "18                                                        0.013693   \n",
       "19                                                        0.003652   \n",
       "20                                                       -0.014252   \n",
       "21                                                        0.003210   \n",
       "22                                                       -0.003635   \n",
       "23                                                        0.003667   \n",
       "24                                                        0.000598   \n",
       "\n",
       "                            away_team_overall_mean_goal_difference  \\\n",
       "principle_component_number                                           \n",
       "0                                                        -0.020654   \n",
       "1                                                        -0.010714   \n",
       "2                                                        -0.006613   \n",
       "3                                                         0.147332   \n",
       "4                                                         0.264195   \n",
       "5                                                         0.066960   \n",
       "6                                                        -0.606364   \n",
       "7                                                        -0.121426   \n",
       "8                                                        -0.491725   \n",
       "9                                                         0.188874   \n",
       "10                                                       -0.246258   \n",
       "11                                                       -0.376999   \n",
       "12                                                       -0.177232   \n",
       "13                                                       -0.007509   \n",
       "14                                                       -0.035747   \n",
       "15                                                        0.063091   \n",
       "16                                                        0.038038   \n",
       "17                                                        0.000827   \n",
       "18                                                        0.001958   \n",
       "19                                                        0.000803   \n",
       "20                                                        0.019562   \n",
       "21                                                        0.001399   \n",
       "22                                                        0.014521   \n",
       "23                                                       -0.003742   \n",
       "24                                                        0.016317   \n",
       "\n",
       "                            head_to_head_goal_difference  \n",
       "principle_component_number                                \n",
       "0                                               0.010048  \n",
       "1                                               0.007697  \n",
       "2                                              -0.009494  \n",
       "3                                              -0.237649  \n",
       "4                                              -0.510897  \n",
       "5                                              -0.037169  \n",
       "6                                              -0.019497  \n",
       "7                                              -0.083916  \n",
       "8                                              -0.213783  \n",
       "9                                               0.116769  \n",
       "10                                             -0.173898  \n",
       "11                                              0.142304  \n",
       "12                                              0.008622  \n",
       "13                                             -0.341852  \n",
       "14                                             -0.643028  \n",
       "15                                              0.052716  \n",
       "16                                              0.131247  \n",
       "17                                              0.005778  \n",
       "18                                              0.069707  \n",
       "19                                             -0.052653  \n",
       "20                                              0.015451  \n",
       "21                                              0.014477  \n",
       "22                                              0.027704  \n",
       "23                                             -0.021700  \n",
       "24                                              0.048045  \n",
       "\n",
       "[25 rows x 75 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pca.components_, columns=stats_columns)\n",
    "df.index.name = \"principle_component_number\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = len(X_train[0])\n",
    "OUTPUT_SIZE = len(output_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "\ttf.keras.layers.Dense(INPUT_SIZE, activation='relu'),\n",
    "\ttf.keras.layers.Dense(12, activation='relu'),\n",
    "\ttf.keras.layers.Dense(OUTPUT_SIZE, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 544us/step - loss: 25.4400 - accuracy: 0.3274\n",
      "Epoch 2/500\n",
      "68/68 [==============================] - 0s 403us/step - loss: 11.8835 - accuracy: 0.4876\n",
      "Epoch 3/500\n",
      "68/68 [==============================] - 0s 409us/step - loss: 10.6317 - accuracy: 0.5260\n",
      "Epoch 4/500\n",
      "68/68 [==============================] - 0s 367us/step - loss: 10.0395 - accuracy: 0.5426\n",
      "Epoch 5/500\n",
      "68/68 [==============================] - 0s 337us/step - loss: 9.9219 - accuracy: 0.5496\n",
      "Epoch 6/500\n",
      "68/68 [==============================] - 0s 311us/step - loss: 9.4839 - accuracy: 0.5567\n",
      "Epoch 7/500\n",
      "68/68 [==============================] - 0s 333us/step - loss: 9.3479 - accuracy: 0.5579\n",
      "Epoch 8/500\n",
      "68/68 [==============================] - 0s 340us/step - loss: 9.2564 - accuracy: 0.5532\n",
      "Epoch 9/500\n",
      "68/68 [==============================] - 0s 326us/step - loss: 9.1377 - accuracy: 0.5508\n",
      "Epoch 10/500\n",
      "68/68 [==============================] - 0s 396us/step - loss: 7.6420 - accuracy: 0.5520\n",
      "Epoch 11/500\n",
      "68/68 [==============================] - 0s 395us/step - loss: 7.5918 - accuracy: 0.5621\n",
      "Epoch 12/500\n",
      "68/68 [==============================] - 0s 573us/step - loss: 7.5414 - accuracy: 0.5556\n",
      "Epoch 13/500\n",
      "68/68 [==============================] - 0s 655us/step - loss: 7.6077 - accuracy: 0.5585\n",
      "Epoch 14/500\n",
      "68/68 [==============================] - 0s 408us/step - loss: 7.3730 - accuracy: 0.5573\n",
      "Epoch 15/500\n",
      "68/68 [==============================] - 0s 362us/step - loss: 7.3638 - accuracy: 0.5579\n",
      "Epoch 16/500\n",
      "68/68 [==============================] - 0s 384us/step - loss: 7.2964 - accuracy: 0.5544\n",
      "Epoch 17/500\n",
      "68/68 [==============================] - 0s 361us/step - loss: 7.3474 - accuracy: 0.5638\n",
      "Epoch 18/500\n",
      "68/68 [==============================] - 0s 344us/step - loss: 7.2868 - accuracy: 0.5556\n",
      "Epoch 19/500\n",
      "68/68 [==============================] - 0s 362us/step - loss: 7.3076 - accuracy: 0.5615\n",
      "Epoch 20/500\n",
      "68/68 [==============================] - 0s 360us/step - loss: 7.2271 - accuracy: 0.5674\n",
      "Epoch 21/500\n",
      "68/68 [==============================] - 0s 488us/step - loss: 7.2541 - accuracy: 0.5597\n",
      "Epoch 22/500\n",
      "68/68 [==============================] - 0s 408us/step - loss: 7.1848 - accuracy: 0.5597\n",
      "Epoch 23/500\n",
      "68/68 [==============================] - 0s 365us/step - loss: 7.1680 - accuracy: 0.5632\n",
      "Epoch 24/500\n",
      "68/68 [==============================] - 0s 366us/step - loss: 7.1943 - accuracy: 0.5662\n",
      "Epoch 25/500\n",
      "68/68 [==============================] - 0s 366us/step - loss: 7.1688 - accuracy: 0.5603\n",
      "Epoch 26/500\n",
      "68/68 [==============================] - 0s 352us/step - loss: 7.1046 - accuracy: 0.5644\n",
      "Epoch 27/500\n",
      "68/68 [==============================] - 0s 354us/step - loss: 7.1470 - accuracy: 0.5644\n",
      "Epoch 28/500\n",
      "68/68 [==============================] - 0s 367us/step - loss: 7.0630 - accuracy: 0.5626\n",
      "Epoch 29/500\n",
      "68/68 [==============================] - 0s 358us/step - loss: 7.0969 - accuracy: 0.5644\n",
      "Epoch 30/500\n",
      "68/68 [==============================] - 0s 353us/step - loss: 7.0206 - accuracy: 0.5644\n",
      "Epoch 31/500\n",
      "68/68 [==============================] - 0s 382us/step - loss: 7.0511 - accuracy: 0.5650\n",
      "Epoch 32/500\n",
      "68/68 [==============================] - 0s 373us/step - loss: 7.0168 - accuracy: 0.5727\n",
      "Epoch 33/500\n",
      "68/68 [==============================] - 0s 430us/step - loss: 7.0279 - accuracy: 0.5715\n",
      "Epoch 34/500\n",
      "68/68 [==============================] - 0s 536us/step - loss: 6.9724 - accuracy: 0.5686\n",
      "Epoch 35/500\n",
      "68/68 [==============================] - 0s 426us/step - loss: 6.9898 - accuracy: 0.5757\n",
      "Epoch 36/500\n",
      "68/68 [==============================] - 0s 455us/step - loss: 6.9726 - accuracy: 0.5656\n",
      "Epoch 37/500\n",
      "68/68 [==============================] - 0s 401us/step - loss: 6.9499 - accuracy: 0.5745\n",
      "Epoch 38/500\n",
      "68/68 [==============================] - 0s 378us/step - loss: 6.9717 - accuracy: 0.5603\n",
      "Epoch 39/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 6.9001 - accuracy: 0.5703\n",
      "Epoch 40/500\n",
      "68/68 [==============================] - 0s 354us/step - loss: 6.9185 - accuracy: 0.5662\n",
      "Epoch 41/500\n",
      "68/68 [==============================] - 0s 350us/step - loss: 6.9173 - accuracy: 0.5733\n",
      "Epoch 42/500\n",
      "68/68 [==============================] - 0s 368us/step - loss: 6.8892 - accuracy: 0.5662\n",
      "Epoch 43/500\n",
      "68/68 [==============================] - 0s 357us/step - loss: 6.8815 - accuracy: 0.5810\n",
      "Epoch 44/500\n",
      "68/68 [==============================] - 0s 399us/step - loss: 6.8622 - accuracy: 0.5686\n",
      "Epoch 45/500\n",
      "68/68 [==============================] - 0s 407us/step - loss: 6.9196 - accuracy: 0.5715\n",
      "Epoch 46/500\n",
      "68/68 [==============================] - 0s 433us/step - loss: 6.8448 - accuracy: 0.5816\n",
      "Epoch 47/500\n",
      "68/68 [==============================] - 0s 410us/step - loss: 6.8188 - accuracy: 0.5822\n",
      "Epoch 48/500\n",
      "68/68 [==============================] - 0s 408us/step - loss: 6.7725 - accuracy: 0.5786\n",
      "Epoch 49/500\n",
      "68/68 [==============================] - 0s 370us/step - loss: 6.8048 - accuracy: 0.5733\n",
      "Epoch 50/500\n",
      "68/68 [==============================] - 0s 384us/step - loss: 6.7795 - accuracy: 0.5774\n",
      "Epoch 51/500\n",
      "68/68 [==============================] - 0s 359us/step - loss: 6.7852 - accuracy: 0.5774\n",
      "Epoch 52/500\n",
      "68/68 [==============================] - 0s 374us/step - loss: 6.7491 - accuracy: 0.5798\n",
      "Epoch 53/500\n",
      "68/68 [==============================] - 0s 362us/step - loss: 6.7480 - accuracy: 0.5786\n",
      "Epoch 54/500\n",
      "68/68 [==============================] - 0s 388us/step - loss: 6.7440 - accuracy: 0.5798\n",
      "Epoch 55/500\n",
      "68/68 [==============================] - 0s 371us/step - loss: 6.7341 - accuracy: 0.5816\n",
      "Epoch 56/500\n",
      "68/68 [==============================] - 0s 383us/step - loss: 6.7780 - accuracy: 0.5810\n",
      "Epoch 57/500\n",
      "68/68 [==============================] - 0s 367us/step - loss: 6.6853 - accuracy: 0.5839\n",
      "Epoch 58/500\n",
      "68/68 [==============================] - 0s 750us/step - loss: 6.7099 - accuracy: 0.5810\n",
      "Epoch 59/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 6.6663 - accuracy: 0.5845\n",
      "Epoch 60/500\n",
      "68/68 [==============================] - 0s 690us/step - loss: 6.6409 - accuracy: 0.5762\n",
      "Epoch 61/500\n",
      "68/68 [==============================] - 0s 575us/step - loss: 6.6447 - accuracy: 0.5798\n",
      "Epoch 62/500\n",
      "68/68 [==============================] - 0s 544us/step - loss: 6.6249 - accuracy: 0.5881\n",
      "Epoch 63/500\n",
      "68/68 [==============================] - 0s 485us/step - loss: 6.6134 - accuracy: 0.5780\n",
      "Epoch 64/500\n",
      "68/68 [==============================] - 0s 470us/step - loss: 6.6150 - accuracy: 0.5792\n",
      "Epoch 65/500\n",
      "68/68 [==============================] - 0s 482us/step - loss: 6.6532 - accuracy: 0.5839\n",
      "Epoch 66/500\n",
      "68/68 [==============================] - 0s 466us/step - loss: 6.6606 - accuracy: 0.5892\n",
      "Epoch 67/500\n",
      "68/68 [==============================] - 0s 437us/step - loss: 6.5786 - accuracy: 0.5822\n",
      "Epoch 68/500\n",
      "68/68 [==============================] - 0s 378us/step - loss: 6.6375 - accuracy: 0.5822\n",
      "Epoch 69/500\n",
      "68/68 [==============================] - 0s 380us/step - loss: 6.5628 - accuracy: 0.5810\n",
      "Epoch 70/500\n",
      "68/68 [==============================] - 0s 356us/step - loss: 6.5572 - accuracy: 0.5863\n",
      "Epoch 71/500\n",
      "68/68 [==============================] - 0s 362us/step - loss: 6.5416 - accuracy: 0.5975\n",
      "Epoch 72/500\n",
      "68/68 [==============================] - 0s 348us/step - loss: 6.5453 - accuracy: 0.5922\n",
      "Epoch 73/500\n",
      "68/68 [==============================] - 0s 367us/step - loss: 6.4921 - accuracy: 0.5863\n",
      "Epoch 74/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 6.5384 - accuracy: 0.5910\n",
      "Epoch 75/500\n",
      "68/68 [==============================] - 0s 367us/step - loss: 6.4636 - accuracy: 0.5922\n",
      "Epoch 76/500\n",
      "68/68 [==============================] - 0s 379us/step - loss: 6.4848 - accuracy: 0.5869\n",
      "Epoch 77/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 6.4910 - accuracy: 0.5869\n",
      "Epoch 78/500\n",
      "68/68 [==============================] - 0s 546us/step - loss: 6.6070 - accuracy: 0.5928\n",
      "Epoch 79/500\n",
      "68/68 [==============================] - 0s 558us/step - loss: 6.5130 - accuracy: 0.5792\n",
      "Epoch 80/500\n",
      "68/68 [==============================] - 0s 376us/step - loss: 6.3818 - accuracy: 0.5904\n",
      "Epoch 81/500\n",
      "68/68 [==============================] - 0s 379us/step - loss: 6.5101 - accuracy: 0.5892\n",
      "Epoch 82/500\n",
      "68/68 [==============================] - 0s 356us/step - loss: 6.4322 - accuracy: 0.5904\n",
      "Epoch 83/500\n",
      "68/68 [==============================] - 0s 383us/step - loss: 6.4762 - accuracy: 0.5928\n",
      "Epoch 84/500\n",
      "68/68 [==============================] - 0s 373us/step - loss: 6.5197 - accuracy: 0.5904\n",
      "Epoch 85/500\n",
      "68/68 [==============================] - 0s 401us/step - loss: 6.3982 - accuracy: 0.5881\n",
      "Epoch 86/500\n",
      "68/68 [==============================] - 0s 393us/step - loss: 6.4419 - accuracy: 0.5839\n",
      "Epoch 87/500\n",
      "68/68 [==============================] - 0s 392us/step - loss: 6.3917 - accuracy: 0.5922\n",
      "Epoch 88/500\n",
      "68/68 [==============================] - 0s 390us/step - loss: 6.3470 - accuracy: 0.5981\n",
      "Epoch 89/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 6.4249 - accuracy: 0.5940\n",
      "Epoch 90/500\n",
      "68/68 [==============================] - 0s 411us/step - loss: 6.3057 - accuracy: 0.5910\n",
      "Epoch 91/500\n",
      "68/68 [==============================] - 0s 383us/step - loss: 6.3413 - accuracy: 0.5910\n",
      "Epoch 92/500\n",
      "68/68 [==============================] - 0s 373us/step - loss: 6.4164 - accuracy: 0.5904\n",
      "Epoch 93/500\n",
      "68/68 [==============================] - 0s 421us/step - loss: 6.2775 - accuracy: 0.5981\n",
      "Epoch 94/500\n",
      "68/68 [==============================] - 0s 357us/step - loss: 6.3471 - accuracy: 0.5833\n",
      "Epoch 95/500\n",
      "68/68 [==============================] - 0s 424us/step - loss: 6.3071 - accuracy: 0.5916\n",
      "Epoch 96/500\n",
      "68/68 [==============================] - 0s 413us/step - loss: 6.3294 - accuracy: 0.5969\n",
      "Epoch 97/500\n",
      "68/68 [==============================] - 0s 404us/step - loss: 6.4210 - accuracy: 0.5975\n",
      "Epoch 98/500\n",
      "68/68 [==============================] - 0s 416us/step - loss: 6.2762 - accuracy: 0.5922\n",
      "Epoch 99/500\n",
      "68/68 [==============================] - 0s 386us/step - loss: 6.2875 - accuracy: 0.5904\n",
      "Epoch 100/500\n",
      "68/68 [==============================] - 0s 377us/step - loss: 6.2388 - accuracy: 0.6093\n",
      "Epoch 101/500\n",
      "68/68 [==============================] - 0s 381us/step - loss: 6.2428 - accuracy: 0.5975\n",
      "Epoch 102/500\n",
      "68/68 [==============================] - 0s 361us/step - loss: 6.2594 - accuracy: 0.5969\n",
      "Epoch 103/500\n",
      "68/68 [==============================] - 0s 391us/step - loss: 6.2711 - accuracy: 0.6017\n",
      "Epoch 104/500\n",
      "68/68 [==============================] - 0s 481us/step - loss: 6.2728 - accuracy: 0.6076\n",
      "Epoch 105/500\n",
      "68/68 [==============================] - 0s 470us/step - loss: 6.1856 - accuracy: 0.6017\n",
      "Epoch 106/500\n",
      "68/68 [==============================] - 0s 403us/step - loss: 6.1557 - accuracy: 0.6058\n",
      "Epoch 107/500\n",
      "68/68 [==============================] - 0s 394us/step - loss: 6.2089 - accuracy: 0.6082\n",
      "Epoch 108/500\n",
      "68/68 [==============================] - 0s 409us/step - loss: 6.1580 - accuracy: 0.6017\n",
      "Epoch 109/500\n",
      "68/68 [==============================] - 0s 391us/step - loss: 6.2014 - accuracy: 0.5957\n",
      "Epoch 110/500\n",
      "68/68 [==============================] - 0s 407us/step - loss: 6.1702 - accuracy: 0.5975\n",
      "Epoch 111/500\n",
      "68/68 [==============================] - 0s 440us/step - loss: 6.1236 - accuracy: 0.5957\n",
      "Epoch 112/500\n",
      "68/68 [==============================] - 0s 441us/step - loss: 6.1294 - accuracy: 0.6017\n",
      "Epoch 113/500\n",
      "68/68 [==============================] - 0s 441us/step - loss: 6.0899 - accuracy: 0.6046\n",
      "Epoch 114/500\n",
      "68/68 [==============================] - 0s 401us/step - loss: 6.0498 - accuracy: 0.6076\n",
      "Epoch 115/500\n",
      "68/68 [==============================] - 0s 402us/step - loss: 6.0917 - accuracy: 0.6087\n",
      "Epoch 116/500\n",
      "68/68 [==============================] - 0s 372us/step - loss: 6.0487 - accuracy: 0.6034\n",
      "Epoch 117/500\n",
      "68/68 [==============================] - 0s 370us/step - loss: 6.0216 - accuracy: 0.6158\n",
      "Epoch 118/500\n",
      "68/68 [==============================] - 0s 383us/step - loss: 6.1040 - accuracy: 0.5975\n",
      "Epoch 119/500\n",
      "68/68 [==============================] - 0s 367us/step - loss: 6.0986 - accuracy: 0.6076\n",
      "Epoch 120/500\n",
      "68/68 [==============================] - 0s 373us/step - loss: 6.0584 - accuracy: 0.6093\n",
      "Epoch 121/500\n",
      "68/68 [==============================] - 0s 363us/step - loss: 6.0389 - accuracy: 0.6141\n",
      "Epoch 122/500\n",
      "68/68 [==============================] - 0s 366us/step - loss: 5.9871 - accuracy: 0.6158\n",
      "Epoch 123/500\n",
      "68/68 [==============================] - 0s 374us/step - loss: 5.9820 - accuracy: 0.6052\n",
      "Epoch 124/500\n",
      "68/68 [==============================] - 0s 357us/step - loss: 6.0425 - accuracy: 0.6117\n",
      "Epoch 125/500\n",
      "68/68 [==============================] - 0s 366us/step - loss: 5.8927 - accuracy: 0.6147\n",
      "Epoch 126/500\n",
      "68/68 [==============================] - 0s 361us/step - loss: 5.9439 - accuracy: 0.6070\n",
      "Epoch 127/500\n",
      "68/68 [==============================] - 0s 358us/step - loss: 5.9131 - accuracy: 0.6129\n",
      "Epoch 128/500\n",
      "68/68 [==============================] - 0s 368us/step - loss: 5.9360 - accuracy: 0.6141\n",
      "Epoch 129/500\n",
      "68/68 [==============================] - 0s 397us/step - loss: 5.9121 - accuracy: 0.6158\n",
      "Epoch 130/500\n",
      "68/68 [==============================] - 0s 413us/step - loss: 5.9284 - accuracy: 0.6223\n",
      "Epoch 131/500\n",
      "68/68 [==============================] - 0s 377us/step - loss: 6.0169 - accuracy: 0.6194\n",
      "Epoch 132/500\n",
      "68/68 [==============================] - 0s 375us/step - loss: 5.8936 - accuracy: 0.6182\n",
      "Epoch 133/500\n",
      "68/68 [==============================] - 0s 364us/step - loss: 5.8859 - accuracy: 0.6170\n",
      "Epoch 134/500\n",
      "68/68 [==============================] - 0s 358us/step - loss: 5.8072 - accuracy: 0.6176\n",
      "Epoch 135/500\n",
      "68/68 [==============================] - 0s 406us/step - loss: 5.9239 - accuracy: 0.6283\n",
      "Epoch 136/500\n",
      "68/68 [==============================] - 0s 411us/step - loss: 5.7828 - accuracy: 0.6176\n",
      "Epoch 137/500\n",
      "68/68 [==============================] - 0s 411us/step - loss: 5.7797 - accuracy: 0.6206\n",
      "Epoch 138/500\n",
      "68/68 [==============================] - 0s 386us/step - loss: 5.8578 - accuracy: 0.6123\n",
      "Epoch 139/500\n",
      "68/68 [==============================] - 0s 404us/step - loss: 5.8706 - accuracy: 0.6046\n",
      "Epoch 140/500\n",
      "68/68 [==============================] - 0s 391us/step - loss: 5.7670 - accuracy: 0.6093\n",
      "Epoch 141/500\n",
      "68/68 [==============================] - 0s 393us/step - loss: 5.8394 - accuracy: 0.6235\n",
      "Epoch 142/500\n",
      "68/68 [==============================] - 0s 756us/step - loss: 5.7780 - accuracy: 0.6200\n",
      "Epoch 143/500\n",
      "68/68 [==============================] - 0s 445us/step - loss: 5.7134 - accuracy: 0.6306\n",
      "Epoch 144/500\n",
      "68/68 [==============================] - 0s 418us/step - loss: 5.8034 - accuracy: 0.6253\n",
      "Epoch 145/500\n",
      "68/68 [==============================] - 0s 431us/step - loss: 5.7696 - accuracy: 0.6206\n",
      "Epoch 146/500\n",
      "68/68 [==============================] - 0s 360us/step - loss: 5.6672 - accuracy: 0.6283\n",
      "Epoch 147/500\n",
      "68/68 [==============================] - 0s 407us/step - loss: 5.8132 - accuracy: 0.6176\n",
      "Epoch 148/500\n",
      "68/68 [==============================] - 0s 375us/step - loss: 5.6744 - accuracy: 0.6188\n",
      "Epoch 149/500\n",
      "68/68 [==============================] - 0s 605us/step - loss: 5.6568 - accuracy: 0.6336\n",
      "Epoch 150/500\n",
      "68/68 [==============================] - 0s 467us/step - loss: 5.6760 - accuracy: 0.6200\n",
      "Epoch 151/500\n",
      "68/68 [==============================] - 0s 406us/step - loss: 5.7321 - accuracy: 0.6371\n",
      "Epoch 152/500\n",
      "68/68 [==============================] - 0s 502us/step - loss: 5.6735 - accuracy: 0.6241\n",
      "Epoch 153/500\n",
      "68/68 [==============================] - 0s 412us/step - loss: 5.6713 - accuracy: 0.6283\n",
      "Epoch 154/500\n",
      "68/68 [==============================] - 0s 413us/step - loss: 5.7085 - accuracy: 0.6259\n",
      "Epoch 155/500\n",
      "68/68 [==============================] - 0s 396us/step - loss: 5.5959 - accuracy: 0.6324\n",
      "Epoch 156/500\n",
      "68/68 [==============================] - 0s 404us/step - loss: 5.5402 - accuracy: 0.6330\n",
      "Epoch 157/500\n",
      "68/68 [==============================] - 0s 402us/step - loss: 5.7062 - accuracy: 0.6283\n",
      "Epoch 158/500\n",
      "68/68 [==============================] - 0s 386us/step - loss: 5.6567 - accuracy: 0.6259\n",
      "Epoch 159/500\n",
      "68/68 [==============================] - 0s 454us/step - loss: 5.6657 - accuracy: 0.6401\n",
      "Epoch 160/500\n",
      "68/68 [==============================] - 0s 396us/step - loss: 5.6186 - accuracy: 0.6223\n",
      "Epoch 161/500\n",
      "68/68 [==============================] - 0s 432us/step - loss: 5.5189 - accuracy: 0.6336\n",
      "Epoch 162/500\n",
      "68/68 [==============================] - 0s 421us/step - loss: 5.6972 - accuracy: 0.6247\n",
      "Epoch 163/500\n",
      "68/68 [==============================] - 0s 363us/step - loss: 5.5899 - accuracy: 0.6424\n",
      "Epoch 164/500\n",
      "68/68 [==============================] - 0s 371us/step - loss: 5.6389 - accuracy: 0.6330\n",
      "Epoch 165/500\n",
      "68/68 [==============================] - 0s 380us/step - loss: 5.5054 - accuracy: 0.6336\n",
      "Epoch 166/500\n",
      "68/68 [==============================] - 0s 359us/step - loss: 5.4022 - accuracy: 0.6277\n",
      "Epoch 167/500\n",
      "68/68 [==============================] - 0s 427us/step - loss: 5.4871 - accuracy: 0.6383\n",
      "Epoch 168/500\n",
      "68/68 [==============================] - 0s 405us/step - loss: 5.4405 - accuracy: 0.6353\n",
      "Epoch 169/500\n",
      "68/68 [==============================] - 0s 405us/step - loss: 5.3208 - accuracy: 0.6401\n",
      "Epoch 170/500\n",
      "68/68 [==============================] - 0s 394us/step - loss: 5.3608 - accuracy: 0.6359\n",
      "Epoch 171/500\n",
      "68/68 [==============================] - 0s 404us/step - loss: 5.3525 - accuracy: 0.6330\n",
      "Epoch 172/500\n",
      "68/68 [==============================] - 0s 405us/step - loss: 5.2769 - accuracy: 0.6418\n",
      "Epoch 173/500\n",
      "68/68 [==============================] - 0s 380us/step - loss: 5.3813 - accuracy: 0.6395\n",
      "Epoch 174/500\n",
      "68/68 [==============================] - 0s 397us/step - loss: 5.3305 - accuracy: 0.6353\n",
      "Epoch 175/500\n",
      "68/68 [==============================] - 0s 409us/step - loss: 5.3337 - accuracy: 0.6442\n",
      "Epoch 176/500\n",
      "68/68 [==============================] - 0s 410us/step - loss: 5.4022 - accuracy: 0.6306\n",
      "Epoch 177/500\n",
      "68/68 [==============================] - 0s 390us/step - loss: 5.2883 - accuracy: 0.6424\n",
      "Epoch 178/500\n",
      "68/68 [==============================] - 0s 396us/step - loss: 5.2965 - accuracy: 0.6330\n",
      "Epoch 179/500\n",
      "68/68 [==============================] - 0s 420us/step - loss: 5.3575 - accuracy: 0.6359\n",
      "Epoch 180/500\n",
      "68/68 [==============================] - 0s 481us/step - loss: 5.2200 - accuracy: 0.6454\n",
      "Epoch 181/500\n",
      "68/68 [==============================] - 0s 430us/step - loss: 5.3129 - accuracy: 0.6454\n",
      "Epoch 182/500\n",
      "68/68 [==============================] - 0s 443us/step - loss: 5.2780 - accuracy: 0.6531\n",
      "Epoch 183/500\n",
      "68/68 [==============================] - 0s 434us/step - loss: 5.2231 - accuracy: 0.6348\n",
      "Epoch 184/500\n",
      "68/68 [==============================] - 0s 358us/step - loss: 5.2056 - accuracy: 0.6454\n",
      "Epoch 185/500\n",
      "68/68 [==============================] - 0s 371us/step - loss: 5.2552 - accuracy: 0.6513\n",
      "Epoch 186/500\n",
      "68/68 [==============================] - 0s 374us/step - loss: 5.2509 - accuracy: 0.6466\n",
      "Epoch 187/500\n",
      "68/68 [==============================] - 0s 368us/step - loss: 5.2136 - accuracy: 0.6359\n",
      "Epoch 188/500\n",
      "68/68 [==============================] - 0s 429us/step - loss: 5.1489 - accuracy: 0.6442\n",
      "Epoch 189/500\n",
      "68/68 [==============================] - 0s 436us/step - loss: 5.2348 - accuracy: 0.6454\n",
      "Epoch 190/500\n",
      "68/68 [==============================] - 0s 474us/step - loss: 5.2131 - accuracy: 0.6418\n",
      "Epoch 191/500\n",
      "68/68 [==============================] - 0s 407us/step - loss: 5.1328 - accuracy: 0.6483\n",
      "Epoch 192/500\n",
      "68/68 [==============================] - 0s 367us/step - loss: 5.1752 - accuracy: 0.6430\n",
      "Epoch 193/500\n",
      "68/68 [==============================] - 0s 373us/step - loss: 5.2212 - accuracy: 0.6418\n",
      "Epoch 194/500\n",
      "68/68 [==============================] - 0s 359us/step - loss: 5.0938 - accuracy: 0.6537\n",
      "Epoch 195/500\n",
      "68/68 [==============================] - 0s 395us/step - loss: 5.1310 - accuracy: 0.6448\n",
      "Epoch 196/500\n",
      "68/68 [==============================] - 0s 384us/step - loss: 4.9892 - accuracy: 0.6637\n",
      "Epoch 197/500\n",
      "68/68 [==============================] - 0s 403us/step - loss: 5.1490 - accuracy: 0.6413\n",
      "Epoch 198/500\n",
      "68/68 [==============================] - 0s 416us/step - loss: 5.0451 - accuracy: 0.6537\n",
      "Epoch 199/500\n",
      "68/68 [==============================] - 0s 393us/step - loss: 5.1953 - accuracy: 0.6519\n",
      "Epoch 200/500\n",
      "68/68 [==============================] - 0s 391us/step - loss: 5.0739 - accuracy: 0.6554\n",
      "Epoch 201/500\n",
      "68/68 [==============================] - 0s 378us/step - loss: 5.2589 - accuracy: 0.6424\n",
      "Epoch 202/500\n",
      "68/68 [==============================] - 0s 402us/step - loss: 5.0757 - accuracy: 0.6525\n",
      "Epoch 203/500\n",
      "68/68 [==============================] - 0s 390us/step - loss: 5.0033 - accuracy: 0.6596\n",
      "Epoch 204/500\n",
      "68/68 [==============================] - 0s 400us/step - loss: 5.0860 - accuracy: 0.6560\n",
      "Epoch 205/500\n",
      "68/68 [==============================] - 0s 654us/step - loss: 5.0075 - accuracy: 0.6684\n",
      "Epoch 206/500\n",
      "68/68 [==============================] - 0s 473us/step - loss: 5.0724 - accuracy: 0.6631\n",
      "Epoch 207/500\n",
      "68/68 [==============================] - 0s 439us/step - loss: 5.1009 - accuracy: 0.6489\n",
      "Epoch 208/500\n",
      "68/68 [==============================] - 0s 484us/step - loss: 4.9764 - accuracy: 0.6554\n",
      "Epoch 209/500\n",
      "68/68 [==============================] - 0s 382us/step - loss: 5.1001 - accuracy: 0.6537\n",
      "Epoch 210/500\n",
      "68/68 [==============================] - 0s 406us/step - loss: 5.0181 - accuracy: 0.6619\n",
      "Epoch 211/500\n",
      "68/68 [==============================] - 0s 383us/step - loss: 4.9758 - accuracy: 0.6531\n",
      "Epoch 212/500\n",
      "68/68 [==============================] - 0s 396us/step - loss: 4.8874 - accuracy: 0.6625\n",
      "Epoch 213/500\n",
      "68/68 [==============================] - 0s 410us/step - loss: 4.9289 - accuracy: 0.6566\n",
      "Epoch 214/500\n",
      "68/68 [==============================] - 0s 400us/step - loss: 5.0500 - accuracy: 0.6495\n",
      "Epoch 215/500\n",
      "68/68 [==============================] - 0s 399us/step - loss: 4.8923 - accuracy: 0.6684\n",
      "Epoch 216/500\n",
      "68/68 [==============================] - 0s 405us/step - loss: 4.9793 - accuracy: 0.6643\n",
      "Epoch 217/500\n",
      "68/68 [==============================] - 0s 419us/step - loss: 4.9869 - accuracy: 0.6619\n",
      "Epoch 218/500\n",
      "68/68 [==============================] - 0s 577us/step - loss: 4.9977 - accuracy: 0.6619\n",
      "Epoch 219/500\n",
      "68/68 [==============================] - 0s 473us/step - loss: 4.9327 - accuracy: 0.6637\n",
      "Epoch 220/500\n",
      "68/68 [==============================] - 0s 490us/step - loss: 4.9076 - accuracy: 0.6608\n",
      "Epoch 221/500\n",
      "68/68 [==============================] - 0s 403us/step - loss: 4.8746 - accuracy: 0.6590\n",
      "Epoch 222/500\n",
      "68/68 [==============================] - 0s 427us/step - loss: 4.8783 - accuracy: 0.6661\n",
      "Epoch 223/500\n",
      "68/68 [==============================] - 0s 372us/step - loss: 4.9755 - accuracy: 0.6531\n",
      "Epoch 224/500\n",
      "68/68 [==============================] - 0s 359us/step - loss: 4.9107 - accuracy: 0.6602\n",
      "Epoch 225/500\n",
      "68/68 [==============================] - 0s 380us/step - loss: 4.8602 - accuracy: 0.6625\n",
      "Epoch 226/500\n",
      "68/68 [==============================] - 0s 367us/step - loss: 4.8217 - accuracy: 0.6773\n",
      "Epoch 227/500\n",
      "68/68 [==============================] - 0s 364us/step - loss: 4.8900 - accuracy: 0.6608\n",
      "Epoch 228/500\n",
      "68/68 [==============================] - 0s 372us/step - loss: 4.9844 - accuracy: 0.6590\n",
      "Epoch 229/500\n",
      "68/68 [==============================] - 0s 377us/step - loss: 4.7435 - accuracy: 0.6720\n",
      "Epoch 230/500\n",
      "68/68 [==============================] - 0s 374us/step - loss: 4.8869 - accuracy: 0.6596\n",
      "Epoch 231/500\n",
      "68/68 [==============================] - 0s 362us/step - loss: 4.7604 - accuracy: 0.6690\n",
      "Epoch 232/500\n",
      "68/68 [==============================] - 0s 369us/step - loss: 4.8387 - accuracy: 0.6661\n",
      "Epoch 233/500\n",
      "68/68 [==============================] - 0s 417us/step - loss: 4.8527 - accuracy: 0.6749\n",
      "Epoch 234/500\n",
      "68/68 [==============================] - 0s 416us/step - loss: 4.8146 - accuracy: 0.6684\n",
      "Epoch 235/500\n",
      "68/68 [==============================] - 0s 396us/step - loss: 4.7586 - accuracy: 0.6820\n",
      "Epoch 236/500\n",
      "68/68 [==============================] - 0s 413us/step - loss: 4.8339 - accuracy: 0.6743\n",
      "Epoch 237/500\n",
      "68/68 [==============================] - 0s 394us/step - loss: 4.8026 - accuracy: 0.6649\n",
      "Epoch 238/500\n",
      "68/68 [==============================] - 0s 407us/step - loss: 4.7756 - accuracy: 0.6779\n",
      "Epoch 239/500\n",
      "68/68 [==============================] - 0s 380us/step - loss: 4.8158 - accuracy: 0.6785\n",
      "Epoch 240/500\n",
      "68/68 [==============================] - 0s 415us/step - loss: 4.9371 - accuracy: 0.6631\n",
      "Epoch 241/500\n",
      "68/68 [==============================] - 0s 421us/step - loss: 4.7098 - accuracy: 0.6743\n",
      "Epoch 242/500\n",
      "68/68 [==============================] - 0s 419us/step - loss: 4.7592 - accuracy: 0.6743\n",
      "Epoch 243/500\n",
      "68/68 [==============================] - 0s 423us/step - loss: 4.8709 - accuracy: 0.6673\n",
      "Epoch 244/500\n",
      "68/68 [==============================] - 0s 384us/step - loss: 4.7445 - accuracy: 0.6673\n",
      "Epoch 245/500\n",
      "68/68 [==============================] - 0s 406us/step - loss: 4.6770 - accuracy: 0.6761\n",
      "Epoch 246/500\n",
      "68/68 [==============================] - 0s 475us/step - loss: 4.6811 - accuracy: 0.6743\n",
      "Epoch 247/500\n",
      "68/68 [==============================] - 0s 412us/step - loss: 4.8798 - accuracy: 0.6619\n",
      "Epoch 248/500\n",
      "68/68 [==============================] - 0s 388us/step - loss: 4.6553 - accuracy: 0.6661\n",
      "Epoch 249/500\n",
      "68/68 [==============================] - 0s 369us/step - loss: 4.9252 - accuracy: 0.6667\n",
      "Epoch 250/500\n",
      "68/68 [==============================] - 0s 391us/step - loss: 4.5989 - accuracy: 0.6678\n",
      "Epoch 251/500\n",
      "68/68 [==============================] - 0s 421us/step - loss: 4.6684 - accuracy: 0.6814\n",
      "Epoch 252/500\n",
      "68/68 [==============================] - 0s 450us/step - loss: 4.7172 - accuracy: 0.6755\n",
      "Epoch 253/500\n",
      "68/68 [==============================] - 0s 415us/step - loss: 4.6428 - accuracy: 0.6814\n",
      "Epoch 254/500\n",
      "68/68 [==============================] - 0s 408us/step - loss: 4.7947 - accuracy: 0.6767\n",
      "Epoch 255/500\n",
      "68/68 [==============================] - 0s 425us/step - loss: 4.6345 - accuracy: 0.6933\n",
      "Epoch 256/500\n",
      "68/68 [==============================] - 0s 517us/step - loss: 4.7276 - accuracy: 0.6738\n",
      "Epoch 257/500\n",
      "68/68 [==============================] - 0s 482us/step - loss: 4.6805 - accuracy: 0.6738\n",
      "Epoch 258/500\n",
      "68/68 [==============================] - 0s 464us/step - loss: 4.6334 - accuracy: 0.6814\n",
      "Epoch 259/500\n",
      "68/68 [==============================] - 0s 397us/step - loss: 4.7680 - accuracy: 0.6826\n",
      "Epoch 260/500\n",
      "68/68 [==============================] - 0s 395us/step - loss: 4.6048 - accuracy: 0.6879\n",
      "Epoch 261/500\n",
      "68/68 [==============================] - 0s 378us/step - loss: 4.7332 - accuracy: 0.6743\n",
      "Epoch 262/500\n",
      "68/68 [==============================] - 0s 358us/step - loss: 4.5741 - accuracy: 0.6832\n",
      "Epoch 263/500\n",
      "68/68 [==============================] - 0s 369us/step - loss: 4.6132 - accuracy: 0.6749\n",
      "Epoch 264/500\n",
      "68/68 [==============================] - 0s 425us/step - loss: 4.5608 - accuracy: 0.6862\n",
      "Epoch 265/500\n",
      "68/68 [==============================] - 0s 377us/step - loss: 4.6226 - accuracy: 0.6826\n",
      "Epoch 266/500\n",
      "68/68 [==============================] - 0s 380us/step - loss: 4.5358 - accuracy: 0.6868\n",
      "Epoch 267/500\n",
      "68/68 [==============================] - 0s 362us/step - loss: 4.6871 - accuracy: 0.6779\n",
      "Epoch 268/500\n",
      "68/68 [==============================] - 0s 357us/step - loss: 4.6754 - accuracy: 0.6779\n",
      "Epoch 269/500\n",
      "68/68 [==============================] - 0s 371us/step - loss: 4.6269 - accuracy: 0.6803\n",
      "Epoch 270/500\n",
      "68/68 [==============================] - 0s 379us/step - loss: 4.6478 - accuracy: 0.6838\n",
      "Epoch 271/500\n",
      "68/68 [==============================] - 0s 433us/step - loss: 4.5867 - accuracy: 0.6856\n",
      "Epoch 272/500\n",
      "68/68 [==============================] - 0s 393us/step - loss: 4.5333 - accuracy: 0.6844\n",
      "Epoch 273/500\n",
      "68/68 [==============================] - 0s 413us/step - loss: 4.5643 - accuracy: 0.6939\n",
      "Epoch 274/500\n",
      "68/68 [==============================] - 0s 384us/step - loss: 4.5083 - accuracy: 0.6921\n",
      "Epoch 275/500\n",
      "68/68 [==============================] - 0s 415us/step - loss: 4.5509 - accuracy: 0.6868\n",
      "Epoch 276/500\n",
      "68/68 [==============================] - 0s 402us/step - loss: 4.6049 - accuracy: 0.6909\n",
      "Epoch 277/500\n",
      "68/68 [==============================] - 0s 377us/step - loss: 4.5595 - accuracy: 0.6838\n",
      "Epoch 278/500\n",
      "68/68 [==============================] - 0s 359us/step - loss: 4.6273 - accuracy: 0.6939\n",
      "Epoch 279/500\n",
      "68/68 [==============================] - 0s 358us/step - loss: 4.4376 - accuracy: 0.6891\n",
      "Epoch 280/500\n",
      "68/68 [==============================] - 0s 371us/step - loss: 4.5531 - accuracy: 0.6826\n",
      "Epoch 281/500\n",
      "68/68 [==============================] - 0s 361us/step - loss: 4.5354 - accuracy: 0.6962\n",
      "Epoch 282/500\n",
      "68/68 [==============================] - 0s 413us/step - loss: 4.4929 - accuracy: 0.6856\n",
      "Epoch 283/500\n",
      "68/68 [==============================] - 0s 381us/step - loss: 4.5185 - accuracy: 0.6868\n",
      "Epoch 284/500\n",
      "68/68 [==============================] - 0s 408us/step - loss: 4.5832 - accuracy: 0.6879\n",
      "Epoch 285/500\n",
      "68/68 [==============================] - 0s 420us/step - loss: 4.5806 - accuracy: 0.6838\n",
      "Epoch 286/500\n",
      "68/68 [==============================] - 0s 419us/step - loss: 4.5844 - accuracy: 0.6690\n",
      "Epoch 287/500\n",
      "68/68 [==============================] - 0s 405us/step - loss: 4.4074 - accuracy: 0.6986\n",
      "Epoch 288/500\n",
      "68/68 [==============================] - 0s 466us/step - loss: 4.3812 - accuracy: 0.6974\n",
      "Epoch 289/500\n",
      "68/68 [==============================] - 0s 454us/step - loss: 4.4818 - accuracy: 0.6891\n",
      "Epoch 290/500\n",
      "68/68 [==============================] - 0s 482us/step - loss: 4.5535 - accuracy: 0.6921\n",
      "Epoch 291/500\n",
      "68/68 [==============================] - 0s 420us/step - loss: 4.4240 - accuracy: 0.6962\n",
      "Epoch 292/500\n",
      "68/68 [==============================] - 0s 385us/step - loss: 4.4320 - accuracy: 0.6909\n",
      "Epoch 293/500\n",
      "68/68 [==============================] - 0s 750us/step - loss: 4.4126 - accuracy: 0.6868\n",
      "Epoch 294/500\n",
      "68/68 [==============================] - 0s 400us/step - loss: 4.4267 - accuracy: 0.6939\n",
      "Epoch 295/500\n",
      "68/68 [==============================] - 0s 368us/step - loss: 4.4579 - accuracy: 0.6773\n",
      "Epoch 296/500\n",
      "68/68 [==============================] - 0s 361us/step - loss: 4.4205 - accuracy: 0.6915\n",
      "Epoch 297/500\n",
      "68/68 [==============================] - 0s 384us/step - loss: 4.4178 - accuracy: 0.6915\n",
      "Epoch 298/500\n",
      "68/68 [==============================] - 0s 374us/step - loss: 4.4504 - accuracy: 0.6956\n",
      "Epoch 299/500\n",
      "68/68 [==============================] - 0s 375us/step - loss: 4.4746 - accuracy: 0.6897\n",
      "Epoch 300/500\n",
      "68/68 [==============================] - 0s 387us/step - loss: 4.3210 - accuracy: 0.7057\n",
      "Epoch 301/500\n",
      "68/68 [==============================] - 0s 403us/step - loss: 4.5224 - accuracy: 0.6874\n",
      "Epoch 302/500\n",
      "68/68 [==============================] - 0s 518us/step - loss: 4.3503 - accuracy: 0.6939\n",
      "Epoch 303/500\n",
      "68/68 [==============================] - 0s 896us/step - loss: 4.3725 - accuracy: 0.7051\n",
      "Epoch 304/500\n",
      "68/68 [==============================] - 0s 510us/step - loss: 4.2710 - accuracy: 0.7051\n",
      "Epoch 305/500\n",
      "68/68 [==============================] - 0s 445us/step - loss: 4.3822 - accuracy: 0.6885\n",
      "Epoch 306/500\n",
      "68/68 [==============================] - 0s 630us/step - loss: 4.3484 - accuracy: 0.6915\n",
      "Epoch 307/500\n",
      "68/68 [==============================] - 0s 452us/step - loss: 4.3558 - accuracy: 0.6956\n",
      "Epoch 308/500\n",
      "68/68 [==============================] - 0s 403us/step - loss: 4.3218 - accuracy: 0.7039\n",
      "Epoch 309/500\n",
      "68/68 [==============================] - 0s 361us/step - loss: 4.3538 - accuracy: 0.6968\n",
      "Epoch 310/500\n",
      "68/68 [==============================] - 0s 365us/step - loss: 4.3887 - accuracy: 0.6933\n",
      "Epoch 311/500\n",
      "68/68 [==============================] - 0s 369us/step - loss: 4.3043 - accuracy: 0.6992\n",
      "Epoch 312/500\n",
      "68/68 [==============================] - 0s 355us/step - loss: 4.3278 - accuracy: 0.6962\n",
      "Epoch 313/500\n",
      "68/68 [==============================] - 0s 383us/step - loss: 4.6315 - accuracy: 0.6803\n",
      "Epoch 314/500\n",
      "68/68 [==============================] - 0s 401us/step - loss: 4.3270 - accuracy: 0.7027\n",
      "Epoch 315/500\n",
      "68/68 [==============================] - 0s 394us/step - loss: 4.2924 - accuracy: 0.6980\n",
      "Epoch 316/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 4.3126 - accuracy: 0.7057\n",
      "Epoch 317/500\n",
      "68/68 [==============================] - 0s 915us/step - loss: 4.3389 - accuracy: 0.7045\n",
      "Epoch 318/500\n",
      "68/68 [==============================] - 0s 467us/step - loss: 4.3263 - accuracy: 0.6879\n",
      "Epoch 319/500\n",
      "68/68 [==============================] - 0s 399us/step - loss: 4.3866 - accuracy: 0.6974\n",
      "Epoch 320/500\n",
      "68/68 [==============================] - 0s 360us/step - loss: 4.4235 - accuracy: 0.6909\n",
      "Epoch 321/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 4.3793 - accuracy: 0.7134\n",
      "Epoch 322/500\n",
      "68/68 [==============================] - 0s 354us/step - loss: 4.2989 - accuracy: 0.6874\n",
      "Epoch 323/500\n",
      "68/68 [==============================] - 0s 357us/step - loss: 4.3645 - accuracy: 0.6962\n",
      "Epoch 324/500\n",
      "68/68 [==============================] - 0s 386us/step - loss: 4.5007 - accuracy: 0.6915\n",
      "Epoch 325/500\n",
      "68/68 [==============================] - 0s 475us/step - loss: 4.3242 - accuracy: 0.7051\n",
      "Epoch 326/500\n",
      "68/68 [==============================] - 0s 418us/step - loss: 4.2564 - accuracy: 0.7098\n",
      "Epoch 327/500\n",
      "68/68 [==============================] - 0s 420us/step - loss: 4.2553 - accuracy: 0.7045\n",
      "Epoch 328/500\n",
      "68/68 [==============================] - 0s 356us/step - loss: 4.1798 - accuracy: 0.7021\n",
      "Epoch 329/500\n",
      "68/68 [==============================] - 0s 391us/step - loss: 4.2442 - accuracy: 0.7216\n",
      "Epoch 330/500\n",
      "68/68 [==============================] - 0s 411us/step - loss: 4.2521 - accuracy: 0.7163\n",
      "Epoch 331/500\n",
      "68/68 [==============================] - 0s 385us/step - loss: 4.2719 - accuracy: 0.7122\n",
      "Epoch 332/500\n",
      "68/68 [==============================] - 0s 399us/step - loss: 4.2548 - accuracy: 0.7122\n",
      "Epoch 333/500\n",
      "68/68 [==============================] - 0s 402us/step - loss: 4.1966 - accuracy: 0.7145\n",
      "Epoch 334/500\n",
      "68/68 [==============================] - 0s 398us/step - loss: 4.2966 - accuracy: 0.7039\n",
      "Epoch 335/500\n",
      "68/68 [==============================] - 0s 446us/step - loss: 4.2981 - accuracy: 0.7098\n",
      "Epoch 336/500\n",
      "68/68 [==============================] - 0s 430us/step - loss: 4.1690 - accuracy: 0.7104\n",
      "Epoch 337/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 4.2355 - accuracy: 0.7104\n",
      "Epoch 338/500\n",
      "68/68 [==============================] - 0s 441us/step - loss: 4.2236 - accuracy: 0.7074\n",
      "Epoch 339/500\n",
      "68/68 [==============================] - 0s 380us/step - loss: 4.3049 - accuracy: 0.7116\n",
      "Epoch 340/500\n",
      "68/68 [==============================] - 0s 366us/step - loss: 4.1811 - accuracy: 0.7116\n",
      "Epoch 341/500\n",
      "68/68 [==============================] - 0s 378us/step - loss: 4.2130 - accuracy: 0.6998\n",
      "Epoch 342/500\n",
      "68/68 [==============================] - 0s 366us/step - loss: 4.1897 - accuracy: 0.7063\n",
      "Epoch 343/500\n",
      "68/68 [==============================] - 0s 411us/step - loss: 4.1899 - accuracy: 0.7033\n",
      "Epoch 344/500\n",
      "68/68 [==============================] - 0s 743us/step - loss: 4.1147 - accuracy: 0.7086\n",
      "Epoch 345/500\n",
      "68/68 [==============================] - 0s 468us/step - loss: 4.2389 - accuracy: 0.7098\n",
      "Epoch 346/500\n",
      "68/68 [==============================] - 0s 528us/step - loss: 4.1732 - accuracy: 0.7216\n",
      "Epoch 347/500\n",
      "68/68 [==============================] - 0s 428us/step - loss: 4.2200 - accuracy: 0.7069\n",
      "Epoch 348/500\n",
      "68/68 [==============================] - 0s 584us/step - loss: 4.2009 - accuracy: 0.6998\n",
      "Epoch 349/500\n",
      "68/68 [==============================] - 0s 417us/step - loss: 4.1891 - accuracy: 0.6962\n",
      "Epoch 350/500\n",
      "68/68 [==============================] - 0s 465us/step - loss: 4.1821 - accuracy: 0.7086\n",
      "Epoch 351/500\n",
      "68/68 [==============================] - 0s 479us/step - loss: 4.1539 - accuracy: 0.7228\n",
      "Epoch 352/500\n",
      "68/68 [==============================] - 0s 635us/step - loss: 4.1123 - accuracy: 0.7181\n",
      "Epoch 353/500\n",
      "68/68 [==============================] - 0s 576us/step - loss: 4.0925 - accuracy: 0.7145\n",
      "Epoch 354/500\n",
      "68/68 [==============================] - 0s 482us/step - loss: 4.2490 - accuracy: 0.7128\n",
      "Epoch 355/500\n",
      "68/68 [==============================] - 0s 390us/step - loss: 4.1079 - accuracy: 0.7169\n",
      "Epoch 356/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 4.2323 - accuracy: 0.7092\n",
      "Epoch 357/500\n",
      "68/68 [==============================] - 0s 382us/step - loss: 4.1942 - accuracy: 0.7151\n",
      "Epoch 358/500\n",
      "68/68 [==============================] - 0s 420us/step - loss: 4.0453 - accuracy: 0.7193\n",
      "Epoch 359/500\n",
      "68/68 [==============================] - 0s 412us/step - loss: 4.1920 - accuracy: 0.7104\n",
      "Epoch 360/500\n",
      "68/68 [==============================] - 0s 428us/step - loss: 4.1689 - accuracy: 0.7021\n",
      "Epoch 361/500\n",
      "68/68 [==============================] - 0s 596us/step - loss: 4.0655 - accuracy: 0.7181\n",
      "Epoch 362/500\n",
      "68/68 [==============================] - 0s 410us/step - loss: 4.1716 - accuracy: 0.7080\n",
      "Epoch 363/500\n",
      "68/68 [==============================] - 0s 413us/step - loss: 4.1863 - accuracy: 0.7074\n",
      "Epoch 364/500\n",
      "68/68 [==============================] - 0s 436us/step - loss: 4.3245 - accuracy: 0.7134\n",
      "Epoch 365/500\n",
      "68/68 [==============================] - 0s 435us/step - loss: 4.3422 - accuracy: 0.7009\n",
      "Epoch 366/500\n",
      "68/68 [==============================] - 0s 448us/step - loss: 4.0979 - accuracy: 0.7139\n",
      "Epoch 367/500\n",
      "68/68 [==============================] - 0s 548us/step - loss: 4.0757 - accuracy: 0.7199\n",
      "Epoch 368/500\n",
      "68/68 [==============================] - 0s 418us/step - loss: 4.1070 - accuracy: 0.7175\n",
      "Epoch 369/500\n",
      "68/68 [==============================] - 0s 403us/step - loss: 4.1019 - accuracy: 0.7139\n",
      "Epoch 370/500\n",
      "68/68 [==============================] - 0s 458us/step - loss: 4.1008 - accuracy: 0.7240\n",
      "Epoch 371/500\n",
      "68/68 [==============================] - 0s 922us/step - loss: 3.9854 - accuracy: 0.7222\n",
      "Epoch 372/500\n",
      "68/68 [==============================] - 0s 475us/step - loss: 4.0554 - accuracy: 0.7169\n",
      "Epoch 373/500\n",
      "68/68 [==============================] - 0s 478us/step - loss: 4.0006 - accuracy: 0.7175\n",
      "Epoch 374/500\n",
      "68/68 [==============================] - 0s 374us/step - loss: 4.2008 - accuracy: 0.7039\n",
      "Epoch 375/500\n",
      "68/68 [==============================] - 0s 400us/step - loss: 4.0754 - accuracy: 0.7216\n",
      "Epoch 376/500\n",
      "68/68 [==============================] - 0s 445us/step - loss: 4.0727 - accuracy: 0.7145\n",
      "Epoch 377/500\n",
      "68/68 [==============================] - 0s 458us/step - loss: 4.1931 - accuracy: 0.7181\n",
      "Epoch 378/500\n",
      "68/68 [==============================] - 0s 659us/step - loss: 4.0839 - accuracy: 0.7039\n",
      "Epoch 379/500\n",
      "68/68 [==============================] - 0s 467us/step - loss: 4.0607 - accuracy: 0.7216\n",
      "Epoch 380/500\n",
      "68/68 [==============================] - 0s 466us/step - loss: 4.5724 - accuracy: 0.7069\n",
      "Epoch 381/500\n",
      "68/68 [==============================] - 0s 391us/step - loss: 4.0330 - accuracy: 0.7145\n",
      "Epoch 382/500\n",
      "68/68 [==============================] - 0s 408us/step - loss: 4.0009 - accuracy: 0.7264\n",
      "Epoch 383/500\n",
      "68/68 [==============================] - 0s 400us/step - loss: 4.0335 - accuracy: 0.7145\n",
      "Epoch 384/500\n",
      "68/68 [==============================] - 0s 439us/step - loss: 4.1401 - accuracy: 0.7134\n",
      "Epoch 385/500\n",
      "68/68 [==============================] - 0s 643us/step - loss: 3.9878 - accuracy: 0.7246\n",
      "Epoch 386/500\n",
      "68/68 [==============================] - 0s 385us/step - loss: 4.0803 - accuracy: 0.7305\n",
      "Epoch 387/500\n",
      "68/68 [==============================] - 0s 430us/step - loss: 4.1522 - accuracy: 0.7110\n",
      "Epoch 388/500\n",
      "68/68 [==============================] - 0s 442us/step - loss: 3.9463 - accuracy: 0.7228\n",
      "Epoch 389/500\n",
      "68/68 [==============================] - 0s 482us/step - loss: 3.9707 - accuracy: 0.7187\n",
      "Epoch 390/500\n",
      "68/68 [==============================] - 0s 472us/step - loss: 3.9889 - accuracy: 0.7222\n",
      "Epoch 391/500\n",
      "68/68 [==============================] - 0s 437us/step - loss: 4.0675 - accuracy: 0.7175\n",
      "Epoch 392/500\n",
      "68/68 [==============================] - 0s 394us/step - loss: 4.0887 - accuracy: 0.7175\n",
      "Epoch 393/500\n",
      "68/68 [==============================] - 0s 397us/step - loss: 4.0062 - accuracy: 0.7270\n",
      "Epoch 394/500\n",
      "68/68 [==============================] - 0s 395us/step - loss: 4.0386 - accuracy: 0.7193\n",
      "Epoch 395/500\n",
      "68/68 [==============================] - 0s 379us/step - loss: 4.0163 - accuracy: 0.7270\n",
      "Epoch 396/500\n",
      "68/68 [==============================] - 0s 392us/step - loss: 4.0513 - accuracy: 0.7258\n",
      "Epoch 397/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 3.9850 - accuracy: 0.7293\n",
      "Epoch 398/500\n",
      "68/68 [==============================] - 0s 427us/step - loss: 3.9600 - accuracy: 0.7275\n",
      "Epoch 399/500\n",
      "68/68 [==============================] - 0s 412us/step - loss: 4.1429 - accuracy: 0.7128\n",
      "Epoch 400/500\n",
      "68/68 [==============================] - 0s 445us/step - loss: 3.9317 - accuracy: 0.7258\n",
      "Epoch 401/500\n",
      "68/68 [==============================] - 0s 423us/step - loss: 4.0005 - accuracy: 0.7287\n",
      "Epoch 402/500\n",
      "68/68 [==============================] - 0s 430us/step - loss: 3.9892 - accuracy: 0.7281\n",
      "Epoch 403/500\n",
      "68/68 [==============================] - 0s 436us/step - loss: 3.9279 - accuracy: 0.7405\n",
      "Epoch 404/500\n",
      "68/68 [==============================] - 0s 390us/step - loss: 4.0916 - accuracy: 0.7092\n",
      "Epoch 405/500\n",
      "68/68 [==============================] - 0s 362us/step - loss: 3.9442 - accuracy: 0.7240\n",
      "Epoch 406/500\n",
      "68/68 [==============================] - 0s 376us/step - loss: 3.9486 - accuracy: 0.7370\n",
      "Epoch 407/500\n",
      "68/68 [==============================] - 0s 408us/step - loss: 4.0527 - accuracy: 0.7151\n",
      "Epoch 408/500\n",
      "68/68 [==============================] - 0s 418us/step - loss: 4.0149 - accuracy: 0.7199\n",
      "Epoch 409/500\n",
      "68/68 [==============================] - 0s 403us/step - loss: 4.0764 - accuracy: 0.7246\n",
      "Epoch 410/500\n",
      "68/68 [==============================] - 0s 497us/step - loss: 4.0744 - accuracy: 0.7258\n",
      "Epoch 411/500\n",
      "68/68 [==============================] - 0s 501us/step - loss: 3.9176 - accuracy: 0.7405\n",
      "Epoch 412/500\n",
      "68/68 [==============================] - 0s 426us/step - loss: 3.9874 - accuracy: 0.7193\n",
      "Epoch 413/500\n",
      "68/68 [==============================] - 0s 471us/step - loss: 4.0117 - accuracy: 0.7270\n",
      "Epoch 414/500\n",
      "68/68 [==============================] - 0s 944us/step - loss: 3.8960 - accuracy: 0.7323\n",
      "Epoch 415/500\n",
      "68/68 [==============================] - 0s 537us/step - loss: 3.8997 - accuracy: 0.7275\n",
      "Epoch 416/500\n",
      "68/68 [==============================] - 0s 510us/step - loss: 3.9049 - accuracy: 0.7252\n",
      "Epoch 417/500\n",
      "68/68 [==============================] - 0s 474us/step - loss: 3.9349 - accuracy: 0.7335\n",
      "Epoch 418/500\n",
      "68/68 [==============================] - 0s 392us/step - loss: 4.0227 - accuracy: 0.7287\n",
      "Epoch 419/500\n",
      "68/68 [==============================] - 0s 409us/step - loss: 3.9679 - accuracy: 0.7128\n",
      "Epoch 420/500\n",
      "68/68 [==============================] - 0s 375us/step - loss: 3.9130 - accuracy: 0.7311\n",
      "Epoch 421/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 3.8140 - accuracy: 0.7340\n",
      "Epoch 422/500\n",
      "68/68 [==============================] - 0s 357us/step - loss: 3.8900 - accuracy: 0.7234\n",
      "Epoch 423/500\n",
      "68/68 [==============================] - 0s 368us/step - loss: 3.8700 - accuracy: 0.7311\n",
      "Epoch 424/500\n",
      "68/68 [==============================] - 0s 950us/step - loss: 3.8898 - accuracy: 0.7305\n",
      "Epoch 425/500\n",
      "68/68 [==============================] - 0s 417us/step - loss: 3.8302 - accuracy: 0.7323\n",
      "Epoch 426/500\n",
      "68/68 [==============================] - 0s 412us/step - loss: 3.9203 - accuracy: 0.7275\n",
      "Epoch 427/500\n",
      "68/68 [==============================] - 0s 475us/step - loss: 3.8461 - accuracy: 0.7340\n",
      "Epoch 428/500\n",
      "68/68 [==============================] - 0s 436us/step - loss: 3.8762 - accuracy: 0.7364\n",
      "Epoch 429/500\n",
      "68/68 [==============================] - 0s 643us/step - loss: 3.8666 - accuracy: 0.7281\n",
      "Epoch 430/500\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 3.8755 - accuracy: 0.7376\n",
      "Epoch 431/500\n",
      "68/68 [==============================] - 0s 381us/step - loss: 3.9260 - accuracy: 0.7216\n",
      "Epoch 432/500\n",
      "68/68 [==============================] - 0s 383us/step - loss: 3.9937 - accuracy: 0.7228\n",
      "Epoch 433/500\n",
      "68/68 [==============================] - 0s 371us/step - loss: 3.9268 - accuracy: 0.7281\n",
      "Epoch 434/500\n",
      "68/68 [==============================] - 0s 385us/step - loss: 3.8664 - accuracy: 0.7317\n",
      "Epoch 435/500\n",
      "68/68 [==============================] - 0s 359us/step - loss: 3.9156 - accuracy: 0.7246\n",
      "Epoch 436/500\n",
      "68/68 [==============================] - 0s 375us/step - loss: 3.8404 - accuracy: 0.7329\n",
      "Epoch 437/500\n",
      "68/68 [==============================] - 0s 408us/step - loss: 3.8901 - accuracy: 0.7270\n",
      "Epoch 438/500\n",
      "68/68 [==============================] - 0s 376us/step - loss: 3.8498 - accuracy: 0.7370\n",
      "Epoch 439/500\n",
      "68/68 [==============================] - 0s 445us/step - loss: 3.8390 - accuracy: 0.7400\n",
      "Epoch 440/500\n",
      "68/68 [==============================] - 0s 374us/step - loss: 3.9372 - accuracy: 0.7358\n",
      "Epoch 441/500\n",
      "68/68 [==============================] - 0s 421us/step - loss: 3.8223 - accuracy: 0.7411\n",
      "Epoch 442/500\n",
      "68/68 [==============================] - 0s 373us/step - loss: 3.8463 - accuracy: 0.7275\n",
      "Epoch 443/500\n",
      "68/68 [==============================] - 0s 377us/step - loss: 3.9784 - accuracy: 0.7346\n",
      "Epoch 444/500\n",
      "68/68 [==============================] - 0s 375us/step - loss: 3.8937 - accuracy: 0.7346\n",
      "Epoch 445/500\n",
      "68/68 [==============================] - 0s 410us/step - loss: 3.9049 - accuracy: 0.7311\n",
      "Epoch 446/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 3.8016 - accuracy: 0.7340\n",
      "Epoch 447/500\n",
      "68/68 [==============================] - 0s 428us/step - loss: 3.9118 - accuracy: 0.7216\n",
      "Epoch 448/500\n",
      "68/68 [==============================] - 0s 367us/step - loss: 3.7884 - accuracy: 0.7411\n",
      "Epoch 449/500\n",
      "68/68 [==============================] - 0s 359us/step - loss: 3.8613 - accuracy: 0.7335\n",
      "Epoch 450/500\n",
      "68/68 [==============================] - 0s 355us/step - loss: 3.8542 - accuracy: 0.7305\n",
      "Epoch 451/500\n",
      "68/68 [==============================] - 0s 478us/step - loss: 3.8420 - accuracy: 0.7299\n",
      "Epoch 452/500\n",
      "68/68 [==============================] - 0s 362us/step - loss: 3.8208 - accuracy: 0.7246\n",
      "Epoch 453/500\n",
      "68/68 [==============================] - 0s 347us/step - loss: 3.8751 - accuracy: 0.7305\n",
      "Epoch 454/500\n",
      "68/68 [==============================] - 0s 416us/step - loss: 3.8583 - accuracy: 0.7346\n",
      "Epoch 455/500\n",
      "68/68 [==============================] - 0s 396us/step - loss: 3.9233 - accuracy: 0.7293\n",
      "Epoch 456/500\n",
      "68/68 [==============================] - 0s 918us/step - loss: 3.7804 - accuracy: 0.7346\n",
      "Epoch 457/500\n",
      "68/68 [==============================] - 0s 442us/step - loss: 3.7625 - accuracy: 0.7370\n",
      "Epoch 458/500\n",
      "68/68 [==============================] - 0s 451us/step - loss: 3.7607 - accuracy: 0.7340\n",
      "Epoch 459/500\n",
      "68/68 [==============================] - 0s 423us/step - loss: 3.8381 - accuracy: 0.7270\n",
      "Epoch 460/500\n",
      "68/68 [==============================] - 0s 407us/step - loss: 3.7968 - accuracy: 0.7258\n",
      "Epoch 461/500\n",
      "68/68 [==============================] - 0s 403us/step - loss: 3.8378 - accuracy: 0.7293\n",
      "Epoch 462/500\n",
      "68/68 [==============================] - 0s 376us/step - loss: 3.8635 - accuracy: 0.7317\n",
      "Epoch 463/500\n",
      "68/68 [==============================] - 0s 415us/step - loss: 3.7229 - accuracy: 0.7476\n",
      "Epoch 464/500\n",
      "68/68 [==============================] - 0s 376us/step - loss: 3.7582 - accuracy: 0.7405\n",
      "Epoch 465/500\n",
      "68/68 [==============================] - 0s 473us/step - loss: 3.7750 - accuracy: 0.7388\n",
      "Epoch 466/500\n",
      "68/68 [==============================] - 0s 378us/step - loss: 3.9352 - accuracy: 0.7234\n",
      "Epoch 467/500\n",
      "68/68 [==============================] - 0s 392us/step - loss: 3.7882 - accuracy: 0.7376\n",
      "Epoch 468/500\n",
      "68/68 [==============================] - 0s 426us/step - loss: 3.7624 - accuracy: 0.7340\n",
      "Epoch 469/500\n",
      "68/68 [==============================] - 0s 414us/step - loss: 3.8820 - accuracy: 0.7311\n",
      "Epoch 470/500\n",
      "68/68 [==============================] - 0s 540us/step - loss: 3.8119 - accuracy: 0.7382\n",
      "Epoch 471/500\n",
      "68/68 [==============================] - 0s 436us/step - loss: 3.8283 - accuracy: 0.7346\n",
      "Epoch 472/500\n",
      "68/68 [==============================] - 0s 376us/step - loss: 3.8330 - accuracy: 0.7465\n",
      "Epoch 473/500\n",
      "68/68 [==============================] - 0s 389us/step - loss: 3.8131 - accuracy: 0.7465\n",
      "Epoch 474/500\n",
      "68/68 [==============================] - 0s 387us/step - loss: 3.7147 - accuracy: 0.7376\n",
      "Epoch 475/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 3.6560 - accuracy: 0.7459\n",
      "Epoch 476/500\n",
      "68/68 [==============================] - 0s 591us/step - loss: 3.8811 - accuracy: 0.7293\n",
      "Epoch 477/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 3.7209 - accuracy: 0.7370\n",
      "Epoch 478/500\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 3.8245 - accuracy: 0.7311\n",
      "Epoch 479/500\n",
      "68/68 [==============================] - 0s 738us/step - loss: 3.7080 - accuracy: 0.7476\n",
      "Epoch 480/500\n",
      "68/68 [==============================] - 0s 590us/step - loss: 3.7642 - accuracy: 0.7518\n",
      "Epoch 481/500\n",
      "68/68 [==============================] - 0s 443us/step - loss: 3.8681 - accuracy: 0.7340\n",
      "Epoch 482/500\n",
      "68/68 [==============================] - 0s 576us/step - loss: 3.7249 - accuracy: 0.7465\n",
      "Epoch 483/500\n",
      "68/68 [==============================] - 0s 422us/step - loss: 3.7635 - accuracy: 0.7364\n",
      "Epoch 484/500\n",
      "68/68 [==============================] - 0s 464us/step - loss: 3.8077 - accuracy: 0.7382\n",
      "Epoch 485/500\n",
      "68/68 [==============================] - 0s 451us/step - loss: 3.8103 - accuracy: 0.7323\n",
      "Epoch 486/500\n",
      "68/68 [==============================] - 0s 498us/step - loss: 3.7941 - accuracy: 0.7388\n",
      "Epoch 487/500\n",
      "68/68 [==============================] - 0s 560us/step - loss: 4.0271 - accuracy: 0.7210\n",
      "Epoch 488/500\n",
      "68/68 [==============================] - 0s 555us/step - loss: 3.8787 - accuracy: 0.7329\n",
      "Epoch 489/500\n",
      "68/68 [==============================] - 0s 526us/step - loss: 3.6730 - accuracy: 0.7553\n",
      "Epoch 490/500\n",
      "68/68 [==============================] - 0s 394us/step - loss: 3.6435 - accuracy: 0.7417\n",
      "Epoch 491/500\n",
      "68/68 [==============================] - 0s 418us/step - loss: 3.8173 - accuracy: 0.7435\n",
      "Epoch 492/500\n",
      "68/68 [==============================] - 0s 394us/step - loss: 3.7029 - accuracy: 0.7459\n",
      "Epoch 493/500\n",
      "68/68 [==============================] - 0s 361us/step - loss: 3.7832 - accuracy: 0.7405\n",
      "Epoch 494/500\n",
      "68/68 [==============================] - 0s 490us/step - loss: 3.7527 - accuracy: 0.7518\n",
      "Epoch 495/500\n",
      "68/68 [==============================] - 0s 899us/step - loss: 3.6747 - accuracy: 0.7459\n",
      "Epoch 496/500\n",
      "68/68 [==============================] - 0s 471us/step - loss: 3.6233 - accuracy: 0.7453\n",
      "Epoch 497/500\n",
      "68/68 [==============================] - 0s 598us/step - loss: 3.7021 - accuracy: 0.7394\n",
      "Epoch 498/500\n",
      "68/68 [==============================] - 0s 390us/step - loss: 3.7811 - accuracy: 0.7447\n",
      "Epoch 499/500\n",
      "68/68 [==============================] - 0s 418us/step - loss: 3.7902 - accuracy: 0.7317\n",
      "Epoch 500/500\n",
      "68/68 [==============================] - 0s 395us/step - loss: 3.6911 - accuracy: 0.7400\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 531us/step - loss: 10.8597 - accuracy: 0.4858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.85971736907959, 0.4858490526676178]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 430us/step\n"
     ]
    }
   ],
   "source": [
    "y_hat = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_shots = 0\n",
    "total_shots_over = 0\n",
    "total_shots_under = 0\n",
    "\n",
    "total_shots_on_target = 0\n",
    "total_shots_on_target_over = 0\n",
    "total_shots_on_target_under = 0\n",
    "\n",
    "total_booking_points = 0\n",
    "total_booking_points_over = 0\n",
    "total_booking_points_under = 0\n",
    "\n",
    "correct_score = 0\n",
    "\n",
    "winner = 0\n",
    "\n",
    "total_corners = 0\n",
    "total_corners_over = 0\n",
    "total_corners_under = 0\n",
    "\n",
    "total_fouls = 0\n",
    "total_fouls_over = 0\n",
    "total_fouls_under = 0\n",
    "\n",
    "goals_over = 0\n",
    "goals_under = 0\n",
    "\n",
    "all_under = 0\n",
    "all_over = 0\n",
    "\n",
    "total_tested  = len(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, y in enumerate(y_hat):\n",
    "\thome_goals_hat, away_goals_hat, home_shots_hat, away_shots_hat, home_shots_on_target_hat, away_shots_on_target_hat, home_corners_hat, away_corners_hat, home_fouls_hat, away_fouls_hat, home_yellow_cards_hat, away_yellow_cards_hat, home_red_cards_hat, away_red_cards_hat = y\n",
    "\thome_goals, away_goals, home_shots, away_shots, home_shots_on_target, away_shots_on_target, home_corners, away_corners, home_fouls, away_fouls, home_yellow_cards, away_yellow_cards, home_red_cards, away_red_cards = y_test.iloc[idx].tolist()\n",
    "\t\n",
    "\ttotal_shots += 1 if home_shots_hat+away_shots_hat == home_shots+away_shots else 0\n",
    "\ttotal_shots_over += 1 if home_shots_hat+away_shots_hat > home_shots+away_shots else 0\n",
    "\ttotal_shots_under += 1 if home_shots_hat+away_shots_hat < home_shots+away_shots else 0\n",
    "\t\n",
    "\ttotal_shots_on_target += 1 if home_shots_on_target_hat+away_shots_on_target_hat == home_shots_on_target+away_shots_on_target else 0\n",
    "\ttotal_shots_on_target_over += 1 if home_shots_on_target_hat+away_shots_on_target_hat > home_shots_on_target+away_shots_on_target else 0\n",
    "\ttotal_shots_on_target_under += 1 if home_shots_on_target_hat+away_shots_on_target_hat < home_shots_on_target+away_shots_on_target else 0\n",
    "\n",
    "\ttotal_booking_points += 1 if (home_yellow_cards_hat+away_yellow_cards_hat)*10+(home_red_cards_hat+away_red_cards_hat)*25 == (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 else 0\n",
    "\ttotal_booking_points_over += 1 if (home_yellow_cards_hat+away_yellow_cards_hat)*10+(home_red_cards_hat+away_red_cards_hat)*25 > (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 else 0\n",
    "\ttotal_booking_points_under += 1 if (home_yellow_cards_hat+away_yellow_cards_hat)*10+(home_red_cards_hat+away_red_cards_hat)*25 < (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 else 0\n",
    "\n",
    "\tcorrect_score += 1 if home_goals_hat == home_goals and away_goals_hat == away_goals else 0\n",
    "\t\n",
    "\twinner += 1 if (home_goals_hat > away_goals_hat and home_goals > away_goals) or (home_goals_hat < away_goals_hat and home_goals < away_goals) else 0\n",
    "\n",
    "\ttotal_fouls += 1 if home_fouls_hat + away_fouls_hat == home_fouls + away_fouls else 0\n",
    "\ttotal_fouls_over += 1 if home_fouls_hat + away_fouls_hat > home_fouls+ away_fouls else 0\n",
    "\ttotal_fouls_under += 1 if home_fouls_hat + away_fouls_hat < home_fouls+ away_fouls else 0\n",
    "\n",
    "\ttotal_corners += 1 if home_corners_hat + away_corners_hat == home_corners + away_corners else 0\n",
    "\ttotal_corners_over += 1 if home_corners_hat + away_corners_hat > home_corners + away_corners else 0\n",
    "\ttotal_corners_under += 1 if home_corners_hat + away_corners_hat < home_corners + away_corners else 0\n",
    "\n",
    "\tgoals_over += 1 if home_goals_hat + away_goals_hat > home_goals + away_goals else 0\n",
    "\tgoals_under += 1 if home_goals_hat + away_goals_hat < home_goals + away_goals else 0\n",
    "\n",
    "\tall_under += 1 if home_shots_hat+away_shots_hat < home_shots+away_shots and home_shots_on_target_hat+away_shots_on_target_hat < home_shots_on_target+away_shots_on_target and (home_yellow_cards_hat+away_yellow_cards_hat)*10+(home_red_cards_hat+away_red_cards_hat)*25 < (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 and home_corners_hat + away_corners_hat < home_corners + away_corners and home_corners_hat + away_corners_hat < home_corners + away_corners and home_goals_hat + away_goals_hat < home_goals + away_goals else 0\n",
    "\tall_over += 1 if home_shots_hat+away_shots_hat > home_shots+away_shots and home_shots_on_target_hat+away_shots_on_target_hat > home_shots_on_target+away_shots_on_target and (home_yellow_cards_hat+away_yellow_cards_hat)*10+(home_red_cards_hat+away_red_cards_hat)*25 > (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 and home_corners_hat + away_corners_hat > home_corners + away_corners and home_goals_hat + away_goals_hat > home_goals + away_goals else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_shots: 0.0\n",
      "total_shots_over: 0.5872641509433962\n",
      "total_shots_under: 0.41273584905660377\n",
      "\n",
      "\n",
      "total_shots_on_target: 0.0\n",
      "total_shots_on_target_over: 0.5849056603773585\n",
      "total_shots_on_target_under: 0.41509433962264153\n",
      "\n",
      "\n",
      "total_booking_points: 0.0\n",
      "total_booking_points_over: 0.5023584905660378\n",
      "total_booking_points_under: 0.49764150943396224\n",
      "\n",
      "\n",
      "correct_score: 0.0\n",
      "\n",
      "\n",
      "winner: 0.5966981132075472\n",
      "\n",
      "\n",
      "total_corners: 0.0\n",
      "total_corners_over: 0.535377358490566\n",
      "total_corners_under: 0.46462264150943394\n",
      "\n",
      "\n",
      "total_fouls: 0.0\n",
      "total_fouls_over: 0.5023584905660378\n",
      "total_fouls_under: 0.49764150943396224\n",
      "\n",
      "\n",
      "goals_over: 0.5589622641509434\n",
      "goals_under: 0.4410377358490566\n",
      "\n",
      "\n",
      "all_over: 0.08490566037735849\n",
      "all_under: 0.05188679245283019\n"
     ]
    }
   ],
   "source": [
    "print(\"total_shots: \"+str(total_shots/total_tested))\n",
    "print(\"total_shots_over: \"+str(total_shots_over/total_tested))\n",
    "print(\"total_shots_under: \"+str(total_shots_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"total_shots_on_target: \"+str(total_shots_on_target/total_tested))\n",
    "print(\"total_shots_on_target_over: \"+str(total_shots_on_target_over/total_tested))\n",
    "print(\"total_shots_on_target_under: \"+str(total_shots_on_target_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"total_booking_points: \"+str(total_booking_points/total_tested))\n",
    "print(\"total_booking_points_over: \"+str(total_booking_points_over/total_tested))\n",
    "print(\"total_booking_points_under: \"+str(total_booking_points_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"correct_score: \"+str(correct_score/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"winner: \"+str(winner/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"total_corners: \"+str(total_corners/total_tested))\n",
    "print(\"total_corners_over: \"+str(total_corners_over/total_tested))\n",
    "print(\"total_corners_under: \"+str(total_corners_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"total_fouls: \"+str(total_fouls/total_tested))\n",
    "print(\"total_fouls_over: \"+str(total_fouls_over/total_tested))\n",
    "print(\"total_fouls_under: \"+str(total_fouls_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"goals_over: \"+str(goals_over/total_tested))\n",
    "print(\"goals_under: \"+str(goals_under/total_tested))\n",
    "print(\"\\n\")\n",
    "print(\"all_over: \"+str(all_over/total_tested))\n",
    "print(\"all_under: \"+str(all_under/total_tested))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to build and compile a model, with the arguments in it being the values to be update during tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp_model(hidden_layer_one=13, dropout=0.2, learn_rate=0.01, n_h_layers=1):\n",
    "\n",
    "\tmodel = tf.keras.models.Sequential()\n",
    "\n",
    "\t#Â input\n",
    "\tmodel.add(tf.keras.layers.Dense(75, activation=\"relu\", input_dim=75))\n",
    "\n",
    "\tfor i in range(n_h_layers):\n",
    "\t\tmodel.add(tf.keras.layers.Dense(hidden_layer_one, activation=\"relu\"))\n",
    "\n",
    "\t# dropout layer to remove redundant nodes\n",
    "\tmodel.add(tf.keras.layers.Dropout(dropout))\n",
    "\t\n",
    "\t# output\n",
    "\tmodel.add(tf.keras.layers.Dense(14, activation=\"relu\"))\n",
    "\n",
    "\tmodel.compile(\n",
    "\t\toptimizer=\"sgd\",\n",
    "\t\tloss=\"mse\",\n",
    "\t\tmetrics=[\"accuracy\"])\n",
    "\t\n",
    "\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a model using the *get_mlp_model* function, letting tensorflow use this function when building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(model=get_mlp_model, verbose=0, hidden_layer_one=10, learn_rate=0.01, dropout=0.05, n_h_layers=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameter search space, and then generate the search object to be used later, by RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a grid of the hyperparameter search space\n",
    "hidden_layer_one = [30, 50, 70]\n",
    "learn_rate = [1e-2, 1e-3, 1e-4]\n",
    "dropout = [0.1, 0.2, 0.3]\n",
    "batch_size = [16, 32, 64]\n",
    "epochs = [100, 200, 500]\n",
    "n_h_layers = [1, 2, 3, 4]\n",
    "\n",
    "# create a dictionary from the hyperparameter grid\n",
    "grid = dict(\n",
    "\thidden_layer_one=hidden_layer_one,\n",
    "\tlearn_rate=learn_rate,\n",
    "\tdropout=dropout,\n",
    "\tbatch_size=batch_size,\n",
    "\tepochs=epochs,\n",
    "\tn_h_layers=n_h_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a scoring function for the searcher, average the value of all the *under* stats and return this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(estimator, test_x: np.ndarray, test_y: pd.DataFrame) -> float:\n",
    "\ttest_y = test_y.to_numpy()\n",
    "\t\n",
    "\t# estimator.save(\"../stats_regression_model.h5\")\n",
    "\ty_hat = estimator.predict(test_x)\n",
    "\t\n",
    "\taverage_under_rate = 0\n",
    "\n",
    "\ttotal_shots_under = 0\n",
    "\ttotal_shots_on_target_under = 0\n",
    "\ttotal_booking_points_under = 0\n",
    "\ttotal_corners_under = 0\n",
    "\ttotal_fouls_under = 0\n",
    "\tgoals_under = 0\n",
    "\n",
    "\ttotal_tested = len(y_hat)\n",
    "\t\n",
    "\tfor idx, y in enumerate(y_hat):\n",
    "\n",
    "\t\thome_goals_hat, away_goals_hat, home_shots_hat, away_shots_hat, home_shots_on_target_hat, away_shots_on_target_hat, home_corners_hat, away_corners_hat, home_fouls_hat, away_fouls_hat, home_yellow_cards_hat, away_yellow_cards_hat, home_red_cards_hat, away_red_cards_hat = y\n",
    "\t\thome_goals, away_goals, home_shots, away_shots, home_shots_on_target, away_shots_on_target, home_corners, away_corners, home_fouls, away_fouls, home_yellow_cards, away_yellow_cards, home_red_cards, away_red_cards = test_y[idx]\n",
    "\n",
    "\t\ttotal_shots_under += 1 if np.floor(home_shots_hat)+np.floor(away_shots_hat) < home_shots+away_shots else 0\n",
    "\t\ttotal_shots_on_target_under += 1 if np.floor(home_shots_on_target_hat)+np.floor(away_shots_on_target_hat) < home_shots_on_target+away_shots_on_target else 0\n",
    "\t\ttotal_booking_points_under += 1 if (np.floor(home_yellow_cards_hat)+np.floor(away_yellow_cards_hat))*10+(np.floor(home_red_cards_hat)+np.floor(away_red_cards_hat))*25 < (home_yellow_cards+away_yellow_cards)*10+(home_red_cards+away_red_cards)*25 else 0\n",
    "\t\ttotal_corners_under += 1 if np.floor(home_corners_hat) + np.floor(away_corners_hat) < home_corners + away_corners else 0\n",
    "\t\ttotal_fouls_under += 1 if np.floor(home_fouls_hat) + np.floor(away_fouls_hat) < home_fouls+ away_fouls else 0\n",
    "\t\tgoals_under += 1 if np.floor(home_goals_hat) + np.floor(away_goals_hat) < home_goals + away_goals else 0\n",
    "\n",
    "\t\taverage_under_rate += ((total_shots_under/total_tested)+(total_shots_on_target_under/total_tested)+(total_booking_points_under/total_tested)+(total_fouls_under/total_tested)+(total_corners_under/total_tested)+(goals_under/total_tested))/6\n",
    "\n",
    "\taverage_under_rate = average_under_rate/total_tested\n",
    "\t\n",
    "\treturn average_under_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the searcher object, used to iterate over the search parameters and determine the best hyper-parameter setup from the space we've created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 972 candidates, totalling 2916 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 01:09:44.325310: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-02-21 01:09:44.746270: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-02-21 01:09:44.781239: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-02-21 01:09:44.844392: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-02-21 01:09:44.865312: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-02-21 01:09:44.867893: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-02-21 01:09:44.869603: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=1;, score=0.302 total time=  10.7s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=2;, score=0.293 total time=  10.1s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=1;, score=0.275 total time=  10.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=1;, score=0.280 total time=  10.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=2;, score=0.286 total time=  10.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=3;, score=0.320 total time=  10.7s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=2;, score=0.338 total time=  11.1s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=3;, score=0.276 total time=   9.5s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=4;, score=0.282 total time=   9.4s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=4;, score=0.273 total time=  10.0s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=1;, score=0.290 total time=   9.4s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=1;, score=0.299 total time=   9.8s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=3;, score=0.315 total time=  10.8s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.01, n_h_layers=4;, score=0.321 total time=  11.4s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=1;, score=0.284 total time=  10.0s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=2;, score=0.285 total time=   9.5s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=2;, score=0.299 total time=   9.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=3;, score=0.331 total time=   9.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=3;, score=0.293 total time=   9.5s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=2;, score=0.283 total time=  11.2s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=3;, score=0.320 total time=  10.4s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=4;, score=0.277 total time=   9.4s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=4;, score=0.323 total time=   9.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=1;, score=0.308 total time=   8.8s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=1;, score=0.313 total time=   8.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=2;, score=0.289 total time=   8.7s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.001, n_h_layers=4;, score=0.276 total time=  11.3s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=1;, score=0.313 total time=  11.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=3;, score=0.292 total time=   8.7s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=2;, score=0.270 total time=   9.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=2;, score=0.301 total time=  11.0s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=3;, score=0.313 total time=   9.1s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=4;, score=0.284 total time=   8.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=3;, score=0.298 total time=  10.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=4;, score=0.321 total time=  11.3s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=4;, score=0.262 total time=   9.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=1;, score=0.304 total time=   9.9s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=2;, score=0.335 total time=   9.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=1;, score=0.293 total time=   9.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=1;, score=0.300 total time=   9.7s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=2;, score=0.296 total time=   9.7s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=2;, score=0.266 total time=  11.6s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=3;, score=0.264 total time=  10.9s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=3;, score=0.290 total time=  12.0s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=3;, score=0.263 total time=  11.2s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=4;, score=0.268 total time=  11.4s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=4;, score=0.295 total time=  11.1s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.01, n_h_layers=4;, score=0.284 total time=  11.5s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=1;, score=0.320 total time=   9.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=1;, score=0.275 total time=  10.1s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=1;, score=0.296 total time=   9.7s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=2;, score=0.281 total time=  10.4s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=2;, score=0.295 total time=  10.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=2;, score=0.294 total time=  11.1s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=3;, score=0.300 total time=  11.0s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=3;, score=0.255 total time=  12.3s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=3;, score=0.272 total time=  12.2s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=4;, score=0.249 total time=  12.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=1;, score=0.300 total time=  10.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=1;, score=0.288 total time=  11.1s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=4;, score=0.323 total time=  12.5s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.001, n_h_layers=4;, score=0.298 total time=  12.0s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=1;, score=0.310 total time=  10.1s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=2;, score=0.279 total time=  10.0s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=2;, score=0.257 total time=  10.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=2;, score=0.293 total time=  10.6s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=3;, score=0.304 total time=  10.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=3;, score=0.289 total time=  10.5s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=3;, score=0.292 total time=  10.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=4;, score=0.313 total time=  11.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=1;, score=0.247 total time=   7.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=4;, score=0.286 total time=   9.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=1;, score=0.300 total time=   8.1s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=4;, score=0.259 total time=   8.8s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=1;, score=0.305 total time=   8.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=2;, score=0.278 total time=   9.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=2;, score=0.275 total time=   8.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=3;, score=0.256 total time=   8.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=3;, score=0.295 total time=   8.8s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=3;, score=0.297 total time=   8.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=4;, score=0.274 total time=   8.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=4;, score=0.270 total time=   7.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=2;, score=0.294 total time=  11.0s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.01, n_h_layers=4;, score=0.270 total time=   7.4s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=1;, score=0.304 total time=   6.7s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=1;, score=0.253 total time=   6.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=1;, score=0.289 total time=   6.6s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=2;, score=0.262 total time=   7.0s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=2;, score=0.269 total time=   7.1s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=2;, score=0.305 total time=   6.7s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=3;, score=0.256 total time=   8.1s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=3;, score=0.319 total time=   7.7s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=3;, score=0.245 total time=   7.4s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=4;, score=0.289 total time=   7.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=4;, score=0.284 total time=   7.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=1;, score=0.298 total time=   7.2s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.001, n_h_layers=4;, score=0.302 total time=   7.6s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=1;, score=0.250 total time=   6.2s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=1;, score=0.283 total time=   6.1s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=2;, score=0.254 total time=   6.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=2;, score=0.272 total time=   6.1s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=2;, score=0.308 total time=   6.4s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=3;, score=0.259 total time=   6.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=3;, score=0.272 total time=   7.1s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=3;, score=0.245 total time=   6.9s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=4;, score=0.296 total time=   6.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=4;, score=0.288 total time=   7.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=100, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=4;, score=0.256 total time=   7.5s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=1;, score=0.313 total time=  12.1s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=1;, score=0.296 total time=  12.0s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=1;, score=0.285 total time=  11.2s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=2;, score=0.281 total time=  11.4s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=2;, score=0.279 total time=  11.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=2;, score=0.289 total time=  12.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=3;, score=0.286 total time=  13.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=3;, score=0.298 total time=  13.7s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=4;, score=0.304 total time=  13.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=3;, score=0.276 total time=  21.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=4;, score=0.296 total time=  14.3s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=1;, score=0.273 total time=  13.0s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.01, n_h_layers=4;, score=0.290 total time=  13.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=1;, score=0.270 total time=  11.9s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=1;, score=0.294 total time=  11.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=2;, score=0.279 total time=  12.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=2;, score=0.253 total time=  12.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=2;, score=0.287 total time=  12.6s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=3;, score=0.264 total time=  12.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=3;, score=0.300 total time=  13.0s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=3;, score=0.276 total time=  12.4s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=4;, score=0.279 total time=  12.9s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=4;, score=0.275 total time=  13.2s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=1;, score=0.277 total time=  12.1s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.001, n_h_layers=4;, score=0.292 total time=  12.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=1;, score=0.287 total time=  11.4s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=1;, score=0.280 total time=  11.5s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=2;, score=0.256 total time=  11.0s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=2;, score=0.297 total time=  10.7s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=2;, score=0.279 total time=  10.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=3;, score=0.285 total time=  11.1s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=3;, score=0.286 total time=  11.3s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=3;, score=0.269 total time=  11.2s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=4;, score=0.273 total time=  11.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=4;, score=0.250 total time=  11.5s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=30, learn_rate=0.0001, n_h_layers=4;, score=0.288 total time=  11.3s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=1;, score=0.279 total time=  10.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=1;, score=0.270 total time=  10.9s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=1;, score=0.277 total time=  10.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=2;, score=0.289 total time=  10.9s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=2;, score=0.285 total time=  10.5s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=2;, score=0.283 total time=  12.1s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=3;, score=0.263 total time=  12.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=3;, score=0.261 total time=  12.8s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=3;, score=0.259 total time=  13.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=4;, score=0.292 total time=  14.0s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=4;, score=0.275 total time=  14.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.01, n_h_layers=4;, score=0.288 total time=  14.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=1;, score=0.280 total time=  13.0s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=1;, score=0.276 total time=  13.2s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=1;, score=0.259 total time=  12.7s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=2;, score=0.271 total time=  12.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=2;, score=0.259 total time=  13.3s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=2;, score=0.274 total time=  12.2s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=3;, score=0.289 total time=  12.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=3;, score=0.301 total time=  12.3s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=3;, score=0.268 total time=  12.1s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=4;, score=0.289 total time=  12.9s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=4;, score=0.287 total time=  12.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.001, n_h_layers=4;, score=0.253 total time=  11.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=1;, score=0.292 total time=  11.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=1;, score=0.285 total time=  11.4s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=1;, score=0.300 total time=  10.7s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=2;, score=0.298 total time=  11.6s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=2;, score=0.271 total time=  11.4s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=2;, score=0.302 total time=  11.0s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=3;, score=0.254 total time=  11.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=3;, score=0.308 total time=  11.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=3;, score=0.275 total time=  11.4s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=4;, score=0.288 total time=  11.4s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=4;, score=0.284 total time=  11.8s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=50, learn_rate=0.0001, n_h_layers=4;, score=0.286 total time=  12.1s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=1;, score=0.270 total time=  11.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=1;, score=0.284 total time=  11.4s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=1;, score=0.302 total time=  11.0s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=2;, score=0.292 total time=  11.6s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=2;, score=0.282 total time=  11.7s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=2;, score=0.276 total time=  12.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=3;, score=0.277 total time=  13.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=3;, score=0.288 total time=  13.5s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=4;, score=0.294 total time=  13.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=4;, score=0.310 total time=  12.7s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=4;, score=0.302 total time=  13.3s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=1;, score=0.302 total time=  11.1s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.01, n_h_layers=3;, score=0.283 total time=  21.1s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=1;, score=0.286 total time=  10.4s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=1;, score=0.273 total time=  10.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=2;, score=0.285 total time=  11.2s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=2;, score=0.283 total time=  11.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=2;, score=0.286 total time=  11.9s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=3;, score=0.285 total time=  12.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=3;, score=0.270 total time=  12.5s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=3;, score=0.309 total time=  12.8s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=4;, score=0.281 total time=  13.3s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=4;, score=0.269 total time=  13.2s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.001, n_h_layers=4;, score=0.274 total time=  14.2s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=1;, score=0.268 total time=  12.3s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=1;, score=0.308 total time=  12.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=1;, score=0.259 total time=  13.5s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=2;, score=0.289 total time=  13.7s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=2;, score=0.289 total time=  13.5s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=2;, score=0.290 total time=  13.3s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=3;, score=0.279 total time=  13.5s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=3;, score=0.295 total time=  13.6s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=3;, score=0.296 total time=  13.1s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=4;, score=0.300 total time=  13.9s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=4;, score=0.283 total time=  13.3s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=200, hidden_layer_one=70, learn_rate=0.0001, n_h_layers=4;, score=0.289 total time=  12.7s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=1;, score=0.260 total time=  29.0s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=1;, score=0.269 total time=  28.8s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=1;, score=0.260 total time=  30.4s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=2;, score=0.279 total time=  30.8s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=2;, score=0.269 total time=  31.0s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=3;, score=0.290 total time=  31.8s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=2;, score=0.289 total time=  41.6s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=3;, score=0.277 total time=  30.3s\n",
      "[CV 3/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=3;, score=0.287 total time=  29.4s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=4;, score=0.295 total time=  29.4s\n",
      "[CV 2/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.01, n_h_layers=4;, score=0.297 total time=  29.5s\n",
      "[CV 1/3] END batch_size=16, dropout=0.1, epochs=500, hidden_layer_one=30, learn_rate=0.001, n_h_layers=1;, score=0.258 total time=  27.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m searcher \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mmodel, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, param_grid\u001b[38;5;241m=\u001b[39mgrid, scoring\u001b[38;5;241m=\u001b[39mscoring, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, refit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m searchResults \u001b[38;5;241m=\u001b[39m searcher\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m      5\u001b[0m bestScore \u001b[38;5;241m=\u001b[39m searchResults\u001b[38;5;241m.\u001b[39mbest_score_\n\u001b[1;32m      6\u001b[0m bestParams \u001b[38;5;241m=\u001b[39m searchResults\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/pl-stats/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "searcher = GridSearchCV(estimator=model, n_jobs=-2, param_grid=grid, scoring=scoring, verbose=4, cv=3, refit=True)\n",
    "\n",
    "searchResults = searcher.fit(X_train, y_train)\n",
    "\n",
    "bestScore = searchResults.best_score_\n",
    "bestParams = searchResults.best_params_\n",
    "print(f\"[INFO] best score is {bestScore} using {bestParams}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 64,\n",
       " 'dropout': 0.1,\n",
       " 'epochs': 100,\n",
       " 'hidden_layer_one': 30,\n",
       " 'learn_rate': 0.01,\n",
       " 'n_h_layers': 3}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model = searcher.best_params_\n",
    "tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "27/27 [==============================] - 0s 939us/step - loss: 33.1961 - accuracy: 0.3020\n",
      "Epoch 2/500\n",
      "27/27 [==============================] - 0s 811us/step - loss: 20.4863 - accuracy: 0.4557\n",
      "Epoch 3/500\n",
      "27/27 [==============================] - 0s 531us/step - loss: 19.6087 - accuracy: 0.4657\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 0s 607us/step - loss: 19.2338 - accuracy: 0.4622\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 18.8544 - accuracy: 0.4675\n",
      "Epoch 6/500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 18.7801 - accuracy: 0.4657\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 0s 551us/step - loss: 18.5783 - accuracy: 0.4687\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 0s 533us/step - loss: 18.3941 - accuracy: 0.4687\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 0s 585us/step - loss: 18.3994 - accuracy: 0.4699\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 0s 580us/step - loss: 18.2976 - accuracy: 0.4693\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 18.1834 - accuracy: 0.4693\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 0s 635us/step - loss: 18.1407 - accuracy: 0.4693\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 0s 721us/step - loss: 18.1138 - accuracy: 0.4699\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 0s 615us/step - loss: 17.9596 - accuracy: 0.4699\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 0s 705us/step - loss: 17.9709 - accuracy: 0.4699\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 17.8439 - accuracy: 0.4693\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 0s 722us/step - loss: 17.7192 - accuracy: 0.4710\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 0s 529us/step - loss: 17.5996 - accuracy: 0.4669\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 0s 785us/step - loss: 17.5926 - accuracy: 0.4687\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 0s 620us/step - loss: 17.5607 - accuracy: 0.4716\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 0s 612us/step - loss: 17.5280 - accuracy: 0.4639\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 0s 470us/step - loss: 17.5226 - accuracy: 0.4675\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 0s 542us/step - loss: 17.5181 - accuracy: 0.4569\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 0s 535us/step - loss: 17.4012 - accuracy: 0.4645\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 17.4584 - accuracy: 0.4563\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 0s 544us/step - loss: 17.4254 - accuracy: 0.4598\n",
      "Epoch 27/500\n",
      "27/27 [==============================] - 0s 644us/step - loss: 17.3232 - accuracy: 0.4663\n",
      "Epoch 28/500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 17.3067 - accuracy: 0.4604\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 17.3161 - accuracy: 0.4639\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 0s 684us/step - loss: 17.2434 - accuracy: 0.4598\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 0s 538us/step - loss: 16.2305 - accuracy: 0.4604\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 0s 649us/step - loss: 8.6279 - accuracy: 0.4734\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 0s 472us/step - loss: 8.0482 - accuracy: 0.5248\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 0s 720us/step - loss: 7.7768 - accuracy: 0.5561\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 0s 649us/step - loss: 7.7432 - accuracy: 0.5514\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 0s 611us/step - loss: 7.7944 - accuracy: 0.5556\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 0s 502us/step - loss: 7.6778 - accuracy: 0.5603\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 0s 689us/step - loss: 7.7082 - accuracy: 0.5573\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 0s 445us/step - loss: 7.5307 - accuracy: 0.5585\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 0s 635us/step - loss: 7.5102 - accuracy: 0.5591\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 7.4721 - accuracy: 0.5609\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 0s 797us/step - loss: 7.4359 - accuracy: 0.5609\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 0s 629us/step - loss: 7.4427 - accuracy: 0.5603\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 7.4500 - accuracy: 0.5615\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 0s 550us/step - loss: 7.4675 - accuracy: 0.5697\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 0s 580us/step - loss: 7.4194 - accuracy: 0.5597\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 0s 522us/step - loss: 7.3520 - accuracy: 0.5615\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 0s 542us/step - loss: 7.3375 - accuracy: 0.5686\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 0s 648us/step - loss: 7.2850 - accuracy: 0.5656\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 7.3839 - accuracy: 0.5656\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 0s 618us/step - loss: 7.1838 - accuracy: 0.5668\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 0s 499us/step - loss: 7.2520 - accuracy: 0.5691\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 0s 531us/step - loss: 7.2653 - accuracy: 0.5691\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 7.2662 - accuracy: 0.5757\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 0s 731us/step - loss: 7.2330 - accuracy: 0.5668\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.1945 - accuracy: 0.5691\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 7.0774 - accuracy: 0.5715\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.1845 - accuracy: 0.5721\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 7.1327 - accuracy: 0.5691\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 7.0834 - accuracy: 0.5768\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 0s 610us/step - loss: 7.0281 - accuracy: 0.5751\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 0s 492us/step - loss: 7.2094 - accuracy: 0.5768\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 0s 542us/step - loss: 7.0449 - accuracy: 0.5727\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 0s 682us/step - loss: 6.9942 - accuracy: 0.5668\n",
      "Epoch 65/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 7.0863 - accuracy: 0.5839\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 0s 568us/step - loss: 7.0854 - accuracy: 0.5733\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 0s 699us/step - loss: 7.0411 - accuracy: 0.5662\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 0s 578us/step - loss: 6.9827 - accuracy: 0.5810\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 0s 697us/step - loss: 6.9511 - accuracy: 0.5833\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 0s 681us/step - loss: 6.8910 - accuracy: 0.5839\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 0s 517us/step - loss: 6.9926 - accuracy: 0.5780\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 0s 589us/step - loss: 6.9795 - accuracy: 0.5822\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 0s 485us/step - loss: 6.9178 - accuracy: 0.5786\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 0s 628us/step - loss: 6.9677 - accuracy: 0.5786\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 0s 435us/step - loss: 6.7811 - accuracy: 0.5798\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 0s 757us/step - loss: 6.8366 - accuracy: 0.5875\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 0s 720us/step - loss: 6.8139 - accuracy: 0.5946\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 0s 488us/step - loss: 6.7984 - accuracy: 0.5863\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 0s 577us/step - loss: 6.7990 - accuracy: 0.5863\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 0s 525us/step - loss: 6.7472 - accuracy: 0.5798\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 0s 553us/step - loss: 6.7167 - accuracy: 0.5910\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 0s 533us/step - loss: 6.6702 - accuracy: 0.5963\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 0s 578us/step - loss: 6.6682 - accuracy: 0.5881\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 0s 564us/step - loss: 6.7614 - accuracy: 0.5881\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 0s 606us/step - loss: 6.6862 - accuracy: 0.5898\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 0s 658us/step - loss: 6.8658 - accuracy: 0.5780\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 6.6273 - accuracy: 0.5904\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 0s 875us/step - loss: 6.6902 - accuracy: 0.5946\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 0s 791us/step - loss: 6.5800 - accuracy: 0.5916\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 0s 586us/step - loss: 6.5512 - accuracy: 0.6017\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 0s 630us/step - loss: 6.5616 - accuracy: 0.6022\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 0s 634us/step - loss: 6.6597 - accuracy: 0.5898\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 0s 598us/step - loss: 6.6488 - accuracy: 0.5922\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 0s 658us/step - loss: 6.4731 - accuracy: 0.6005\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 0s 569us/step - loss: 6.4443 - accuracy: 0.6064\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 6.5118 - accuracy: 0.5851\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 0s 713us/step - loss: 6.4602 - accuracy: 0.5922\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 6.4388 - accuracy: 0.5975\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 6.4196 - accuracy: 0.6064\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 0s 766us/step - loss: 6.3011 - accuracy: 0.6087\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 0s 542us/step - loss: 6.3373 - accuracy: 0.6117\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 0s 568us/step - loss: 6.4097 - accuracy: 0.6117\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 0s 496us/step - loss: 6.3991 - accuracy: 0.6070\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 6.4168 - accuracy: 0.6005\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 0s 481us/step - loss: 6.2412 - accuracy: 0.6064\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 0s 656us/step - loss: 6.1848 - accuracy: 0.6129\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 0s 468us/step - loss: 6.2531 - accuracy: 0.6087\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 0s 631us/step - loss: 6.3818 - accuracy: 0.6064\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 0s 516us/step - loss: 6.2309 - accuracy: 0.6229\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 0s 501us/step - loss: 6.4417 - accuracy: 0.6087\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 0s 544us/step - loss: 6.2563 - accuracy: 0.6058\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 0s 804us/step - loss: 6.3026 - accuracy: 0.6093\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 0s 459us/step - loss: 6.1686 - accuracy: 0.6076\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 0s 781us/step - loss: 6.1744 - accuracy: 0.6117\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 0s 637us/step - loss: 6.1457 - accuracy: 0.6123\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 0s 467us/step - loss: 6.1568 - accuracy: 0.6152\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 0s 537us/step - loss: 6.0534 - accuracy: 0.6253\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 0s 619us/step - loss: 6.1023 - accuracy: 0.6176\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 0s 516us/step - loss: 6.0278 - accuracy: 0.6135\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 6.1020 - accuracy: 0.6217\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.9845 - accuracy: 0.6229\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 0s 447us/step - loss: 6.0490 - accuracy: 0.6158\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 0s 531us/step - loss: 5.9894 - accuracy: 0.6265\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 0s 965us/step - loss: 6.0506 - accuracy: 0.6164\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 0s 615us/step - loss: 5.9394 - accuracy: 0.6223\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 0s 687us/step - loss: 5.9280 - accuracy: 0.6217\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 0s 715us/step - loss: 5.9535 - accuracy: 0.6235\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 0s 509us/step - loss: 5.8995 - accuracy: 0.6152\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 0s 659us/step - loss: 5.9046 - accuracy: 0.6271\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 0s 590us/step - loss: 5.9976 - accuracy: 0.6330\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 0s 588us/step - loss: 5.9336 - accuracy: 0.6277\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 0s 479us/step - loss: 5.7255 - accuracy: 0.6401\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 0s 619us/step - loss: 6.0377 - accuracy: 0.6271\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 0s 661us/step - loss: 5.9252 - accuracy: 0.6265\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 0s 538us/step - loss: 5.6781 - accuracy: 0.6395\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 0s 561us/step - loss: 5.7642 - accuracy: 0.6348\n",
      "Epoch 137/500\n",
      "27/27 [==============================] - 0s 527us/step - loss: 5.6574 - accuracy: 0.6377\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 5.7541 - accuracy: 0.6377\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 0s 553us/step - loss: 5.8769 - accuracy: 0.6235\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 0s 652us/step - loss: 5.8131 - accuracy: 0.6395\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 0s 464us/step - loss: 5.6363 - accuracy: 0.6359\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 0s 602us/step - loss: 5.7211 - accuracy: 0.6389\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 0s 554us/step - loss: 5.7029 - accuracy: 0.6365\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.5464 - accuracy: 0.6377\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 0s 837us/step - loss: 5.7629 - accuracy: 0.6401\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 0s 745us/step - loss: 5.8237 - accuracy: 0.6348\n",
      "Epoch 147/500\n",
      "27/27 [==============================] - 0s 639us/step - loss: 5.6206 - accuracy: 0.6548\n",
      "Epoch 148/500\n",
      "27/27 [==============================] - 0s 594us/step - loss: 5.6263 - accuracy: 0.6460\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - 0s 565us/step - loss: 5.5454 - accuracy: 0.6483\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 5.4897 - accuracy: 0.6454\n",
      "Epoch 151/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 5.7015 - accuracy: 0.6519\n",
      "Epoch 152/500\n",
      "27/27 [==============================] - 0s 758us/step - loss: 5.5041 - accuracy: 0.6430\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.5620 - accuracy: 0.6418\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 0s 725us/step - loss: 5.4391 - accuracy: 0.6554\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 0s 477us/step - loss: 5.5279 - accuracy: 0.6578\n",
      "Epoch 156/500\n",
      "27/27 [==============================] - 0s 594us/step - loss: 5.5339 - accuracy: 0.6489\n",
      "Epoch 157/500\n",
      "27/27 [==============================] - 0s 549us/step - loss: 5.4498 - accuracy: 0.6460\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - 0s 500us/step - loss: 5.4653 - accuracy: 0.6602\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 0s 546us/step - loss: 5.4687 - accuracy: 0.6548\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 0s 685us/step - loss: 5.4913 - accuracy: 0.6454\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.5260 - accuracy: 0.6489\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 0s 585us/step - loss: 5.5004 - accuracy: 0.6413\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 0s 880us/step - loss: 5.4752 - accuracy: 0.6548\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 0s 499us/step - loss: 5.5483 - accuracy: 0.6501\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 0s 704us/step - loss: 5.3432 - accuracy: 0.6596\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 0s 592us/step - loss: 5.6529 - accuracy: 0.6359\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 0s 579us/step - loss: 5.3579 - accuracy: 0.6643\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 0s 647us/step - loss: 5.3118 - accuracy: 0.6519\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 0s 489us/step - loss: 5.2991 - accuracy: 0.6566\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 0s 671us/step - loss: 5.4008 - accuracy: 0.6513\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 0s 637us/step - loss: 5.4202 - accuracy: 0.6389\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 0s 561us/step - loss: 5.3584 - accuracy: 0.6495\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 0s 611us/step - loss: 5.3913 - accuracy: 0.6531\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 5.3673 - accuracy: 0.6537\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 0s 572us/step - loss: 5.2242 - accuracy: 0.6673\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 0s 616us/step - loss: 5.3075 - accuracy: 0.6578\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 0s 544us/step - loss: 5.2358 - accuracy: 0.6661\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 0s 598us/step - loss: 5.2389 - accuracy: 0.6584\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 0s 534us/step - loss: 5.1293 - accuracy: 0.6732\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 5.3084 - accuracy: 0.6608\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 0s 560us/step - loss: 5.1304 - accuracy: 0.6631\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 0s 558us/step - loss: 5.2837 - accuracy: 0.6643\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.2044 - accuracy: 0.6720\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 5.3575 - accuracy: 0.6578\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 0s 513us/step - loss: 5.1449 - accuracy: 0.6773\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 0s 778us/step - loss: 5.1541 - accuracy: 0.6809\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 0s 627us/step - loss: 5.0957 - accuracy: 0.6726\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 0s 537us/step - loss: 5.3036 - accuracy: 0.6590\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 0s 740us/step - loss: 5.0953 - accuracy: 0.6779\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 0s 611us/step - loss: 5.2053 - accuracy: 0.6696\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 0s 566us/step - loss: 5.1151 - accuracy: 0.6625\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 0s 574us/step - loss: 4.9999 - accuracy: 0.6738\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 0s 536us/step - loss: 5.0366 - accuracy: 0.6738\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 0s 604us/step - loss: 5.1729 - accuracy: 0.6673\n",
      "Epoch 195/500\n",
      "27/27 [==============================] - 0s 612us/step - loss: 5.1847 - accuracy: 0.6684\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 0s 552us/step - loss: 5.1304 - accuracy: 0.6732\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 0s 558us/step - loss: 5.0384 - accuracy: 0.6749\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 0s 629us/step - loss: 4.9333 - accuracy: 0.6749\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 0s 650us/step - loss: 4.9553 - accuracy: 0.6726\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 0s 448us/step - loss: 5.1152 - accuracy: 0.6690\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 0s 737us/step - loss: 4.9963 - accuracy: 0.6755\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 0s 494us/step - loss: 5.0189 - accuracy: 0.6761\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 0s 762us/step - loss: 5.2613 - accuracy: 0.6761\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 0s 481us/step - loss: 4.9256 - accuracy: 0.6791\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 0s 705us/step - loss: 4.9685 - accuracy: 0.6820\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 0s 629us/step - loss: 4.9557 - accuracy: 0.6797\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 0s 439us/step - loss: 5.0421 - accuracy: 0.6690\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 0s 688us/step - loss: 5.0295 - accuracy: 0.6779\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 0s 831us/step - loss: 5.0775 - accuracy: 0.6767\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 0s 532us/step - loss: 5.0131 - accuracy: 0.6803\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 0s 601us/step - loss: 4.7501 - accuracy: 0.6933\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 0s 578us/step - loss: 5.0981 - accuracy: 0.6844\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 0s 457us/step - loss: 5.2939 - accuracy: 0.6602\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 0s 609us/step - loss: 4.7935 - accuracy: 0.6874\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 0s 774us/step - loss: 4.8399 - accuracy: 0.6974\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 0s 426us/step - loss: 4.9423 - accuracy: 0.6838\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 0s 689us/step - loss: 4.7750 - accuracy: 0.6885\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 0s 775us/step - loss: 4.8900 - accuracy: 0.6797\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 0s 684us/step - loss: 4.7851 - accuracy: 0.6891\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.7625 - accuracy: 0.6950\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 0s 4ms/step - loss: 4.9106 - accuracy: 0.6856\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.6834 - accuracy: 0.6891\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 0s 855us/step - loss: 4.9769 - accuracy: 0.6779\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 0s 900us/step - loss: 4.9445 - accuracy: 0.6690\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 0s 568us/step - loss: 4.9471 - accuracy: 0.6868\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 0s 517us/step - loss: 4.8180 - accuracy: 0.6950\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 0s 541us/step - loss: 4.8529 - accuracy: 0.6862\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 0s 587us/step - loss: 4.7869 - accuracy: 0.6921\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 0s 691us/step - loss: 4.7861 - accuracy: 0.6956\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 0s 474us/step - loss: 4.7926 - accuracy: 0.6956\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 0s 629us/step - loss: 4.8554 - accuracy: 0.6726\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 0s 539us/step - loss: 4.6633 - accuracy: 0.6956\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 0s 538us/step - loss: 4.6658 - accuracy: 0.7009\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 0s 509us/step - loss: 4.7825 - accuracy: 0.6950\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 0s 618us/step - loss: 4.8851 - accuracy: 0.6791\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 0s 575us/step - loss: 4.5912 - accuracy: 0.7004\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 4.7967 - accuracy: 0.6903\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 0s 648us/step - loss: 4.5697 - accuracy: 0.6927\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 0s 561us/step - loss: 4.7741 - accuracy: 0.6944\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 0s 576us/step - loss: 4.6921 - accuracy: 0.6944\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 0s 719us/step - loss: 4.6989 - accuracy: 0.6974\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 0s 903us/step - loss: 4.6317 - accuracy: 0.6927\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 0s 637us/step - loss: 4.6994 - accuracy: 0.7015\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 0s 661us/step - loss: 4.7983 - accuracy: 0.7015\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 0s 637us/step - loss: 4.6360 - accuracy: 0.7027\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 0s 504us/step - loss: 4.6079 - accuracy: 0.7057\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 0s 736us/step - loss: 4.8816 - accuracy: 0.6874\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 0s 623us/step - loss: 4.5696 - accuracy: 0.6980\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 0s 546us/step - loss: 4.6438 - accuracy: 0.7074\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 0s 601us/step - loss: 4.5917 - accuracy: 0.7021\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 4.7954 - accuracy: 0.6980\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.5156 - accuracy: 0.6998\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 0s 482us/step - loss: 4.6110 - accuracy: 0.6980\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 0s 670us/step - loss: 4.5427 - accuracy: 0.7051\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 0s 651us/step - loss: 4.6517 - accuracy: 0.6950\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 0s 570us/step - loss: 4.7118 - accuracy: 0.6856\n",
      "Epoch 257/500\n",
      "27/27 [==============================] - 0s 653us/step - loss: 4.6092 - accuracy: 0.6980\n",
      "Epoch 258/500\n",
      "27/27 [==============================] - 0s 583us/step - loss: 4.5202 - accuracy: 0.7039\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.4707 - accuracy: 0.7069\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 0s 975us/step - loss: 4.5390 - accuracy: 0.7033\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 0s 721us/step - loss: 4.5493 - accuracy: 0.7086\n",
      "Epoch 262/500\n",
      "27/27 [==============================] - 0s 510us/step - loss: 4.5166 - accuracy: 0.7063\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 0s 605us/step - loss: 4.6614 - accuracy: 0.7092\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 0s 571us/step - loss: 4.5755 - accuracy: 0.7122\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 0s 650us/step - loss: 4.4276 - accuracy: 0.7116\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 0s 573us/step - loss: 4.4839 - accuracy: 0.7116\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 0s 497us/step - loss: 4.4889 - accuracy: 0.7039\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 0s 740us/step - loss: 4.6583 - accuracy: 0.6968\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 0s 544us/step - loss: 4.5966 - accuracy: 0.7092\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 0s 783us/step - loss: 4.3952 - accuracy: 0.7104\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 0s 539us/step - loss: 4.4197 - accuracy: 0.7122\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 0s 550us/step - loss: 4.4531 - accuracy: 0.7210\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 0s 662us/step - loss: 4.4987 - accuracy: 0.7033\n",
      "Epoch 274/500\n",
      "27/27 [==============================] - 0s 724us/step - loss: 4.4589 - accuracy: 0.7051\n",
      "Epoch 275/500\n",
      "27/27 [==============================] - 0s 521us/step - loss: 4.5527 - accuracy: 0.7128\n",
      "Epoch 276/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.4141 - accuracy: 0.7063\n",
      "Epoch 277/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 4.5511 - accuracy: 0.6968\n",
      "Epoch 278/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.4523 - accuracy: 0.7281\n",
      "Epoch 279/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 4.5335 - accuracy: 0.7045\n",
      "Epoch 280/500\n",
      "27/27 [==============================] - 0s 842us/step - loss: 4.5006 - accuracy: 0.7199\n",
      "Epoch 281/500\n",
      "27/27 [==============================] - 0s 962us/step - loss: 4.4115 - accuracy: 0.7110\n",
      "Epoch 282/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.3254 - accuracy: 0.7293\n",
      "Epoch 283/500\n",
      "27/27 [==============================] - 0s 549us/step - loss: 4.4275 - accuracy: 0.7145\n",
      "Epoch 284/500\n",
      "27/27 [==============================] - 0s 522us/step - loss: 4.6025 - accuracy: 0.7009\n",
      "Epoch 285/500\n",
      "27/27 [==============================] - 0s 529us/step - loss: 4.4308 - accuracy: 0.7175\n",
      "Epoch 286/500\n",
      "27/27 [==============================] - 0s 592us/step - loss: 4.4005 - accuracy: 0.7240\n",
      "Epoch 287/500\n",
      "27/27 [==============================] - 0s 487us/step - loss: 4.2600 - accuracy: 0.7128\n",
      "Epoch 288/500\n",
      "27/27 [==============================] - 0s 541us/step - loss: 4.3896 - accuracy: 0.7139\n",
      "Epoch 289/500\n",
      "27/27 [==============================] - 0s 573us/step - loss: 4.2917 - accuracy: 0.7246\n",
      "Epoch 290/500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 4.5044 - accuracy: 0.7139\n",
      "Epoch 291/500\n",
      "27/27 [==============================] - 0s 517us/step - loss: 4.2562 - accuracy: 0.7246\n",
      "Epoch 292/500\n",
      "27/27 [==============================] - 0s 561us/step - loss: 4.3441 - accuracy: 0.7240\n",
      "Epoch 293/500\n",
      "27/27 [==============================] - 0s 512us/step - loss: 4.4694 - accuracy: 0.7122\n",
      "Epoch 294/500\n",
      "27/27 [==============================] - 0s 543us/step - loss: 4.3891 - accuracy: 0.7092\n",
      "Epoch 295/500\n",
      "27/27 [==============================] - 0s 658us/step - loss: 4.2968 - accuracy: 0.7275\n",
      "Epoch 296/500\n",
      "27/27 [==============================] - 0s 792us/step - loss: 4.3864 - accuracy: 0.7151\n",
      "Epoch 297/500\n",
      "27/27 [==============================] - 0s 530us/step - loss: 4.2245 - accuracy: 0.7281\n",
      "Epoch 298/500\n",
      "27/27 [==============================] - 0s 596us/step - loss: 4.2896 - accuracy: 0.7258\n",
      "Epoch 299/500\n",
      "27/27 [==============================] - 0s 645us/step - loss: 4.1745 - accuracy: 0.7299\n",
      "Epoch 300/500\n",
      "27/27 [==============================] - 0s 600us/step - loss: 4.2530 - accuracy: 0.7128\n",
      "Epoch 301/500\n",
      "27/27 [==============================] - 0s 691us/step - loss: 4.3796 - accuracy: 0.7193\n",
      "Epoch 302/500\n",
      "27/27 [==============================] - 0s 614us/step - loss: 4.3123 - accuracy: 0.7216\n",
      "Epoch 303/500\n",
      "27/27 [==============================] - 0s 863us/step - loss: 4.2789 - accuracy: 0.7299\n",
      "Epoch 304/500\n",
      "27/27 [==============================] - 0s 931us/step - loss: 4.2547 - accuracy: 0.7222\n",
      "Epoch 305/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 4.3271 - accuracy: 0.7193\n",
      "Epoch 306/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.2587 - accuracy: 0.7388\n",
      "Epoch 307/500\n",
      "27/27 [==============================] - 0s 787us/step - loss: 4.3090 - accuracy: 0.7299\n",
      "Epoch 308/500\n",
      "27/27 [==============================] - 0s 775us/step - loss: 4.3222 - accuracy: 0.7045\n",
      "Epoch 309/500\n",
      "27/27 [==============================] - 0s 578us/step - loss: 4.4277 - accuracy: 0.7199\n",
      "Epoch 310/500\n",
      "27/27 [==============================] - 0s 823us/step - loss: 4.1935 - accuracy: 0.7228\n",
      "Epoch 311/500\n",
      "27/27 [==============================] - 0s 628us/step - loss: 4.2948 - accuracy: 0.7400\n",
      "Epoch 312/500\n",
      "27/27 [==============================] - 0s 657us/step - loss: 4.2880 - accuracy: 0.7187\n",
      "Epoch 313/500\n",
      "27/27 [==============================] - 0s 641us/step - loss: 4.3096 - accuracy: 0.7187\n",
      "Epoch 314/500\n",
      "27/27 [==============================] - 0s 679us/step - loss: 4.3015 - accuracy: 0.7287\n",
      "Epoch 315/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.2002 - accuracy: 0.7270\n",
      "Epoch 316/500\n",
      "27/27 [==============================] - 0s 947us/step - loss: 4.1473 - accuracy: 0.7329\n",
      "Epoch 317/500\n",
      "27/27 [==============================] - 0s 568us/step - loss: 4.4401 - accuracy: 0.7074\n",
      "Epoch 318/500\n",
      "27/27 [==============================] - 0s 744us/step - loss: 4.2346 - accuracy: 0.7216\n",
      "Epoch 319/500\n",
      "27/27 [==============================] - 0s 610us/step - loss: 4.2075 - accuracy: 0.7281\n",
      "Epoch 320/500\n",
      "27/27 [==============================] - 0s 576us/step - loss: 4.2702 - accuracy: 0.7145\n",
      "Epoch 321/500\n",
      "27/27 [==============================] - 0s 454us/step - loss: 4.3777 - accuracy: 0.7246\n",
      "Epoch 322/500\n",
      "27/27 [==============================] - 0s 711us/step - loss: 4.1017 - accuracy: 0.7346\n",
      "Epoch 323/500\n",
      "27/27 [==============================] - 0s 642us/step - loss: 4.1977 - accuracy: 0.7258\n",
      "Epoch 324/500\n",
      "27/27 [==============================] - 0s 609us/step - loss: 4.2170 - accuracy: 0.7264\n",
      "Epoch 325/500\n",
      "27/27 [==============================] - 0s 662us/step - loss: 4.1596 - accuracy: 0.7216\n",
      "Epoch 326/500\n",
      "27/27 [==============================] - 0s 558us/step - loss: 4.2920 - accuracy: 0.7074\n",
      "Epoch 327/500\n",
      "27/27 [==============================] - 0s 567us/step - loss: 4.1046 - accuracy: 0.7352\n",
      "Epoch 328/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.3043 - accuracy: 0.7193\n",
      "Epoch 329/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 4.0871 - accuracy: 0.7335\n",
      "Epoch 330/500\n",
      "27/27 [==============================] - 0s 832us/step - loss: 4.1713 - accuracy: 0.7299\n",
      "Epoch 331/500\n",
      "27/27 [==============================] - 0s 781us/step - loss: 4.1489 - accuracy: 0.7317\n",
      "Epoch 332/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.1597 - accuracy: 0.7258\n",
      "Epoch 333/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.1042 - accuracy: 0.7388\n",
      "Epoch 334/500\n",
      "27/27 [==============================] - 0s 931us/step - loss: 4.1000 - accuracy: 0.7311\n",
      "Epoch 335/500\n",
      "27/27 [==============================] - 0s 540us/step - loss: 4.1511 - accuracy: 0.7429\n",
      "Epoch 336/500\n",
      "27/27 [==============================] - 0s 637us/step - loss: 4.1617 - accuracy: 0.7352\n",
      "Epoch 337/500\n",
      "27/27 [==============================] - 0s 870us/step - loss: 4.1898 - accuracy: 0.7222\n",
      "Epoch 338/500\n",
      "27/27 [==============================] - 0s 500us/step - loss: 4.2319 - accuracy: 0.7411\n",
      "Epoch 339/500\n",
      "27/27 [==============================] - 0s 536us/step - loss: 4.0589 - accuracy: 0.7240\n",
      "Epoch 340/500\n",
      "27/27 [==============================] - 0s 579us/step - loss: 4.1192 - accuracy: 0.7252\n",
      "Epoch 341/500\n",
      "27/27 [==============================] - 0s 512us/step - loss: 4.1047 - accuracy: 0.7204\n",
      "Epoch 342/500\n",
      "27/27 [==============================] - 0s 639us/step - loss: 4.3134 - accuracy: 0.7246\n",
      "Epoch 343/500\n",
      "27/27 [==============================] - 0s 543us/step - loss: 4.0765 - accuracy: 0.7199\n",
      "Epoch 344/500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 4.1030 - accuracy: 0.7317\n",
      "Epoch 345/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 4.1109 - accuracy: 0.7275\n",
      "Epoch 346/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 4.0637 - accuracy: 0.7329\n",
      "Epoch 347/500\n",
      "27/27 [==============================] - 0s 933us/step - loss: 3.9774 - accuracy: 0.7453\n",
      "Epoch 348/500\n",
      "27/27 [==============================] - 0s 777us/step - loss: 4.0518 - accuracy: 0.7335\n",
      "Epoch 349/500\n",
      "27/27 [==============================] - 0s 546us/step - loss: 4.1545 - accuracy: 0.7204\n",
      "Epoch 350/500\n",
      "27/27 [==============================] - 0s 629us/step - loss: 4.1310 - accuracy: 0.7216\n",
      "Epoch 351/500\n",
      "27/27 [==============================] - 0s 727us/step - loss: 4.1016 - accuracy: 0.7382\n",
      "Epoch 352/500\n",
      "27/27 [==============================] - 0s 684us/step - loss: 4.0285 - accuracy: 0.7435\n",
      "Epoch 353/500\n",
      "27/27 [==============================] - 0s 629us/step - loss: 3.9525 - accuracy: 0.7376\n",
      "Epoch 354/500\n",
      "27/27 [==============================] - 0s 498us/step - loss: 4.1037 - accuracy: 0.7317\n",
      "Epoch 355/500\n",
      "27/27 [==============================] - 0s 573us/step - loss: 4.0377 - accuracy: 0.7429\n",
      "Epoch 356/500\n",
      "27/27 [==============================] - 0s 508us/step - loss: 4.0164 - accuracy: 0.7246\n",
      "Epoch 357/500\n",
      "27/27 [==============================] - 0s 656us/step - loss: 4.0032 - accuracy: 0.7340\n",
      "Epoch 358/500\n",
      "27/27 [==============================] - 0s 564us/step - loss: 4.0034 - accuracy: 0.7364\n",
      "Epoch 359/500\n",
      "27/27 [==============================] - 0s 473us/step - loss: 4.1227 - accuracy: 0.7234\n",
      "Epoch 360/500\n",
      "27/27 [==============================] - 0s 602us/step - loss: 4.0453 - accuracy: 0.7287\n",
      "Epoch 361/500\n",
      "27/27 [==============================] - 0s 782us/step - loss: 4.2149 - accuracy: 0.7370\n",
      "Epoch 362/500\n",
      "27/27 [==============================] - 0s 986us/step - loss: 4.0246 - accuracy: 0.7411\n",
      "Epoch 363/500\n",
      "27/27 [==============================] - 0s 560us/step - loss: 3.9900 - accuracy: 0.7352\n",
      "Epoch 364/500\n",
      "27/27 [==============================] - 0s 747us/step - loss: 4.0615 - accuracy: 0.7423\n",
      "Epoch 365/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 4.0048 - accuracy: 0.7275\n",
      "Epoch 366/500\n",
      "27/27 [==============================] - 0s 621us/step - loss: 4.0981 - accuracy: 0.7299\n",
      "Epoch 367/500\n",
      "27/27 [==============================] - 0s 525us/step - loss: 3.9834 - accuracy: 0.7311\n",
      "Epoch 368/500\n",
      "27/27 [==============================] - 0s 714us/step - loss: 4.2158 - accuracy: 0.7181\n",
      "Epoch 369/500\n",
      "27/27 [==============================] - 0s 508us/step - loss: 4.0252 - accuracy: 0.7305\n",
      "Epoch 370/500\n",
      "27/27 [==============================] - 0s 857us/step - loss: 3.9237 - accuracy: 0.7423\n",
      "Epoch 371/500\n",
      "27/27 [==============================] - 0s 723us/step - loss: 3.9396 - accuracy: 0.7394\n",
      "Epoch 372/500\n",
      "27/27 [==============================] - 0s 818us/step - loss: 4.0082 - accuracy: 0.7388\n",
      "Epoch 373/500\n",
      "27/27 [==============================] - 0s 778us/step - loss: 3.9402 - accuracy: 0.7346\n",
      "Epoch 374/500\n",
      "27/27 [==============================] - 0s 602us/step - loss: 3.9139 - accuracy: 0.7417\n",
      "Epoch 375/500\n",
      "27/27 [==============================] - 0s 665us/step - loss: 3.9660 - accuracy: 0.7447\n",
      "Epoch 376/500\n",
      "27/27 [==============================] - 0s 855us/step - loss: 3.9663 - accuracy: 0.7329\n",
      "Epoch 377/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 3.9717 - accuracy: 0.7476\n",
      "Epoch 378/500\n",
      "27/27 [==============================] - 0s 902us/step - loss: 4.1485 - accuracy: 0.7299\n",
      "Epoch 379/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.9243 - accuracy: 0.7476\n",
      "Epoch 380/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 3.9958 - accuracy: 0.7305\n",
      "Epoch 381/500\n",
      "27/27 [==============================] - 0s 906us/step - loss: 3.9510 - accuracy: 0.7465\n",
      "Epoch 382/500\n",
      "27/27 [==============================] - 0s 516us/step - loss: 3.9139 - accuracy: 0.7405\n",
      "Epoch 383/500\n",
      "27/27 [==============================] - 0s 551us/step - loss: 3.8964 - accuracy: 0.7435\n",
      "Epoch 384/500\n",
      "27/27 [==============================] - 0s 463us/step - loss: 4.0698 - accuracy: 0.7453\n",
      "Epoch 385/500\n",
      "27/27 [==============================] - 0s 556us/step - loss: 3.9888 - accuracy: 0.7441\n",
      "Epoch 386/500\n",
      "27/27 [==============================] - 0s 625us/step - loss: 3.8886 - accuracy: 0.7535\n",
      "Epoch 387/500\n",
      "27/27 [==============================] - 0s 460us/step - loss: 3.8003 - accuracy: 0.7524\n",
      "Epoch 388/500\n",
      "27/27 [==============================] - 0s 510us/step - loss: 3.9209 - accuracy: 0.7358\n",
      "Epoch 389/500\n",
      "27/27 [==============================] - 0s 582us/step - loss: 3.8111 - accuracy: 0.7470\n",
      "Epoch 390/500\n",
      "27/27 [==============================] - 0s 581us/step - loss: 3.7760 - accuracy: 0.7500\n",
      "Epoch 391/500\n",
      "27/27 [==============================] - 0s 624us/step - loss: 3.9981 - accuracy: 0.7441\n",
      "Epoch 392/500\n",
      "27/27 [==============================] - 0s 567us/step - loss: 3.9299 - accuracy: 0.7335\n",
      "Epoch 393/500\n",
      "27/27 [==============================] - 0s 602us/step - loss: 3.8397 - accuracy: 0.7435\n",
      "Epoch 394/500\n",
      "27/27 [==============================] - 0s 723us/step - loss: 3.9937 - accuracy: 0.7293\n",
      "Epoch 395/500\n",
      "27/27 [==============================] - 0s 586us/step - loss: 3.9952 - accuracy: 0.7530\n",
      "Epoch 396/500\n",
      "27/27 [==============================] - 0s 553us/step - loss: 4.0017 - accuracy: 0.7305\n",
      "Epoch 397/500\n",
      "27/27 [==============================] - 0s 569us/step - loss: 3.8420 - accuracy: 0.7429\n",
      "Epoch 398/500\n",
      "27/27 [==============================] - 0s 677us/step - loss: 3.8191 - accuracy: 0.7476\n",
      "Epoch 399/500\n",
      "27/27 [==============================] - 0s 511us/step - loss: 3.8757 - accuracy: 0.7506\n",
      "Epoch 400/500\n",
      "27/27 [==============================] - 0s 440us/step - loss: 3.8697 - accuracy: 0.7453\n",
      "Epoch 401/500\n",
      "27/27 [==============================] - 0s 596us/step - loss: 3.8784 - accuracy: 0.7535\n",
      "Epoch 402/500\n",
      "27/27 [==============================] - 0s 559us/step - loss: 3.9060 - accuracy: 0.7447\n",
      "Epoch 403/500\n",
      "27/27 [==============================] - 0s 562us/step - loss: 3.7946 - accuracy: 0.7429\n",
      "Epoch 404/500\n",
      "27/27 [==============================] - 0s 826us/step - loss: 3.9064 - accuracy: 0.7346\n",
      "Epoch 405/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 3.7825 - accuracy: 0.7465\n",
      "Epoch 406/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 3.8359 - accuracy: 0.7541\n",
      "Epoch 407/500\n",
      "27/27 [==============================] - 0s 715us/step - loss: 3.9146 - accuracy: 0.7553\n",
      "Epoch 408/500\n",
      "27/27 [==============================] - 0s 738us/step - loss: 3.8489 - accuracy: 0.7488\n",
      "Epoch 409/500\n",
      "27/27 [==============================] - 0s 614us/step - loss: 3.8349 - accuracy: 0.7447\n",
      "Epoch 410/500\n",
      "27/27 [==============================] - 0s 519us/step - loss: 3.9081 - accuracy: 0.7500\n",
      "Epoch 411/500\n",
      "27/27 [==============================] - 0s 633us/step - loss: 3.8175 - accuracy: 0.7488\n",
      "Epoch 412/500\n",
      "27/27 [==============================] - 0s 527us/step - loss: 3.9573 - accuracy: 0.7287\n",
      "Epoch 413/500\n",
      "27/27 [==============================] - 0s 595us/step - loss: 3.9096 - accuracy: 0.7459\n",
      "Epoch 414/500\n",
      "27/27 [==============================] - 0s 583us/step - loss: 3.7737 - accuracy: 0.7482\n",
      "Epoch 415/500\n",
      "27/27 [==============================] - 0s 682us/step - loss: 3.8846 - accuracy: 0.7258\n",
      "Epoch 416/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 3.8116 - accuracy: 0.7459\n",
      "Epoch 417/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 3.8318 - accuracy: 0.7535\n",
      "Epoch 418/500\n",
      "27/27 [==============================] - 0s 766us/step - loss: 4.0051 - accuracy: 0.7352\n",
      "Epoch 419/500\n",
      "27/27 [==============================] - 0s 813us/step - loss: 3.8910 - accuracy: 0.7370\n",
      "Epoch 420/500\n",
      "27/27 [==============================] - 0s 998us/step - loss: 3.8090 - accuracy: 0.7405\n",
      "Epoch 421/500\n",
      "27/27 [==============================] - 0s 487us/step - loss: 3.8230 - accuracy: 0.7494\n",
      "Epoch 422/500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 3.8652 - accuracy: 0.7400\n",
      "Epoch 423/500\n",
      "27/27 [==============================] - 0s 528us/step - loss: 3.9752 - accuracy: 0.7311\n",
      "Epoch 424/500\n",
      "27/27 [==============================] - 0s 444us/step - loss: 3.8230 - accuracy: 0.7453\n",
      "Epoch 425/500\n",
      "27/27 [==============================] - 0s 478us/step - loss: 3.7101 - accuracy: 0.7465\n",
      "Epoch 426/500\n",
      "27/27 [==============================] - 0s 428us/step - loss: 3.8748 - accuracy: 0.7346\n",
      "Epoch 427/500\n",
      "27/27 [==============================] - 0s 589us/step - loss: 3.8602 - accuracy: 0.7459\n",
      "Epoch 428/500\n",
      "27/27 [==============================] - 0s 610us/step - loss: 3.7854 - accuracy: 0.7388\n",
      "Epoch 429/500\n",
      "27/27 [==============================] - 0s 514us/step - loss: 3.7893 - accuracy: 0.7494\n",
      "Epoch 430/500\n",
      "27/27 [==============================] - 0s 544us/step - loss: 3.7636 - accuracy: 0.7535\n",
      "Epoch 431/500\n",
      "27/27 [==============================] - 0s 527us/step - loss: 3.7277 - accuracy: 0.7530\n",
      "Epoch 432/500\n",
      "27/27 [==============================] - 0s 966us/step - loss: 3.7953 - accuracy: 0.7565\n",
      "Epoch 433/500\n",
      "27/27 [==============================] - 0s 618us/step - loss: 3.7761 - accuracy: 0.7482\n",
      "Epoch 434/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.6987 - accuracy: 0.7512\n",
      "Epoch 435/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.6900 - accuracy: 0.7654\n",
      "Epoch 436/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.7669 - accuracy: 0.7441\n",
      "Epoch 437/500\n",
      "27/27 [==============================] - 0s 707us/step - loss: 3.7588 - accuracy: 0.7565\n",
      "Epoch 438/500\n",
      "27/27 [==============================] - 0s 692us/step - loss: 3.8993 - accuracy: 0.7400\n",
      "Epoch 439/500\n",
      "27/27 [==============================] - 0s 756us/step - loss: 3.8155 - accuracy: 0.7488\n",
      "Epoch 440/500\n",
      "27/27 [==============================] - 0s 605us/step - loss: 3.6877 - accuracy: 0.7636\n",
      "Epoch 441/500\n",
      "27/27 [==============================] - 0s 679us/step - loss: 3.7312 - accuracy: 0.7476\n",
      "Epoch 442/500\n",
      "27/27 [==============================] - 0s 484us/step - loss: 3.7193 - accuracy: 0.7589\n",
      "Epoch 443/500\n",
      "27/27 [==============================] - 0s 544us/step - loss: 3.7380 - accuracy: 0.7470\n",
      "Epoch 444/500\n",
      "27/27 [==============================] - 0s 490us/step - loss: 3.7424 - accuracy: 0.7429\n",
      "Epoch 445/500\n",
      "27/27 [==============================] - 0s 647us/step - loss: 3.8088 - accuracy: 0.7535\n",
      "Epoch 446/500\n",
      "27/27 [==============================] - 0s 750us/step - loss: 3.7913 - accuracy: 0.7488\n",
      "Epoch 447/500\n",
      "27/27 [==============================] - 0s 531us/step - loss: 3.7100 - accuracy: 0.7618\n",
      "Epoch 448/500\n",
      "27/27 [==============================] - 0s 585us/step - loss: 3.7010 - accuracy: 0.7583\n",
      "Epoch 449/500\n",
      "27/27 [==============================] - 0s 687us/step - loss: 3.7277 - accuracy: 0.7530\n",
      "Epoch 450/500\n",
      "27/27 [==============================] - 0s 755us/step - loss: 3.7223 - accuracy: 0.7459\n",
      "Epoch 451/500\n",
      "27/27 [==============================] - 0s 592us/step - loss: 3.7715 - accuracy: 0.7441\n",
      "Epoch 452/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.7120 - accuracy: 0.7553\n",
      "Epoch 453/500\n",
      "27/27 [==============================] - 0s 996us/step - loss: 3.7720 - accuracy: 0.7535\n",
      "Epoch 454/500\n",
      "27/27 [==============================] - 0s 895us/step - loss: 3.7236 - accuracy: 0.7524\n",
      "Epoch 455/500\n",
      "27/27 [==============================] - 0s 633us/step - loss: 3.6512 - accuracy: 0.7476\n",
      "Epoch 456/500\n",
      "27/27 [==============================] - 0s 611us/step - loss: 3.7719 - accuracy: 0.7547\n",
      "Epoch 457/500\n",
      "27/27 [==============================] - 0s 661us/step - loss: 3.7368 - accuracy: 0.7465\n",
      "Epoch 458/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.7026 - accuracy: 0.7494\n",
      "Epoch 459/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 3.7681 - accuracy: 0.7518\n",
      "Epoch 460/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 3.7134 - accuracy: 0.7583\n",
      "Epoch 461/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 3.6970 - accuracy: 0.7595\n",
      "Epoch 462/500\n",
      "27/27 [==============================] - 0s 753us/step - loss: 3.7209 - accuracy: 0.7636\n",
      "Epoch 463/500\n",
      "27/27 [==============================] - 0s 680us/step - loss: 3.7699 - accuracy: 0.7488\n",
      "Epoch 464/500\n",
      "27/27 [==============================] - 0s 554us/step - loss: 3.7802 - accuracy: 0.7423\n",
      "Epoch 465/500\n",
      "27/27 [==============================] - 0s 495us/step - loss: 3.6907 - accuracy: 0.7459\n",
      "Epoch 466/500\n",
      "27/27 [==============================] - 0s 530us/step - loss: 3.6108 - accuracy: 0.7612\n",
      "Epoch 467/500\n",
      "27/27 [==============================] - 0s 526us/step - loss: 3.6755 - accuracy: 0.7553\n",
      "Epoch 468/500\n",
      "27/27 [==============================] - 0s 514us/step - loss: 3.6015 - accuracy: 0.7518\n",
      "Epoch 469/500\n",
      "27/27 [==============================] - 0s 582us/step - loss: 3.6660 - accuracy: 0.7636\n",
      "Epoch 470/500\n",
      "27/27 [==============================] - 0s 491us/step - loss: 3.6993 - accuracy: 0.7470\n",
      "Epoch 471/500\n",
      "27/27 [==============================] - 0s 513us/step - loss: 3.6245 - accuracy: 0.7547\n",
      "Epoch 472/500\n",
      "27/27 [==============================] - 0s 546us/step - loss: 3.8137 - accuracy: 0.7423\n",
      "Epoch 473/500\n",
      "27/27 [==============================] - 0s 419us/step - loss: 3.6537 - accuracy: 0.7595\n",
      "Epoch 474/500\n",
      "27/27 [==============================] - 0s 577us/step - loss: 3.5895 - accuracy: 0.7600\n",
      "Epoch 475/500\n",
      "27/27 [==============================] - 0s 560us/step - loss: 3.7978 - accuracy: 0.7494\n",
      "Epoch 476/500\n",
      "27/27 [==============================] - 0s 587us/step - loss: 3.7205 - accuracy: 0.7530\n",
      "Epoch 477/500\n",
      "27/27 [==============================] - 0s 882us/step - loss: 3.6479 - accuracy: 0.7547\n",
      "Epoch 478/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.6463 - accuracy: 0.7524\n",
      "Epoch 479/500\n",
      "27/27 [==============================] - 0s 573us/step - loss: 3.7641 - accuracy: 0.7382\n",
      "Epoch 480/500\n",
      "27/27 [==============================] - 0s 798us/step - loss: 3.6438 - accuracy: 0.7589\n",
      "Epoch 481/500\n",
      "27/27 [==============================] - 0s 697us/step - loss: 3.7082 - accuracy: 0.7388\n",
      "Epoch 482/500\n",
      "27/27 [==============================] - 0s 811us/step - loss: 3.6901 - accuracy: 0.7518\n",
      "Epoch 483/500\n",
      "27/27 [==============================] - 0s 617us/step - loss: 3.6008 - accuracy: 0.7624\n",
      "Epoch 484/500\n",
      "27/27 [==============================] - 0s 627us/step - loss: 3.5572 - accuracy: 0.7606\n",
      "Epoch 485/500\n",
      "27/27 [==============================] - 0s 598us/step - loss: 3.6814 - accuracy: 0.7589\n",
      "Epoch 486/500\n",
      "27/27 [==============================] - 0s 651us/step - loss: 3.7121 - accuracy: 0.7665\n",
      "Epoch 487/500\n",
      "27/27 [==============================] - 0s 685us/step - loss: 3.6638 - accuracy: 0.7636\n",
      "Epoch 488/500\n",
      "27/27 [==============================] - 0s 427us/step - loss: 3.7294 - accuracy: 0.7565\n",
      "Epoch 489/500\n",
      "27/27 [==============================] - 0s 776us/step - loss: 3.6646 - accuracy: 0.7618\n",
      "Epoch 490/500\n",
      "27/27 [==============================] - 0s 659us/step - loss: 3.6470 - accuracy: 0.7583\n",
      "Epoch 491/500\n",
      "27/27 [==============================] - 0s 585us/step - loss: 3.6805 - accuracy: 0.7465\n",
      "Epoch 492/500\n",
      "27/27 [==============================] - 0s 804us/step - loss: 3.6883 - accuracy: 0.7335\n",
      "Epoch 493/500\n",
      "27/27 [==============================] - 0s 604us/step - loss: 3.6209 - accuracy: 0.7541\n",
      "Epoch 494/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 3.6725 - accuracy: 0.7512\n",
      "Epoch 495/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.6011 - accuracy: 0.7565\n",
      "Epoch 496/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 3.6031 - accuracy: 0.7553\n",
      "Epoch 497/500\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 3.6662 - accuracy: 0.7577\n",
      "Epoch 498/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 3.5807 - accuracy: 0.7494\n",
      "Epoch 499/500\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 3.5840 - accuracy: 0.7630\n",
      "Epoch 500/500\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 3.6006 - accuracy: 0.7530\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_one = tuned_model[\"hidden_layer_one\"]\n",
    "learn_rate = tuned_model[\"learn_rate\"]\n",
    "dropout = tuned_model[\"dropout\"]\n",
    "batch_size = tuned_model[\"batch_size\"]\n",
    "epochs = tuned_model[\"epochs\"]\n",
    "n_h_layers = tuned_model[\"n_h_layers\"]\n",
    "\n",
    "model = get_mlp_model(hidden_layer_one=30, learn_rate=0.01, dropout=0.1, n_h_layers=3)\n",
    "model.fit(X_train, y_train, epochs=500, batch_size=64, )\n",
    "\n",
    "model.save(\"../stats_regression_model.h5\")\n",
    "# pd.DataFrame(data=components[:, [p for p in range(15)]], columns=pca.get_feature_names_out(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1692\n"
     ]
    }
   ],
   "source": [
    "print(len\n",
    "\t  (X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next v  steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tune parameters and layers on the 15 PC model to increase the accuracy\n",
    "- Create a method to define the accuracy on the test set; strict equality for each of the output values is not necessary as under/over options on the betting platform mean a close approximation of the outcome is all that is required. Success/accuracy measure based on the bet markets available for each game:\n",
    "\t- Total shots\n",
    "\t- Total booking points\n",
    "\t- Correct score\n",
    "\t- Outright\n",
    "\t- Total corners\n",
    "\t- Under/over goals\n",
    "- Save the model\n",
    "- Complete the notebook with all annotations and text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomSearchCV  \n",
    "best score is 0.39 using {'n_h_layers': 5, 'learn_rate': 0.0001, 'hidden_layer_one': 15, 'epochs': 100, 'dropout': 0.2, 'batch_size': 64}  \n",
    "best score is 0.40 using {'n_h_layers': 7, 'learn_rate': 0.0001, 'hidden_layer_one': 15, 'epochs': 1000, 'dropout': 0.75, 'batch_size': 16}  \n",
    "best score is 0.49 using {'n_h_layers': 3, 'learn_rate': 0.0001, 'hidden_layer_one': 30, 'epochs': 10, 'dropout': 0.3, 'batch_size': 64} \n",
    "\n",
    "GridSearchCV  \n",
    "best score is 0.47 using {'batch_size': 64, 'dropout': 0.4, 'epochs': 100, 'hidden_layer_one': 10, 'learn_rate': 0.0001, 'n_h_layers': 2}  \n",
    "best score is 0.49100 using {'batch_size': 64, 'dropout': 0.3, 'epochs': 10, 'hidden_layer_one': 10, 'learn_rate': 0.0001, 'n_h_layers': 3}  \n",
    "best score is 0.49130 using {'batch_size': 64, 'dropout': 0.3, 'epochs': 20, 'hidden_layer_one': 15, 'learn_rate': 1e-05, 'n_h_layers': 4}  \n",
    "best score is 0.49132 using {'batch_size': 64, 'dropout': 0.3, 'epochs': 20, 'hidden_layer_one': 15, 'learn_rate': 1e-06, 'n_h_layers': 4}  \n",
    "best score is 0.49138 using {'batch_size': 64, 'dropout': 0.3, 'epochs': 15, 'hidden_layer_one': 10, 'learn_rate': 0.0001, 'n_h_layers': 6}  \n",
    "best score is 0.49138 using {'batch_size': 64, 'dropout': 0.3, 'epochs': 15, 'hidden_layer_one': 10, 'learn_rate': 1e-05, 'n_h_layers': 6}  \n",
    "best score is 0.49138 using {'batch_size': 64, 'dropout': 0.3, 'epochs': 15, 'hidden_layer_one': 10, 'learn_rate': 1e-07, 'n_h_layers': 6}  \n",
    "best score is 0.49138 using {'batch_size': 64, 'dropout': 0.3, 'epochs': 15, 'hidden_layer_one': 10, 'learn_rate': 0.0001, 'n_h_layers': 4}  \n",
    "best score is 0.49138 using {'batch_size': 32, 'dropout': 0.2, 'epochs': 12, 'hidden_layer_one': 10, 'learn_rate': 1e-05, 'n_h_layers': 4}  \n",
    "\n",
    "- During\n",
    "\t- [CV 1/3] END batch_size=64, dropout=0.2, epochs=100, hidden_layer_one=15, learn_rate=0.0001, n_h_layers=1;, score=0.459 total time=   4.3s\n",
    "\t- [CV 3/3] END batch_size=64, dropout=0.2, epochs=100, hidden_layer_one=15, learn_rate=0.0001, n_h_layers=1;, score=0.462 total time=   3.2s\n",
    "\t- [CV 1/3] END batch_size=64, dropout=0.2, epochs=100, hidden_layer_one=15, learn_rate=0.0001, n_h_layers=2;, score=0.430 total time=   3.5s\n",
    "\t- [CV 2/3] END batch_size=64, dropout=0.2, epochs=100, hidden_layer_one=15, learn_rate=0.0001, n_h_layers=1;, score=0.458 total time=   5.3s\n",
    "\t- [CV 2/3] END batch_size=64, dropout=0.2, epochs=100, hidden_layer_one=15, learn_rate=0.0001, n_h_layers=2;, score=0.412 total time=   3.8s\n",
    "\t- [CV 3/3] END batch_size=64, dropout=0.2, epochs=100, hidden_layer_one=15, learn_rate=0.0001, n_h_layers=2;, score=0.451 total time=   3.5s\n",
    "\t- [CV 1/3] END batch_size=64, dropout=0.2, epochs=100, hidden_layer_one=15, learn_rate=0.0001, n_h_layers=3;, score=0.447 total time=   3.8s\n",
    "\t- [CV 2/3] END batch_size=64, dropout=0.2, epochs=100, hidden_layer_one=15, learn_rate=0.0001, n_h_layers=3;, score=0.413 total time=   4.8s\n",
    "\t- [CV 3/3] END batch_size=64, dropout=0.2, epochs=100, hidden_layer_one=15, learn_rate=0.0001, n_h_layers=3;, score=0.415 total time=   4.9s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scaling y reduces the accuracy of the model by a factor of 6, why?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl-stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
